<!DOCTYPE html>
<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <meta name="generator" content="HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/c63cc39">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <title>Data on the Web Best Practices</title>
    <script class="remove" src="http://www.w3.org/Tools/respec/respec-w3c-common">
</script> <script class="remove" src="bpconfig.js">
</script> <style type="text/css">
#bp-summary ul {
  list-style-type: none;
  padding-left: 0;
  line-height:1.6em;
  background-color: #FCFAEE;
}

@media screen and (min-width: 600px) {
  #bp-summary ul {
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
    column-gap: 1em;
  }
}

@media screen and (min-width: 900px) {
    #bp-summary ul {
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
  }
}

.practice, #tempPractice {
  padding-left: 1em;
  background-color: #FCFAEE;
  border: thin solid black;
}

#tempPractice .tempPracticelab {
  background-color:#dfffff;
  position: relative;
  top: -1.5em;
  font-weight:bold;
}

.practice p.practicedesc, #tempPractice p.tempPracticedesc {
  font-style:italic;
  border-bottom: thin solid black;
  position:relative;
  top:-1.5em;
  margin: 0 2em -1em 1em;;
}

.subhead{
  font-weight:bold;
}

.practice dl dt #tempPractice dl dt{
  font-weight:normal;
}

figure {
  text-align:center;
}

figure figcaption {
  text-align:center;
  font-style:italic;
}

  </style>
  </head>
  <body>
    <section id="abstract">
      <p>This document provides best practices related to the publication and
        usage of data on the Web designed to help support a self-sustaining
        ecosystem. Data should be discoverable and understandable by humans and
        machines. Where data is used in some way, whether by the originator of
        the data or by an external party, such usage should also be discoverable
        and the efforts of the data publisher recognized. In short, following
        these best practices will facilitate interaction between publishers and
        consumers.</p>
    </section>
    <section id="sotd">
      <p>This early version of the document shows its expected scope and future
        direction. A template is used that shows the what, why and how of each
        best practice. Comments are sought on the usefulness of this approach
        and the expected scope of the final document.</p>
    </section>
    <section id="intro" class="informative">
      <h2>Introduction</h2>
      <p>Data on the Web Best Practices have been developed to encourage and
        enable the continued expansion of the Web as a medium for the exchange
        of data. The growth of open data by governments across the world
        [[OKFN-INDEX]], the increasing publication of research data encouraged
        by organizations like the Research Data Alliance [[RDA]], the harvesting
        and analysis of social media, crowd-sourcing of information, the
        provision of important cultural heritage collections such as
        at the Biblioth√®que nationale de France [[BNF]] and the sustained growth
        in the Linked Open Data Cloud [[LODC]], provide some examples of this
        phenomenon.</p>
      <p>In broad terms, data publishers aim to share data either openly or
        through a paywall/firewall. Data consumers (who may also be producers
        themselves) want to be able to find and use data, especially if it is
        accurate, regularly updated and guaranteed to be available at all times.
        This creates a fundamental need for a common understanding between data
        publishers and data consumers. Without this agreement, data publishers'
        efforts may be incompatible with data consumers' desires.</p>
      <p>Publishing data on the Web creates new challenges, such as how to
        represent, describe and make data available in a way that it will be
        easy to find and to understand. In this context, it becomes crucial to
        provide guidance to publishers that will improve consistency in the way
        data is managed, thus promoting the reuse of data and also to foster
        trust in the data among developers, whatever technology they choose to
        use, increasing the potential for genuine innovation.</p>
      <p>This document sets out a series of best practices that will help
        publishers and consumers face the new challenges and opportunities posed
        by data on the Web. </p>
      <p>Best practices cover different aspects related to data publishing and
        consumption, like data formats, data access, data identification and
        metadata. In order to delimit the scope and elicit the required features
        for Data on the Web Best Practices, the <abbr title="Data on the Web Best Practices">DWBP</abbr>
        working group compiled a set of use cases [[UCR]] that represent
        scenarios of how data is commonly published on the Web and how it is
        used. The set of requirements derived from these use cases were used to
        guide the development of the best practice.</p>
    </section>
    <section id="audience" class="informative">
      <h2>Audience</h2>
      <p>This document provides best practices to those who publish data on the
        Web. The best practices are designed to meet the needs of information
        management staff, developers, and wider groups such as scientists
        interested in sharing and reusing research data on the Web. Every
        attempt has been made to make the document as readable and usable as
        possible while still retaining the accuracy and clarity needed in a
        technical specification. </p>
      <p>Readers of this document are expected to be familiar with some
        fundamental concepts of the architecture of the Web [[!WEBARCH]], such
        as resources and URIs, as well as a number of data formats. The
        normative element of each best practice is the <em>intended outcome</em>.
        Possible implementations are suggested and, where appropriate, these
        recommend the use of a particular technology such as <abbr title="Comma Separataed Variables">CSV</abbr>,
        JSON or RDF. A basic knowledge of vocabularies and data models would be
        helpful to better understand some aspects of this document. </p>
      <p>This document is not targeted solely at data publishers; others
        interested on using the published data are encouraged to read it.</p>
    </section>
    <section id="scope" class="informative">
      <h2>Scope</h2>
      <p>This document is concerned solely with best practices that:</p>
      <ul>
        <li>are specifically relevant to data published on the Web;</li>
        <li>encourage publication or reuse of data on the Web;</li>
        <li>can be tested by machines, humans or a combination of the two.</li>
      </ul>
      <p>As noted above, whether a best practice has or has not been followed
        should be judged against the <em>intended outcome</em>, not the
        specific implementation which is offered as guidance. A best practice is
        always subject to improvement as we learn and evolve the Web together.</p>
    </section>
    <section id="context" class="informative">
      <h2>Context</h2>
      <section id="challenges">
        <h2>Data on the Web Challenges</h2>
        <p>The openness and flexibility of the Web creates new challenges for
          data publishers and data consumers. In contrast to conventional
          databases, for example, where there's is a single data model to
          represent the data and a database management system (DBMS) to control
          data access, data on the Web allows for the existence of multiple ways
          to represent and to access data. Furthermore, publishers and consumers
          may be unknown to each other and be part of entirely disparate
          communities with different norms and in-built assumptions so that it
          becomes essential to provide information about data structure,
          quality, provenance and any terms of use. The following list
          summarizes some of the main challenges faced when publishing or
          consuming data on the Web. These challenges were identified from the <abbr

            title="Data on the Web Best Practices">DWBP</abbr> Use Cases and
          Requirements [[UCR]] and are described by one or more questions.</p>
        <dl>
          <dt>Metadata</dt>
          <dd><em>What kind of metadata should be considered when describing
              data on the Web?<br>
              How can metadata be provided in a machine readable way?</em></dd>
          <dt>Data Identification</dt>
          <dd><em>How can unique identifiers be provided for data resources?<br>
              How should URIs be designed and managed for persistence?</em></dd>
          <dt>Data Formats</dt>
          <dd><em>What kind of data formats should be considered when publishing
              data on the Web?</em></dd>
          <dt>Data Vocabularies</dt>
          <dd><em>How can existing vocabularies be used to provide semantic
              interoperability?<br>
              How can a new vocabulary be designed if needed?</em></dd>
          <dt>Data Licenses</dt>
          <dd><em>How can data licenses be made machine readable?<br>
              How can license information about data published on the Web be
              provided/gathered?</em></dd>
          <dt>Data Provenance</dt>
          <dd><em>How can data provenance information about data published on
              the Web be gathered/provided?</em></dd>
          <dt>Data Quality</dt>
          <dd><em>How can data quality information about data on the Web be
              provided/gathered?</em></dd>
          <dt>Data Granularity</dt>
          <dd><em>How can publishers decide what kind of data granularity is
              most appropriate when publishing data on the Web?</em></dd>
          <dt>Sensitive Data</dt>
          <dd><em>How can data be published without infringing a person's right
              to privacy or an organization's security?</em></dd>
          <dt>Data Access</dt>
          <dd><em>What kind of data access should be considered when publishing
              data on the Web?<br>
              What requirements should be taken into account when deciding how
              to make data available on the Web?</em></dd>
          <dt>Data Versioning</dt>
          <dd><em>How can different versions of a dataset be tracked and
              managed?</em></dd>
          <dt>Data Preservation</dt>
          <dd><em>How can publishers decide when data on the Web should be
              archived?</em></dd>
          <dt>Feedback</dt>
          <dd><em>How can user feedback about data consumed from the Web be
              gathered?</em></dd>
        </dl>
        <p> Each one of these challenges originated one or more requirements as
          documented in <a href="http://w3c.github.io/dwbp/usecasesv1.html#R-UniqueIdentifier">the
            use-cases document</a>. The development of Data on the Web Best
          practices were guided by these requirements, in such a way that each
          best practice should have at least one of these requirements as an
          evidence of its relevance.</p>
      </section>
      <section id="lifecycle">
        <h2>Data on the Web Lifecycle</h2>
        <p>Literature presents a lot of proposals for data lifecycles ranging
          from multimedia data to digital libraries. Knud M√∂ller [[MOLLER]]
          presents a survey of lifecycle models for data-centric domains as well
          as an Abstract Data Lifecycle Model (<abbr title="Abstract Data Lifecycle Model">ADLM</abbr>)
          comprising a set of phases, features and roles that can be used to
          classify and compare existing lifecycle models. <abbr title="Abstract Data Lifecycle Model">ADLM</abbr>
          also provides the basis to construct new lifecycle models for
          data-centric domains. Following this pattern, a generic lifecycle
          model for data-centric domains comprises the following main phases: <em>Ontology
            development</em>, <em>Planning</em>, <em>Creation</em>, <em>Archiving</em>,
          <em>Refinement</em>, <em>Publication</em>, <em>Access</em>, <em>External
            use</em>, <em>Feedback</em> and <em>Termination</em>.</p>
        <p>The Data on the Web lifecycle is an instance of an <abbr title="Abstract Data Lifecycle Model">ADLM</abbr>.
          In what follows, the <abbr title="Abstract Data Lifecycle Model">ADLM</abbr>
          phases are revisited and defined according to the data on the Web
          context. It is important to note that the ontology development phase
          is not included, since it is considered an independent phase that can
          take place <i>a priori</i>. The termination phase is also out of
          scope since it is not possible to make sure that a piece of data was
          completely removed from the Web. </p>
        <ul>
          <li><em>Data Planning</em>: this phase concerns the moment when the
            intent to publish data on the Web takes a concrete form. It also
            comprises the selection of data to be published.</li>
          <li><em>Data Creation</em>: defines the moment when new data is
            created, i.e, it means that the data did not previously exist on the
            Web. It may comprise the extraction of data from existing data
            sources and its transformation to a proper format or structure for
            publishing on the Web. </li>
          <li><em>Data Publication</em>: this phase concerns the moment when
            data is made accessible on the Web.</li>
          <li><em>Access</em>: denotes the moment in the lifecycle when users
            gain access to the data available on the Web.</li>
          <li><em>External use</em>: implies that data was used to perform some
            further actions like the creation of visualizations or data
            analysis.</li>
          <li><em>Feedback</em>: this phase concerns the moment when users
            comment on the data or metadata they have previously accessed and
            used.</li>
          <li><em>Refinement</em>: this phase covers all kinds of activities
            that make additions or changes to data that already exist on the
            Web. It also concerns the management of data versioning. </li>
          <li><em>Data Archiving</em>: defines the moment when data no longer
            needs to be available on the Web. </li>
        </ul>
        <figure id="centerImg"> <img src="images/lifecyclesvg.svg" alt="The diagram shows the different phases of the Data on the Web lifecycle"

            width="450"><figcaption>The different phases of the Data on the Web
            lifecycle</figcaption></figure>
        <p>As proposed in [[MOLLER]], the data on the Web lifecycle model is an
          evolving one, since there is no restriction for data to pass through
          all phases of the lifecycle before the start of a new iteration,
          neither a specific point of the lifecyle to begin with.</p>
        <p>In the data on the Web context, two main roles may be played by
          actors in the lifecycle: data publisher and data consumer. The data
          publisher role may be played by several actors who are responsible for
          performing actions like data and metadata creation, and data
          publication and archiving. The data consumer are these actors who
          receive and consume the data. Of course consumers may well also be
          publishers.</p>
        
        
        
      </section>
    </section>
    <div class="issue">
      <p> Bernadette: Include a new section to present a glossary with definitions (or link to existing definitions) of the main terms used in the doc (ex: dataset, resource, ...) .</p>
      <p><a href="https://www.w3.org/2013/dwbp/track/issues/52">Tracker
              Issue 52</a></p>
        </div>
    <section id="bp-template">
      <h2>Best Practices Template</h2>
      <p>This section presents the template used to describe Data on the Web
        Best Practices.</p>
      <div id="tempPractice">
        <p><span id="template" class="tempPracticelab">Best Practice Template</span></p>
        <p class="tempPracticedesc">Short description of the BP.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>This section answers two crucial questions:</p>
          <ul>
            <li>Why this is unique to publishing or reusing data on the Web ?</li>
            <li>How does this encourages publication or reuse of data on the Web
              ?</li>
          </ul>
        </section>
        <section class="description">A full text description of the problem
          addressed by the best practice may also be provided. It can be any
          length but is likely to be no more than a few sentences. </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>What it should do. This is the normative part of the best practice
            and includes one or more [[!RFC2119]] keywords.</p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>A description of a possible implementation strategy is provided.
            This represents the best advice available at the time of writing but
            specific circumstances and future developments may mean that
            alternative implementation methods are more appropriate to achieve
            the intended outcome.</p>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Information on how to test the BP has been met. This might or might
            not be machine testable.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p>Information about the relevance of the BP. It is described by one
            or more relevant requirements as documented in the <a href="http://www.w3.org/TR/dwbp-ucr/">Data
              on the Web Best Practices Use Cases &amp; Requirements document</a></p>
        </section>
      </div>
    </section>
    <section id="bp-summary"></section>
    <section id="bestPractices">
      <h2>The Best Practices</h2>
      <p>This section contains the best practices to be used by data publishers
        in order to help them and data consumers to overcome the different
        challenges faced during the data on the Web lifecycle. One or more best
        practices were proposed for each one of the previously described
        challenges. Each BP is related to one or more requirements from the <a

          href="http://www.w3.org/TR/dwbp-ucr/">Data on the Web Best Practices
          Use Cases &amp; Requirements document.</a></p>
      <div class="issue">
          <p> Bernadette: Include a paragraph to explain the relation between DWBP and Best Practices for Publishing Linked Data.</p>
     <p><a href="https://www.w3.org/2013/dwbp/track/issues/125">Tracker
              Issue 125</a></p>
        </div>
      
      <section id="metadata">
        <h3>Metadata</h3>
        <p>Metadata is data about data. It provides additional information that
          helps consumers better understand the meaning of data, its structure,
          and to clarify other issues, such as rights and license terms, the
          organization that generated the data, data quality, data access
          methods, the update schedule of datasets, etc.</p>
        <p>Metadata can be used to help tasks such as dataset discovery and
          reuse, and can be assigned considering different levels of granularity
          from a single property of a resource to a whole dataset, or all
          datasets from a specific organization.</p>
        <p>Metadata can be of different types. These types can be classified in
          different taxonomies, with different grouping criteria. For example, a
          specific taxonomy could define three metadata types according to
          descriptive, structural and administrative features. Descriptive
          metadata serves to identify a dataset, structural metadata serves to
          understand the format(s) in which the dataset is distributed and
          administrative metadata serves to provide information about the
          version, update schedule etc. A different taxonomy could define
          metadata types with a scheme according to tasks where metadata are
          used, for example, discovery and reuse.</p>
        <p>This document specifies the intended outcomes for each best practice
          and then gives some guidance on possible implementation methods. In
          terms of metadata, the particular implementation method will depend on
          the format of the dataset distribution, for example, metadata
          describing a CSV file <em class="rfc2119">should</em> be provided in
          a different way than for an RDF dataset. However, the <em>intention</em>
          is the same irrespective of format.</p>
        <!-- begin of Provide Metadata BP -->
        <div class="practice">
          <p><span id="ProvideMetadata" class="practicelab">Provide metadata</span></p>
          <p class="practicedesc">Data on the Web <em class="rfc2119">must</em>
            be described by metadata.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The Web is an open information space; in the absence of a
              specific context, such a company's internal information system,
              metadata is essential. Data will not be discoverable or reusable
              by anyone other than the publisher if insufficient metadata is
              provided.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data consumers <span class="rfc2119">MUST</span> be able to:</p>
            <ol>
              <li>discover the data;</li>
              <li>understand the nature and structure of the data, i.e. what the
                data describes and how it does it;</li>
              <li>find out the origin of the data and under what terms it may be
                used.</li>
            </ol>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Later best practices provide more implementation guidance but in
              brief:</p>
            <ul>
              <li>Use DCAT [[VOCAB-DCAT]] to <strong>describe the dataset as a
                  whole</strong> and the administrative environment in which it
                was created. This vocabulary reuses much of the Dublin Core
                Metadata set [[DC-TERMS]] that provides common terms such as
                title, date, description, creator etc.</li>
              <li>For RDF datasets, use Vocabulary of Interlinked Datasets
                (VoID) [[VOID]] to <strong>describe the dataset as a whole</strong>
                and the administrative environment in which it was created. As
                DCAT, VoID uses Dublin Core Metadata set to describe the
                dataset. It can also describe patterns of the URIs used to
                access the resources and how multiple datasets are related and
                can be used together.</li>
              <li>Use an appropriate metadata schema to describe the <strong>structure
                  of the dataset</strong> as, for example, the Metadata
                Vocabulary for Tabular Data for <abbr title="Comma Separated Variables">CSV</abbr>
                files [[TABULAR-METADATA]].</li>
              <li>Use the <code>dcterms:license</code> or <code>dcterms:rights</code>
                to link a dataset to license and/or rights information.</li>
            </ul>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Test for the presence of metadata associated with the dataset.
              More detailed tests are suggested for more detailed best practices
              later in this document.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a></p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin of Provide Metadata in Different Formats BP -->
        <div class="practice">
          <p><span id="ProvideMetadataForms" class="practicelab"> Provide
              metadata in different formats </span></p>
          <p class="practicedesc">Metadata <em class="rfc2119">should</em> be
            provided for both humans and machines</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Metadata can be used by machines, notably search engines, to
              discover and classify data. Further metadata can be used by
              machines to process the data once discovered. However, machines
              typically act on instructions from, and report back to, humans.
              That is, it will often be a human that reads and makes a variety
              of assessments based on the metadata.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Humans <em class="rfc2119">must</em> be able to read metadata
              related to a dataset.</p>
            <p> Computer applications, notably search tools, <em class="rfc2119">should</em>
              be able to locate and process the metadata easily.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <ol>
              <li>Metadata for humans is most easily provided as part of an HTML
                Web page.</li>
              <li>Metadata for machines is best provided either as an
                alternative representation of the Web page in a format such as
                Turtle or JSON-LD (for RDF) or it can be embdedded in the HTML
                page, again as [[JSON-LD]], or [[HTML-RDFA]] or [[Microdata]].</li>
            </ol>
            <p>If the multiple formats are published separately, they should be
              served from the same URL using content negotiation. Maintenance of
              multiple formats is best achieved by generating each available
              format on the fly based on a single source of the metadata.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a human user can easily read the metadata associated
              with a dataset. Access the same URL either with a user agent that
              accepts a more data oriented format, such as RDF, or a tool that
              extracts the data from an HTML page such as the <a href="http://rdf-translator.appspot.com/">RDF
                Translator</a>.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a></p>
          </section>
        </div>
        <div class="issue">
          <p> Bernadette: Should we have requirements to evidence that metadata
            should also be available for humans?</p>
          <p><a href="https://www.w3.org/2013/dwbp/track/issues/121">Tracker
              Issue 121</a></p>
        </div>
        <!-- end of BP -->
        <!-- begin of Provide Metadata Standardized BP -->
        <div class="practice">
          <p><span id="ProvideMetadataStandardized" class="practicelab">Use
              standard terms to describe metadata</span></p>
          <p class="practicedesc">Metadata <em class="rfc2119">should</em> be
            provided using standard vocabularies for greater interoperability
            and discoverability.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The provision of metadata is fundamental to data on the Web. It
              is the shop window, the user-manual and the conditions of use. It
              is possible to provide this information an an infinite number of
              ways: <i>maker</i>, <i>author</i>, <i>originator</i>, <i>person
                responsible</i> and <i>source</i> are among the many near
              synonyms for <i>creator</i>. And of course those examples are all
              just in a single language. The task of finding and processing
              relevant data among the vast amounts available on the Web, for
              people and the computer systems they use, is made substantially
              more achievable if different publishers use the same terms as each
              other, or rather, use <em>common identifers</em> for the terms
              used, however those terms are presented to humans. Only in this
              way can the same tools and methods be used for multiple tasks.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Metadata <em class="rfc2119">must</em> be provided using
              standard vocabularies.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Metadata is best provided using RDF vocabularies. Each term in an
              RDF vocabulary has its own HTTP URI to which labels and
              descriptions in multiple languages can be attached. If labels are
              not provided in your language, you can add them. If your context
              demands that a term be specialized, you can create a sub class or
              sub property but retain the benefits of the original vocabulariy's
              semantics.</p>
            <p>Detailed advice on the best practices for the selection, use and
              extension of vocabularies is provided in Best Practices for
              Publishing Linked Data [[LD-BP]].</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that standard vocabularies have been used wherever
              possible. In particular mark as an error instances where
              vocabularies such as [[DC-TERMS]] and [[VOCAB-DCAT]] could have
              been used but were not.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
          </section>
        </div>
        <div class="issue">
          <p> Bernadette: The intended outcome of this BP should be reviewed. I
            think the intended outcome should reflect what do we expect to be
            possible when the BP is applied. The approach to implementation should also be reviewed. I suggest
            to remove the first paragraph.</p>
          <p><a href="https://www.w3.org/2013/dwbp/track/issues/122">Tracker
              Issue 122</a></p>
        </div>
        <!-- end of BP -->
        <!-- begin  Metadata Documentation BP -->
        <div class="practice">
          <p><span id="MetadataDocum" class="practicelab">Document metadata </span></p>
          <p class="practicedesc">The metadata vocabularies used, and any lists
            of allowed values, <em class="rfc2119">should</em> be documented.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The use of standardized vocabularies is a crucial step towards
              interoperability but there is almost always a choice of
              vocabularies that can be used to achieve a given task. In addition
              there are often multiple ways of using a single vocabulary. For
              example, the value of <code>dcterms:spatial</code> should be a
              URI but those provided by <a href="http://www.geonames.org/">geonames</a>,
              <a href="http://dbpedia.org/">dbpedia</a> and <a href="http://www.wikidata.org/">wikidata</a>
              are just three possible sources of such URIs. Ensuring that the
              value of a property is always drawn from a controlled list of
              allowed values, such as a code list, helps interoperability but it
              may be that some of the same values occur in multiple lists. While
              it may be obvious to at least some potential users which
              vocabularies have been used and how they have been used,
              documenting this can often make the policies used more explicit,
              thereby reducing surprises and increasing confidence among users.</p>
            <p>Documentation is particularly important where vocabularies have
              been created or extended from existing standards (see <a href="dataVocabularies">Data
                Vocabularies</a>).</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Vocabularies and controlled lists used to provide metadata <em class="rfc2119">should</em>
              be documented.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>A description of the metadata used should form part of the
              overall description of the data.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that the provision of metadata follows a defined pattern or
              policy. It may be possible to machine-test this using the work of
              the <a href="http://www.w3.org/2014/data-shapes/">RDF Data Shapes</a>
              Working Group.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataDocum">R-MetadataDocum</a>
            </p>
          </section>
        </div>
        <div class="issue">
          <p> Bernadette: I suggest to remove this BP. I think this BP is
            redundant with Document vocabularies BP and Provide
            metadata in different formats BP.</p>
          <p><a href="https://www.w3.org/2013/dwbp/track/issues/120">Tracker
              Issue 120</a></p>
        </div>
        <!-- end of BP -->
        <!-- begin Discovery Metadata BP -->
        <div class="practice">
          <p><span id="DiscoveryMetadata" class="practicelab">Provide discovery
              metadata</span></p>
         
          <p class="practicedesc">The overall features of a dataset <em class="rfc2119">must</em>
            be described by metadata.</p>
           <p>This best practice is a specialization of the higher level <a href="#ProvideMetadata">Provide
                Metadata</a> best practice. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>In order to be discoverable on the Web, typically through a
              search engine or a data portal's own search function, it is
              essential to provide the kind of information that such tools need
              explicitly. Unlike a natural language document that, to a greater
              or lesser extent, can be processed and its content 'understood,' a
              dataset must be described and it's that description that forms the
              basis of any classification, or indexing.</p>
            
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Search tools <em class="rfc2119">must</em> be able to discover
              datasets.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The vocabulary recommended by W3C is the Data Catalog Vocabulary
              [[VOCAB-DCAT]].</p>
            <p>This provides a framework in which datasets can be described as
              abstract entities with one or more distributions, that is, means
              of accessing the data. This might be through one or more downloads
              or APIs. Aspects covered include:</p>
            <ul>
              <li>The <strong>title</strong> and a <strong>description</strong>
                of the data.</li>
              <li>The <strong>format(s)</strong> in which the data be
                downloaded (e.g. XML, CSV, TSV, JSON, JSON-LD, RDF/XML, Turtle,
                N-Triples etc.)</li>
              <li>Any <strong>variants</strong> (e.g. different human-language
                translations) of data.</li>
              <li><strong>Access mechanisms</strong> though which the data be
                accessed, e.g. SPARQL endpoints, Linked Data Platform, REST
                interfaces, SOAP-based web services, etc. (see <a href="#access">Data
                  Access</a>). </li>
            </ul>
            <p>See also <a href="#AdministrativeMetadata">Provide
                Administrative Metadata</a></p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>A human test might simply be to use an appropriate search tool
              and check that the dataset is discoverable as expected since that
              is the intended outcome. However, a more structured test would be
              to ensure that the basic metadata fields listed above are filled.
              It may be possible to machine-test this using the work of the <a

                href="http://www.w3.org/2014/data-shapes/">RDF Data Shapes</a>
              Working Group.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin Administrative Metadata BP -->
        <div class="practice">
          <p><span id="AdministrativeMetadata" class="practicelab">Provide
              administrative metadata</span></p>
          <p class="practicedesc">The origin and terms of use of a dataset <em

              class="rfc2119">must</em> be described by metadata.</p>
           <p>This best practice is a specialization of the higher level <a href="#ProvideMetadata">Provide
                Metadata</a> best practice </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Once a potential user has <a href="#DiscoveryMetadata">discovered</a>
              a dataset, the next questions are ones such as: do I trust it? Am
              I allowed to use it? Will it be updated? Who is maintaining it?
              And so on. The more information that is provided, the better able
              a potential user will be to decide whether he/she will actually
              use the data or not.</p>
           
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Users <em class="rfc2119">must</em> be able to assess the
              availability, trustworthiness and usefulness of the data in their
              own context.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The Data Catalog Vocabulary [[VOCAB-DCAT]] provides the basic
              terms necessary for this metadata but this can be enriched using
              the Provenance Ontology [[PROV-O]] and more. Aim to provide
              information such as:</p>
            <ul>
              <li><strong>Rights/License information</strong> (see <a href="#licenses">Data
                  Licenses</a>).</li>
              <li><strong>Provenance</strong> (see <a href="#provenance">Data
                  Provenance</a> and <a href="#quality">Data Quality</a>).</li>
              <li><strong>Review information</strong> such as feedback from data
                users about how useful the data was. Did they rate it as good
                quality data? What was their rating?</li>
              <li><strong>Examples of use by others</strong> including links to
                data mash-ups and visualizations, links to other datasets that
                were used in combination to achieve a particular purpose etc.</li>
              <li>A <strong>contact point</strong> for the person or
                organization responsible for the data.</li>
            </ul>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>More detailed tests are provided for <a href="#licenses">Data
                Licenses</a>, <a href="#provenance">Data Provenance</a>, <a href="#quality">Data
                Quality</a> and <a href="#feedback">Feedback</a>. Apart from a
              human check that other administrative data has been provided, it
              may be possible to machine-test this using the work of the <a href="http://www.w3.org/2014/data-shapes/">RDF
                Data Shapes</a> Working Group.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin Locale Parameters BP -->
        <div class="practice">
          <p><span id="LocaleParametersMetadata" class="practicelab">Provide
              locale parameters metadata </span></p>
          <p class="practicedesc">Information about locale parameters (date,
            time, and number formats, language) <em class="rfc2119">should</em>
            be made available. </p>
          <p>This best practice is a specialization of the higher level <a href="#ProvideMetadata">Provide
                Metadata</a> best practice </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Some data fields differ subtly but significantly with changes in
              locale. Providing information about the locality for which the
              data is currently published aids data users in interpreting its
              meaning. Date, time, and number formats can have very different
              meanings, despite similar appearances. Making the language
              explicit allows users to determine how readily they can work with
              the data and may enable automated translation services.</p>
            
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Users working with the data in a locale that differs from that in
              which it was originally published <em class="rfc2119">should</em>
              be able to interpret the meaning of the data accurately. Errors in
              dates, times, and numbers will be avoided.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide locale metadata for date, time, and number fields, and
              include the language in which the data is published in the dataset
              metadata. Where an international format specification exists,
              e.g., ISO 8601 for dates and times, use it. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that the metadata for the dataset itself includes the
              language in which it is published and that all numeric, date, and
              time fields have locale metadata provided either with each field
              or as a general rule. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatLocalize">R-FormatLocalize</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a></p>
          </section>
        </div>
        <!-- end of Locale Parameters BP -->
      
        <div class="issue">
          <p> Bernadette: Review the specialization hierarchy between Provide Metadata BP and other BP. Provide Data Provenance BP, Provide Data License BP and Provide 
            Data Quality information BP should be a specialization of Provide Metadata BP or Provide Administrative Metadata BP? ). </p>
        </div>
      </section>
      <!-- end of Metadata -->
      <!-- begin of Data Identification -->
      <section id="dataIdentification">
        <h3>Data Identification</h3>
        <p>Identifiers are simple conventions of labels that allow us to
          distinguish what is being identified from any other thing. Identifiers
          have being extensively used in every information system, making possible
          to refer to any particular element. On the web, a friendly and uniform 
          system of identification will be required to enable data persistency and
          reuse, being a crucial element for the process of data sharing and 
          connecting.</p> 
           <!-- begin of Unique Identifiers BP -->
        <div class="practice">
          <p><span id="ProvideUniqueIdentifiers" class="practicelab">Provide
              unique identifiers</span></p>
          <p class="practicedesc">Each data resource <em class="rfc2119">must</em>
            be clearly associated with an unique identifier that represents it. </p>
          <div class="axioms">
            <p class="subhead">Why</p>
            <p>Just by adopting a common identification system we are making possible basic data identification and comparison processes by the different stakeholders in a reliable way. These will be essential pre-conditions for proper data management and to facilitate reuse.</p>
          </div>
          <div class="description">
            <p class="subhead">Intended outcome</p>
            <p>A number of basic requirements <em class="rfc2119">should</em> be fulfilled during the definition of an identification system:</p>
	    <ol>
		<li>Ensure that any data resource can be identified by its unique identifier.</li>
		<li>The resource identifier needs to remain persistent along time, regardless the status of the associated resource.</li>
		<li>Use always a consistent and uniform, but also flexible and extensible, structure for the composition of identifiers.</li>
		<li>Identifiers should remain as much neutral as possible (technically, idiomatically, culturally, semantically, etc.)<li>
	   </ol>
          </div>
          <div class="how">
            <p class="subhead">Possible Approach to Implementation</p>
	     <p>The architecture of the World Wide Web [[WEBARCH]] is based on
              links between resources based on a single global identification system for this purpose: the 
		[[URI]]. URIs are a cornerstone of Web architecture, providing identification 
		for people, places or concepts that is common across the Web.</p>
	    <p>Some best practices to adopt while using URIs as a data identification system are:</p> 
		<ul>
		<li>Associate every data resource with an unique identifier using a representational URI.</li>
		<li>Use the HTTP protocol to ensure that the resolution of any URI on the Web is possible.</li>
		<li>When someone looks up an identifier URI, provide always useful information or metadata.</li>
		<li>Build standard URIs that follow a well-defined and extensible scheme or pattern to provide consistency and uniformity.</li>
		<li>Avoid broken URIs. In the event that a resource has been modified or deleted, 
		those changes must be communicated using the appropriate [[HTTP status codes]]. 
		If the resource has change location HTTP 3XX codes should be used, 
		whereas if the resource has been deleted a HTTP 410 code will be used. <li>
		<li>Do not expose information on the technical implementation of the resources represented by the URI. 
		Any information about the underlying technology should be omitted (e.g. file extensions).</li>
		</ul>
          </div>
          <div class="test">
            <p class="subhead">How to Test</p>
            <p>Verify that there is a documented scheme of web identifiers for the data in question. For any of the existing identifiers test that the associated data can always be retrieved by means of its identifier and in a technologically neutral way.</p>
          </div>
          <div class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a></p>
          </div>
        </div>
        <!-- end of Unique Identifiers BP --> </section>
      <!-- end of Data Identification -->
      <!-- begin of Data Formats -->
      <section id="dataFormats">
        <h3>Data Formats</h3>
        <p>Best practices on data formats include considerations on making data
          available in multiple open and machine readable formats for example
          RDF and JSON. In addition this section will include guidance on
          preferred data formats for example preferred formats for date, string
          and numbers. Guidance will also be provided on expressing data in
          multiple languages. While mentioned in the use case document as
          challenge, the best practices document should not make recommendations
          regarding the formats of source data for example database dumps,
          spreadsheets. It is expected that data sources for data on the web
          will continue to be in multiple formats.</p>
        <!-- begin of Machine-Readable Standardized Format BP -->
        <div class="practice">
          <p><span id="MachineReadableStandardizedFormat" class="practicelab">Use
              machine-readable standardized formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">must</em> be
            available in a machine-readable standardized format that is adequate
            for its intended or potential use. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> As data becomes more ubiquitous, and datasets become larger and
              more complex, processing by computers becomes ever more crucial.
              Posting data in a format that is not machine readable places
              severe limitations on the continuing usefulness of the data. Using
              nonstandard formats is costly and inefficient, and the data may
              lose meaning as it is transformed. On the other hand, standardized
              formats enable interoperability as well as future uses, such as
              remixing or visualization, many of which cannot be anticipated
              when the data is first published.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> A machine <em class="rfc2119">must</em> be able to: </p>
            <ol>
              <li> Open and read the data using commonly available software
                packages. </li>
              <li> Process the data. </li>
              <li> Store the data for future use.</li>
            </ol>
            <p></p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Consider which formats potential users of the data are most
              likely to have the necessary tools to parse. proprietary or
              (preferably) non-proprietary formats, including but not limited to
              MS Excel, CSV, NetCDF, XML, JSON and RDF. Standard data types as
              well as the use of standard data vocabularies will better enable
              machines to process the data.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that the format conforms to a known machine-readable
              format specification in current use among anticipated data users.
            </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMachineRead">R-FormatMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatStandardized">R-FormatStandardized</a></p>
          </section>
        </div>
        <!-- end of Machine-Readable Standardized FormatBP -->
        <!-- begin of Open Format BP -->
        <div class="practice">
          <p><span id="OpenFormat" class="practicelab">Use open formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            availabe in a nonproprietary format. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Open formats are usable by anyone. Proprietary formats may be
              difficult or impractical for some data users to view or parse.
              Thus, the use of open formats increases the possibilities for use
              and reuse of data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Any person who wants to use or reuse the data <em class="rfc2119">should</em>
              be able to do so without investment in proprietary software.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Make data available in open formats including but not limited to
              CSV, Turtle, NetCDF and JSON.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check if it is possible to read, process, and store the data
              without using any proprietary software package. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatOpen">R-FormatOpen</a></p>
          </section>
        </div>
        <!-- end of Open Formats BP -->
        <!-- begin of Multiple Formats BP -->
        <div class="practice">
          <p><span id="MultipleFormats" class="practicelab">Provide data in
              multiple formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            availabe in multiple formats. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Providing data in more than one format reduces costs incurred in
              data transformation. It also minimizes the possibility of
              introducing errors in the process of transformation. If many users
              would need to transform the data into a specific format,
              publishing the data in that format from the beginning saves time
              and money and prevents errors many times over. Lastly it increases
              the number of tools and applications that can process the data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Users <em class="rfc2119">should</em> be able to work with the
              data without transforming it. More users will attempt to use the
              data.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Consider the formats most likely to be needed by intended users,
              and consider alternatives that are likely to be useful in the
              future. Data publishers must balance the effort required to make
              the data available in many formats, but providing at least one
              alternative will greatly increase the usability of the data.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that the complete dataset is available in more than one
              format.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMultiple">R-FormatMultiple</a></p>
          </section>
        </div>
        <!-- end of Multiple Formats BP --> </section>
      <!-- end of Data Formats -->
      <!-- begin of Data Vocabularies -->
      <section id="dataVocabularies">
        <h3>Data Vocabularies</h3>
        <p>Datasets often resort to a range of vocabularies in the data they
          contain: data is entered or captured in a controlled way, i.e.,
          positions in a data graph (or column in a relationship table) are
          explicitly defined, the name of a person, the subject of a book, a
          relationship ‚Äúknows‚Äù between two persons. Additionally, for certain
          positions, the values used should come from a limited set of
          pre-existing resources: for example object types, roles of a person,
          countries in a geographic area, or possible subjects for books. Such
          vocabularies ensure a level of control, standardization and
          interoperability in the data. They can also provide a way to easily
          create richer data. Say, a dataset contains a reference to a concept
          described in several languages. This reference allows applications to
          localize their display of their search depending on the language of
          the user.</p>
        <p>According to W3C, <a href="http://www.w3.org/standards/semanticweb/ontology">vocabularies</a>
          define the concepts and relationships (also referred to as ‚Äúterms‚Äù)
          used to describe and represent an area of concern. Vocabularies are
          used to classify the terms that can be used in a particular
          application, characterize possible relationships, and define possible
          constraints on using those terms. Several categories of vocabularies
          have been coined, e.g., ontology, controlled vocabularies, thesaurus,
          taxonomy, semantic network.</p>
        <p>There is no strict division between the artefacts refered to by these
          names. ‚ÄúOntology‚Äù tends however to denote the vocabularies of classes
          and properties that structure the descriptions of resources in
          (linked) datasets. In relational databases, these correspond to the
          names of tables and columns; in XML, they correspond to the elements
          defined by an XML Schema. Ontologies are the key building blocks for
          inference techniques on the Semantic Web. The first means offered by
          W3C for creating (‚Äúlight-weight‚Äù) ontologies is the <a href="http://www.w3.org/standards/techs/rdf#w3c_all">RDF
            Schema</a> language. It is possible to define more complex
          (‚Äúheavy-weight‚Äù) ontologies with advanced axioms using languages such
          as The Web Ontology Language <a href="http://www.w3.org/standards/techs/owl#w3c_all">OWL</a>.
        </p>
        <p>On the other hand, ‚Äúcontrolled vocabularies‚Äù, ‚Äúconcept schemes‚Äù,
          ‚Äúknowledge organization systems‚Äù enumerate and define resources that
          can be employed in the descriptions made with ontologies. A concept
          from a thesaurus, say, ‚Äúarchitecture‚Äù, will for example be used in the
          subject field for a book description (where ‚Äúsubject‚Äù has been defined
          in an ontology for books). For defining the terms in these
          vocabularies, complex formalisms are most often not needed. Simpler
          models have thus been proposed to represent and exchange them on the
          web, such as W3C's Simple Knowledge Organization System (<a href="http://www.w3.org/standards/techs/skos#w3c_all">SKOS</a>).</p>
        <p>This section presents best practices for data vocabularies accessible
          as URI sets on the Web, which are applicable to any kind of
          vocabulary.</p>
        <!-- begin of Document Vocabularies BP -->
        <div class="practice">
          <p><span id="DocumentVocabularies" class="practicelab"> Document
              vocabularies </span></p>
          <p class="practicedesc"> Vocabularies <em class="rfc2119">should</em>
            be clearly documented. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> A documentation defines what is within the vocabulary and the
              better is the documentation the higher is possibility of reuse the
              vocabulary and the datasets built with it. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Humans <em class="rfc2119">should</em> be able to understand
              the vocabulary. </p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> A vocabulary may be published together with human-readable Web
              pages, as detailed in the recipes for serving vocabularies with
              HTML documents in the <a href="http://www.w3.org/TR/swbp-vocab-pub/">Best
                Practice Recipes for Publishing RDF Vocabularies</a>. Elements
              from the vocabulary are defined with attributes containing
              human-understandable labels and definitions, such as rdfs:label,
              rdfs:comment, dc:description, skos:prefLabel, skos:altLabel,
              skos:note, skos:definition, skos:example, etc.;</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that a human user can understand the documentation
              associated with a vocabulary. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabDocum">R-VocabDocum</a>
            </p>
          </section>
        </div>
        <!-- end of Document Vocabularies BP -->
        <!-- begin of Share Open Vocabularies BP -->
        <div class="practice">
          <p><span id="ShareOpenVocabularies" class="practicelab"> Share
              vocabularies in an open way </span></p>
          <p class="practicedesc"> Vocabularies <em class="rfc2119">should</em>
            be shared in an open way </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Sharing vocabularies in an open way may increase the usage of a
              data vocabulary and help to understand the relationships among
              different vocabularies.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Any person who wants to use or reuse a vocabulary <em class="rfc2119">should</em>
              be able to do so. </p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide the vocabulary under an open license such as <a href="http://xmlns.com/foaf/spec/">FOAF</a>'s
              <a href="http://creativecommons.org/licenses/by/1.0/">Creative
                Commons Attribution License</a>. Create entries for the
              vocabulary in repositories such as <a href="http://lov.okfn.org/">LOV</a>,
              <a href="http://prefix.cc">Prefix.cc</a>, <a href="http://bioportal.bioontology.org/">Bioportal</a>
              or <a href="https://joinup.ec.europa.eu/catalogue/repository">Joinup</a><a>.</a></p>
            <a> </a></section>
          <a>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p> Check that an open license is available looking for URL or
                link to the document where the copyright is provided. </p>
            </section>
          </a>
          <section class="ucr"><a>
              <p class="subhead">Evidence</p>
            </a>
            <p><a><span>Relevant requirements</span>: </a><a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabOpen">R-VocabOpen</a>
            </p>
          </section>
        </div>
        <!-- end of Share Open Vocabularies BP -->
        <!-- begin of BP -->
        <!--<div class="practice">
          <p><span id="VersioningVocabularies" class="practicelab"> Vocabulary              versioning </span></p>
          <p class="practicedesc"> Vocabularies <em class="rfc2119">should</em>            include versioning information </p>
          <section class="axioms">            <p class="subhead">Why</p>
            <p>Because it guarantees compatibility over time; Versioning              information provides a way to compare different versions of the
              vocabulary in order to be reused;</p>          </section>
          <section class="description">            <p class="subhead">What</p>
            <p> </p>          </section>
          <section class="outcome">            <p class="subhead">Intended Outcome</p>
            <p>Humans can make changes in a compatible way and machines can              interoperate data consistently; </p>
          </section>          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>            <p> Apply the versioning policy; </p>
          </section>          <section class="test">
            <p class="subhead">How to Test</p>            <p> Different versions of a vocabulary can be easily identified; </p>
          </section>          <section class="ucr">
            <p class="subhead">Evidence</p>            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabVersion">R-VocabVersion</a>
            </p>          </section>
        </div>         <!-- end of BP -->
        <!-- begin of Reuse Vocabularies BP -->
        <!-- <div class="practice">
          <p><span id="ReusingVocabularies" class="practicelab"> Reuse              vocabularies </span></p>
          <p class="practicedesc"> Existing reference vocabularies <em class="rfc2119">should</em>            be reused where possible </p>
          <section class="axioms">            <p class="subhead">Why</p>
            <p> Reusing vocabularies provides a way to support interoperability and              reduces redundancies between vocabularies which helps data
              creation and re-use;</p>          </section>
          <section class="outcome">            <p class="subhead">Intended Outcome</p>
            <p>Datasets (and vocabularies) use as much as possible the same core              vocabularies; </p>
          </section>          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>            <p> </p>
          </section>          <section class="test">
            <p class="subhead">How to Test</p>            <p> </p>
          </section>          <section class="ucr">
            <p class="subhead">Evidence</p>            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>
            </p>          </section>
        </div>        <!-- end of BP -->
        <!-- begin of Not Over formalize Vocabularies BP -->
        <div class="practice">
          <p><span id="NotOverformalizeVocabularies" class="practicelab">Do not
              overformalize vocabularies</span></p>
          <p class="practicedesc">When creating or re-using a vocabulary for an
            application, a data publisher <em class="rfc2119">should</em> try
            to avoid using a knowledge representation language that is
            unnecessarily complex for the application at hand.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Unnecessarily complex vocabularies cost more efforts to produce
              and are less likely to be re-used in other datasets. Resources
              that are equiped with a strong, formal semantics are less clear
              (harder to understand) for any data re-user. It will hamper
              comparing and linking across datasets. Highly formalized data is
              harder to exploit by inference engines: using an OWL class in a
              position where a SKOS concept is enough or using OWL classes with
              complex OWL axioms raises the formal complexity of the data (cf. <a

                href="http://www.w3.org/TR/owl2-profiles/">OWL Profiles</a>).</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>The data <em class="rfc2119">should</em> not be more complex to
              produce and re-use than what is necessary;</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Identify the ‚Äúrole‚Äù played by the vocabulary for the datasets,
              say, providing classes and properties used to type resources and
              provide the predicates for RDF statements, as opposed to providing
              simple concepts or codes that are used for representing attributes
              of the resources described in a dataset. Represent vocabularies
              simpler data models, e.g. SKOS, as opposed to formal ontology
              languages like OWL, when simpler models are enough. See for
              example <a href="http://www.w3.org/TR/vocab-data-cube/#schemes">Concept
                schemes and code lists</a> are used in the RDF Data Cube
              recommendation</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Applying an inference engine does not produce too many statements
              that are unnecessary for an application.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabDocum">R-VocabDocum</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityComparable">R-QualityComparable</a>
            </p>
          </section>
        </div>
        <!-- end of Not Over formalize Vocabularies BP -->
        <h4> How to find vocabularies ? </h4>
        <p> In order to be possible the reuse of vocabularies, it is important
          to provide ways to find them, when they are available on the Web. The
          can be done by using different approaches, such as: </p>
        <ol>
          <li> Search tools: <a href="http://ws.nju.edu.cn/falcons/objectsearch/index.jsp">
              Falcons </a> , <a href="http://watson.kmi.open.ac.uk/WatsonWUI/">Watson</a>,
            <a href="http://sindice.com/"> Sindice</a>, <a href="http://swoogle.umbc.edu/">Swoogle</a>,
            and others; </li>
          <li> Repositories: <a href="http://lov.okfn.org/dataset/lov/">LOV</a>,
            <a href="http://bioportal.bioontology.org/">BioPortal</a>, and <a href="https://joinup.ec.europa.eu/catalogue/repository">JoinUp</a>;
          </li>
          <li> <a href="http://www.w3.org/standards/">W3C Standards</a>; </li>
          <li> <a href="http://www.w3.org/2005/Incubator/lld/XGR-lld-vocabdataset-20111025/">Library
              Linked Data Incubator Group</a>. </li>
        </ol>
        <h3>How to choose vocabularies?</h3>
        <p> It is very important to know how to choose the vocabulary to be
          reused. For doing this, see <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Vocabulary
            Checklist</a> </p>
        <div class="issue"> Antoine: The <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Vocabulary
            Checklist</a> from the Best Practices for Publishing Linked Data
          overlaps quite a lot with the best practices from this section. Should
          we clarify the difference in positioning? Is there one? 
        <p><a href="https://www.w3.org/2013/dwbp/track/issues/124">Tracker
              Issue 124</a></p></div>
      </section>
      <div class="issue">
        <p> Bernadette: I removed the Vocabulary versioning BP because it was
          too vague. The requirement <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabVersion">R-VocabVersion</a>
          will be associated to one of the Data Versioning BP.  I removed the Reuse Vocabulary BP because it was too vague. </p>
        </div>
      <!-- end of Data Vocabularies -->
      <!-- begin of Data Licenses -->
      <section id="licenses">
        <h3>Data Licenses</h3>
        <p>License is a piece of information very useful to be attached to data
          on the Web. As defined by [[DC-TERMS]], a license is a legal document
          giving official permission to do something with the data to which it
          is associated. According to the type of license adopted by the
          publisher, there might be more or less restrictions on sharing and
          reusing data. In the context of the Data on the Web, the license of a
          dataset can be specified within the data, or outside of it, in a
          separate document linking the data. However, in line with the Linked
          Data principles, licenses for such datasets <em class="rfc2119">should</em>
          be specified in RDF, for instance through the Dublin Core vocabulary
          [[DC-TERMS]] </p>
        <!-- begin of Provide Data License BP -->
        <div class="practice">
          <p><span class="practicelab">Provide data license</span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            associated with a license.</p>
          <div class="axioms">
            <p class="subhead">Why</p>
            <p> Licenses are essential to determine what are the permissions
              when reusing data by consumers or other publishers. </p>
            <p>This best practice is a specialization of the higher level <a href="#ProvideMetadata">Provide
                Metadata</a> best practice </p>
          </div>
          <div class="description">
            <p class="subhead">Intended outcome</p>
            <p>Data consumers <em class="rfc2119">must</em> be able to: </p>
            <ol>
              <li> Discover the permission for reusing any piece of data; </li>
              <li> Understand the nature of the license, i.e. what are the
                restrictions applied to the license attached to the data; </li>
              <li> Quickly understand if the data is open for reuse. </li>
            </ol>
            <p></p>
          </div>
          <div class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Data license <em class="rfc2119">should</em> be clearly stated
              either in the data itself or in an external document linked to the
              data. </p>
            <ol>
              <li>Depending on the formats used to publish the data, publishers
                <em class="rfc2119">should</em> provide a URL or link to the
                document with the copyright statements.</li>
              <li> If a publisher adds a dataset to a catalog, such as the Data
                Hub, publisher <em class="rfc2119">should</em> make sure which
                license applied to the dataset within that catalog. This gives
                people searching the catalog a quick and easy way of seeing that
                they will be able to reuse the dataset. </li>
            </ol>
          </div>
          <div class="test">
            <p class="subhead">How to Test</p>
            <p> Humans can check the presence of license looking for URL or link
              to the document with the copyright is provided.</p>
          </div>
          <div class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant use cases</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseAvailable">R-LicenseAvailable</a></p>
          </div>
        </div>
        <!-- end of Data License BP -->
        <!-- begin of machine detectable license BP -->
        <div class="practice">
          <p><span class="practicelab">Provide machine detectable license</span></p>
          <p class="practicedesc">A License <em class="rfc2119">should</em> be
            detectable by machines</p>
          <div class="axioms">
            <p class="subhead">Why</p>
            <p> By means of machine-readable licenses, machines, including
              search engines, can be set up to automatically harvest data that
              has an associated license. </p>
            <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataForms">Provide
                metadata in different formats</a> best practice. </p>
          </div>
          <div class="description">
            <p class="subhead">Intended outcome</p>
            <p>Machines <em class="rfc2119">should</em> be able to
              automatically detect whether a given dataset does or does not
              carry a license.</p>
          </div>
          <div class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Publisher <em class="rfc2119">should</em> link license to data
              by exploiting one or more among the following approaches: </p>
            <ol>
              <li> Insert the reference to a license in a property such as <code>dct:license</code>
                at the metadata level of the data in RDF or RDFa. Alternative
                properties which can be considered includes <code>http://creativecommons.org/ns#license</code>,
                <code>http://schema.org/license</code>, or <code>http://www.w3.org/1999/xhtml/vocab#license</code>.
              </li>
              <li> Provide a HTTP Link Header with a <code>@rel</code> value of
                license [[RFC4946]] </li>
            </ol>
            <p> For open data licensing, more guides can be found at
              [[ODI-LICENSING]]. </p>
          </div>
          <div class="test">
            <p class="subhead">How to Test</p>
            <p> The test for the presence of detectable license can be done by:
            </p>
            <p> </p>
            <ol>
              <li> parsing the data looking for <code>dcterms:license</code>
                property, or any vocabulary describing the rights associated
                with a dataset; </li>
              <li> looking for a link element or HTTP Link Header with a <code>@rel</code>
                value of license [[RFC4946]].</li>
            </ol>
          </div>
          <div class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant use cases</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseAvailable">R-LicenseAvailable</a>
              and <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>
            </p>
          </div>
        </div>
        <!-- end of machine detectable license BP --> </section>
      <!-- end of Data Licenses -->
      <!-- begin of Data Provenance -->
      <section id="provenance">
        <h3>Data Provenance</h3>
        <p>Provenance originates from the French term provenir (to come from),
          which is used to describe the curation process of artwork as art is
          passed from owner to owner. Data provenance, in a similar way, is
          metadata, that allows data providers to pass details about the data
          history to data users. Provenance becomes particularly important when
          data is shared between collaborators who might not have direct contact
          with one another either due to proximity or because the published data
          outlives the lifespan of the data provider projects or organizations.</p>
        <p>The Web brings together business, engineering, and scientific
          communities creating collaborative opportunities that were previously
          unimaginable. The challenge is publishing data on the Web is providing
          an appropriate level of detail about its origin. The data publishers
          may not necessarily be the data provider and so collecting and
          conveying this corresponding metadata is particularly important.
          Without provenance, consumers have no inherent way to trust the
          integrity and credibility of the data being shared. Data publishers in
          turn need to be aware of the needs of prospective consumer communities
          to know how much provenance detail is appropriate. </p>
        <p>Fortunately, the W3C community offers the Provenance Ontology
          [[PROV-O]] so that data publishers can formally describe data
          provenance and methodologies so that consumers can query and use
          provenance. </p>
        <!-- begin of Provide Data Provenance BP -->
        <div class="practice">
          <p><span id="ProvideDataProvenance" class="practicelab">Provide data
              provenance</span></p>
          <p class="practicedesc">Data provenance information <em class="rfc2119">should</em>
            be available. </p>
          <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataForms">Provide
                metadata in different formats</a> best practice. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Without accessible data provenance, consumers will not know the
              origin or history of the published data.</p>
            <p>Data provenance is metadata that corresponds to data. Data
              provenance relies upon existing vocabularies that make provenance
              easily identifiable such as the Provenance Ontology [[PROV-O]].</p>
            
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>If data is published with data provenance, then the data
              provenance <em class="rfc2119">must</em> provide a URL reference
              to the published data.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Data provenance can be published in a number of ways:</p>
            <ol>
              <li>Use the Provenance Ontology [[PROV-O]] to describe data
                provenance.</li>
              <li>Use an appropriate level of detail that will be meaningful to
                the intended audience. </li>
              <li>Write the data provenance in either a machine readable form
                such as Turtle or RDF/XML or embed provenance in an HTML page
                using [[JSON-LD]], or [[HTML-RDFA]] </li>
              <li>Verify that the data provenance references published data</li>
            </ol>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Use a [[PROV-O]] validator or inspect the provenance in the HTML
              page. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-ProvAvailable">R-ProvAvailable</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>
            </p>
          </section>
        </div>
        <!-- end of Provide Data Provenance BP --> </section>
      <!-- end of Data Provenance -->
      <!-- begin of Data Quality -->
      <section id="quality">
        <h3>Data Quality</h3>
        <p>Data quality is commonly defined as ‚Äúfitness for use‚Äù for a specific
          application or use case. It can affect the potentiality of the
          application that use data, as a consequence, its inclusion in the data
          publishing and consumption pipelines is of primary importance. </p>
        <p>Usually, the assessment of quality involves different kinds of
          quality dimensions, each representing groups of characteristics that
          are relevant to publishers and consumers. Measures and metrics are
          defined to assess the quality for each dimension. They are heuristics
          designed to fit specific assessment situations and rely on quality
          indicators, namely, pieces of data content, pieces of data
          meta-information, human ratings, which give indication about the
          suitability of data for some intended use. </p>
        <p>Dimensions and metrics to adopt might largely depend on the specific
          application scenario, or even on the data domain. A systematic review
          of dimensions, metrics adopted in the context of Open Linked data can
          be found in the recent literature (e.g., see [[ZAVERI]]). </p>
        <!-- begin of Provide Data Quality BP -->
        <div class="practice">
          <p><span id="ProvideDataQuality" class="practicelab">Provide data
              quality information</span></p>
          <p class="practicedesc">Data Quality information <em class="rfc2119">should</em>
            be available. </p>
          <p>This best practice is a specialization of the higher level <a href="#ProvideMetadata">Provide
                Metadata</a> best practice. </p>
          
          <section class="axioms">
            <p class="subhead">Why</p>
            
              <p>Data quality might seriously affect the suitability of data
                for specific applications. </p>
              <p>Documenting data quality eases in the process of data
                selection increasing the chances of re-use. </p>
            
          </section>
          <section class="description">
            <p class="subhead">What</p>
            <p> As noted above, quality affects the reusability of data.
              Information about quality <em class="rfc2119">should</em> be
              included in dataset metadata since it is precious to assess if
              data fit in with specific purpose. This is pivotal in the Web
              context, where the reuse of data can be even for purposes not
              originally planned by providers. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <ul>
              <li> Humans <em class="rfc2119">should</em> be able to
                read quality info in metadata related to a dataset. </li>
              <li> Computer applications, notably search tools, <em class="rfc2119">should</em> be able to locate and process info
                about quality in metadata. </li>
            </ul>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Depending on application domain, information pertaining to the
              quality can relies on specific quality metrics or feedback-opinion
              and specific quality metadata fields might or not be explicitly
              included in the metadata vocabularies adopted by catalogs.
              Independently from domain-specific peculiarities, quality of data
              <em class="rfc2119">should</em> be documented and known quality
              issues should be explicitly stated in metadata. </p>
            <p> The definition of a Quality Vocabulary is included in the
              activity of the DWBP group in order to support in the
              implementation of this best practice. The Quality Vocabulary is
              foreseen as an extension to DCAT to cover the quality of the data,
              how frequently is it updated, whether it accepts user corrections,
              persistence commitments etc. When used by publishers, this
              vocabulary will foster trust in the data amongst developers. </p>
            
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Checking in dataset metadata if there is any explicit
              description of known quality issues or metric deployed.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p> Information about the relevance of the BP is described by
              requirements documented in <a href="http://w3c.github.io/dwbp/usecasesv1.html">the
                Data on the Web Best Practices Use Cases &amp; Requirements
                document</a>: <a href="https://w3c.github.io/dwbp/usecasesv1.html#h4_can-req-quality">Requirements
                for Data Quality</a></p>
          </section>
          <!-- end of Provide Data Quality BP -->
        </div>
        <div class="issue">
             
              <p>Should we provide more specific/ detailed strategies on how to
                attach quality info in metadata apart from the use of DATA
                QUALITY Vocabulary the group is working on? </p>
           <p><a href="https://www.w3.org/2013/dwbp/track/issues/116">Tracker
                  Issue 116</a></p>
            </div>
       
      </section>
      <!-- end of Data Quality -->
      <!-- begin of Data Granularity -->
      <section id="granularity">
        <h3>Data Granularity</h3>
        <p>The section on granularity</p>
        
      </section>
      <!-- end of Data Granularity -->
      <!-- begin of Sensitive Data -->
      <section id="sensitive">
        <h3>Sensitive Data</h3>
        <p>Sensitive data is any designated data or metadata that is used in
          limited ways and/or intended for limited audiences. Sensitive data may
          include personal data, corporate, or government data and mishandling
          of published sensitive data may lead to damages to individuals or
          organizations. </p>
        <p>To support best practices for publishing sensitive data, data
          publishers <em class="rfc2119">should</em> identify all sensitive
          data, assess the exposure risk, determine the intended usage, data
          user audience and any related usage policies, obtain appropriate
          approval, and determine the appropriate security measures needed to
          taken to protect the data. Appropriate security measures <em class="‚Äúrfc2119‚Äù">should</em>
          also account for secure authentication and use of HTTPS. </p>
        <p>At times, because of sharing policies sensitive data may not be
          available in part or in its entirety. Data unavailability represent
          gaps that may effect the overall analysis of data sets. To account for
          unavailable data, data publishers <em class="rfc2119">should</em>
          publish information about unavoidable data gaps.</p>
        <!-- begin of Preserve Privacy BP -->
        <div class="practice">
          <p><span id="PreservePrivacy" class="practicelab">Preserve person's
              right to privacy </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> not
            infringe a person's right to privacy. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Data publishers <em class="rfc2119">should</em> preserve the
              privacy of individuals where the release of personal information
              would endanger safety (unintended accidents) or security
              (deliberate attack). Privacy information might include: Full name,
              home address, mail address, national identification number, IP
              address (in some cases), vehicle registration plate number,
              driver's license number, face, fingerprints, or handwriting,
              credit card numbers, digital identity, date of birth, birthplace,
              genetic information, telephone number, login name, screen name,
              nickname, health records etc.</p>
          </section>
          <section class="description">
            <p class="subhead">What</p>
            <p>Data publishers <em class="rfc2119">should</em> identify all
              personal data, assess the exposure risk, determine the intended
              usage, data user audience and any related usage policies, obtain
              appropriate approval, and determine the appropriate security
              measures needed to taken to protect the data including secure
              authentication and use of HTTPS for data transmission.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
          </section>
          <p>The data publisher needs to establish a security plan for
            publishing data and metadata. The plan <em class="rfc2119">should</em>
            include preparatory steps to ensure personal data is protected or
            removed prior to publication. All steps need to be followed prior to
            publication of new data or new data formats particularly binary
            formats (word processing, spreadsheet etc) that may embed personal
            metadata in files. </p>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
          </section>
          <p> Identify any personal data exposure risks. Write a security plan
            for publishing data and metadata that includes clear guidelines to
            follow. Prior to publication put security measures in place and
            follow them. In preparation to publication review data to ensure
            compliance. </p>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Write test plan for reviewing, curating and vetting data prior to
              publication.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitivePrivacy">R-SensitivePrivacy</a></p>
          </section>
        </div>
        <!-- end of Preserve Privacy BP -->
        <!-- begin of Preserve Security BP -->
        <div class="practice">
          <p><span id="PreserveSecurity" class="practicelab">Preserve
              organization's security </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> not
            infringe an organization's security (local government, national
            government, business). </p>
          <section class="axioms">
            <p class="subhead">Why</p>
          </section>
          <section class="description">
            <p class="subhead">What</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitiveSecurity">R-SensitiveSecurity</a></p>
          </section>
        </div>
        <!-- end of Preserve Security BP -->
        <div class="practice">
          <p><span id="DataUnavailabilityReference" class="practicelab">Provide
              data unavailability reference </span></p>
          <p class="practicedesc">References to data that is not open, or is
            available under different restrictions to the origin of the
            reference, <em class="rfc2119">should</em> provide context by
            explaining how or by whom the referred to data can be accessed. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Publishing on-line documentation about unavailable data due to
              sensitivity issues provides a means for publishers to identify
              knowledge gaps to consumer communities with a contextual
              explanation.</p>
          </section>
          <section class="description">
            <p class="subhead">What</p>
            <p></p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>By providing an explanation about the unavailability of data consumers
               have a better idea of what data might be missing due to security policies.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>For consumer human usage, data publishers <em class="rfc2119">should</em>
              publish an HTML document that explains data unavailibility. From a
              consumer machine usage perspective, the Web HTML file could
              contain Turtle or JSON-LD (for RDF) or it can be embdedded in the
              HTML page, again as [[JSON-LD]], or [[HTML-RDFA]] or
              [[Microdata]]. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> </p>
            <ul>
              <li>Download a set of data</li>
              <li>Open Web page explaining data unavailability</li>
              <li>Write REST client to extract unavailability from web page</li>
              <li>Determine: Is the explanation sufficient and consistent? </li>
            </ul>
            <p></p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a></p>
          </section>
        </div>
        <!-- end of BP --> </section>
      <!-- end of Data Sensitive -->
      <!-- begin of Data Access -->
      <section id="dataAccess">
        <h3>Data Access</h3>
        <p>Providing an easy access to data on the Web enable both humans and
          machines to take advantage of the benefits of sharing data on top of
          the Web infrastructure. By default, the Web offers access using
          Hypertext Transfer Protocol (HTTP) methods. This provides access to
          data at an atomic transaction level. However, when data is distributed
          across multiple files or requires more sophisticated retrieval methods
          different approaches can be adopted to enable data access, including:
          bulk download and APIs (Application Programming Interfaces). </p>
        <p>One approach is packaging data in bulk using non-proprietary file
          formats(for example zip files or tar files). Using this approach, bulk
          data is generally pre-processed server side where multiple files or
          directory trees of files are provided as one downloadable file. When
          bulk data is being retrieved from non-file system solutions, depending
          on the data user communities, data publisher should offer APIs to
          support a series of retrieval operations representing a single
          transaction.</p>
        <p>For data that is streaming to the Web in ‚Äúreal time‚Äù or ‚Äúnear real
          time‚Äù, data publishers must publish data or use APIs to enable
          immediate access to data, allowing access to critical time sensitive
          data, such as emergency information, weather forecasting data, or
          published system metrics. For all data on the Web, APIs should be
          available to allow third parties to automatically search and retrieve
          data published on the Web. </p>
        <p> This section provides some BP to be followed by data publishers in
          order to enable easy data access for data consumers.</p>
        <!-- begin of BP Bulk Access-->
        <div class="practice">
          <p><span id="BulkAccess" class="practicelab">Provide bulk download </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            available for bulk download. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Bulk access provides a simple way of publishing data encouraging
              data publishers to release full datasets and enabling data
              consumers to download large amounts of data at once. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> It <em class="rfc2119">should</em> be possible to
              download data on the Web in bulk. Data publishers <em class="rfc2119">should</em>
              provide a way either through bulk file formats or APIs for
              consumers to access this type of data.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <ol>
              <li> Create a collection of data files, archive the collection
                using a zip or tar and compress if possible. <br>
                Create a README file describing the contents of the bulk file. <br>
                Make the bulk file available on the Web. </li>
              <li> Create a database or SPARQL endpoint and populate with data.
                <br>
                Create REST service that relies upon the HTTP GET method as a
                wrapper around a database API that performs a complex database
                retrieval transaction. </li>
            </ol>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <ul>
              <li> Try to download the files. </li>
              <li> Try to use REST service. </li>
            </ul>
            <p> </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessBulk">R-AccessBulk</a></p>
          </section>
        </div>
        <!-- end of BP Bulk Access -->
        <!-- begin of BP Bulk Access 2-->
        <div class="practice">
          <p><span id="BulkAccess2" class="practicelab">Follow REST principles
              when designing APIs</span></p>
          <p class="practicedesc">Where there is data accessible throught an
            API, this application programming interface <em class="rfc2119">should</em>
            follow REST (Representational State Transfer) architectural
            approaches. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Considering RESTful architectural aspects when designing an APIs
              can guarantee easier development, use of pre existing
              infrastructure (Web), shorter learning curve for developers that
              want to access data on Web applications. Also, Its a way to assure
              sustainability because "the technologies that make up this
              foundation include the Hypertext Transfer Protocol (HTTP), Uniform
              Resource Identifier (URI), markup languages such as HTML and XML,
              and Web-friendly formats"[[RICHARDSON]]. Furthermore it can
              mitigate the use of specific clients or the need of UDDI use
              (Universal Description, Discovery and Integration).</p>
          </section>
          <section class="description">
            <p class="subhead">What</p>
            <p> APIs are frequently constructed over different approaches, like
              SOAP, for example. For data on the Web context, the architecture
              of the Web itself described at the documentation of REST
              architectural style, offers the same entry for humans and machines
              to access data. If humans already have access to data in URLs, it
              can be also structured for offering multiple representations for
              formats and use content negotiation between applications easily,
              for example. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <ul>
              <li> Machines <em class="rfc2119">should</em> be able  
                to negotiate content using URLs. </li>
              <li> Humans <em class="rfc2119">should</em> be possible 
                 to access data using browser as a client. </li>
            </ul>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p></p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Use API testing tools to compare benefits of implementing RESTful
              design.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="https://w3c.github.io/dwbp/usecasesv1.html#R-AccessBulk">R-AccessBulk</a></p>
          </section>
        </div>
        <!-- end of BP BulkAccess 2-->
        <div class="issue"> Follow REST principles
              when designing APIs BP is incomplete. 
        </div>
        
        <!-- begin of BP Access Real-time-->
        <div class="practice">
          <p><span id="AccessRealTime" class="practicelab">Provide real-time
              access </span></p>
          <p class="practicedesc">Where data is produced in real-time, it <em class="rfc2119">should</em>
            be available on the Web in real-time. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Providing real-time access data enables access to critical time
              sensitive data whenever is required, encouraging the development
              of real-time based applications. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Data <em class="rfc2119">should</em> be available at real time
              or near real time, where real-time means a range from milliseconds
              to a few seconds after the data creation, and near real time is a
              predetermined delay for expected data delivery. </p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Implement a Web API to enable data access either using a live
              streaming data source or mockup a synthetic data source to
              simulate real or near real time data. A mockup could be as simple
              as a looping script that reads data from one file and populates
              the ‚Äúreal time‚Äù source. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <ul>
              <li>Write test client to use real-time access API. </li>
              <li> Start or setup real-time data source that provides a real
                time data date/time stamp.</li>
              <li> Log real time data date/time stamp and record corresponding
                test client date/time stamp.</li>
              <li> Verify time difference between each successful access attempt
                and the real time data date/time stamp.</li>
            </ul>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessRealTime">R-AccessRealTime</a></p>
          </section>
        </div>
        <!-- end of BP Access Real-time-->
        <!-- begin of BP Access Up to date -->
        <div class="practice">
          <p><span id="AccessUptoDate" class="practicelab">Provide data up to
              date </span></p>
          <p class="practicedesc"> Data <em class="rfc2119">must</em> be
            available in an up-to-date manner and the update cycle made
            explicit. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Data on the Web availability should closely coincide with data
              provided at creation time, collection time, or after it has been
              processed or changed. Carefully synchronizing data publication to
              the update cycle encourages data consumer confidence and reuse.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> When new data is provided or data is updated, it <em class="rfc2119">must</em>
              be published to coincide with the data changes.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Implement an API to enable data access. <br>
              When data is provided by bulk access, new files with new data
              should be provided as soon as additional data is created or
              updated. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Write test standard operating procedure for data publisher to
              keep test data on Web site up to date.</p>
            <p> Following standard operating procedure:</p>
            <ul>
              <li> Write test client to access published data. </li>
              <li> Access data and save first copy locally. </li>
              <li> Publish an updated version of data.</li>
              <li> Access data and save second copy locally.</li>
              <li> Compare first copy to second copy to verify change.</li>
            </ul>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessUptodate">R-AccessUptodate</a></p>
          </section>
        </div>
        <!-- end of BP Access Up to date--> </section>
      <!-- end of Data Access -->
      <!-- begin of Data Versioning -->
      <section id="dataVersioning">
        <h3>Data Versioning</h3>
        <!-- begin of provide Versioning Info BP -->
        <div class="practice">
          <p><span id="provideVersioningInfo" class="practicelab">Provide
              Versioning Information</span></p>
          <p class="practicedesc">Data that will be updated over time <em class="rfc2119">should</em>
            be assigned a version number or, at a minimum, a version date, and
            that identifier <em class="rfc2119">should</em> be distributed with
            the data. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Version information makes a dataset uniquely identifiable.
              Uniqueness enables consumers to determine how the data changes
              across time and whether they are working with the latest version
              of a dataset. Good versioning helps them to determine when to
              update to a newer version. Explicit versioning allows for
              repeatability in research, enables comparisons, and prevents
              confusion. Using version numbers that follow a standardized
              approach can also set consumer expectations about how the versions
              differ.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data consumers <em class="rfc2119">should</em> be able to easily
              determine which version of the data they are working with.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Include a version number in the metadata for the dataset. The
              numbering scheme could be multipart, each part representing a
              level of difference from the previous version. For example, a
              change from 1.0 to 1.1 could reflect only changes to data values,
              while a change from 1.0 to 2.0 could reflect changes to the
              schema. Also provide a description of what has changed since the
              previous version. If the data is made available through an API,
              the URI used to request the latest version of the data should not
              change as the versions change, but it should be possible to
              request a specific version through the API.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a unique version number or date is provided with the
              metadata describing the dataset.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:</p>
          </section>
        </div>
        <div class="issue">
          <p>Discuss the possibility of use of the SchemaVer on the
            Implementation of this BP</p>
          <p><a href="https://www.w3.org/2013/dwbp/track/issues/127">Tracker
              Issue 127</a></p>
        </div>
        <!-- end of provide Versioning Info BP -->
        <!-- begin of provide version history BP -->
        <div class="practice">
          <p><span id="provideVersionHistory" class="practicelab">Provide
              version history</span></p>
          <p class="practicedesc">It is <em class="rfc2119">recommended</em>
            that a version history be made available for versioned data.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>In creating applications that use data, it can be helpful to
              understand the variability of that data over time. Interpreting
              the data is also enhanced by an understanding of its dynamics.
              Determining how the various versions of a dataset differ from each
              other is typically very laborious unless a summary of the
              differences is provided.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Users of the data can readily determine which version is of
              interest to them. Data users can quickly understand how the data
              typically changes from version to version.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide a list of published versions and a description for each
              version that explains how it differs from the previous version. An
              API can expose a version history with a single dedicated URL that
              retrieves the latest version of the complete history.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a list of published versions is available, and that
              each version is described.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:</p>
          </section>
        </div>
        <!-- end of provide version history BP -->
        <!-- begin of versions For API BP -->
        <div class="practice">
          <p><span id="versionsForAPI" class="practicelab">Maintain separate
              versions for a data API</span></p>
          <p class="practicedesc">If data is made available through an API, the
            API itself <em class="rfc2119">should</em> be versioned separately
            from the data. Old versions <em class="rfc2119">should</em>
            continue to be available.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Developers need to be made aware of changes to an API so that
              they can update their code to use it. When an API is changed, as
              opposed to when the data it makes available is changed, releasing
              it as a new version makes it possible to gracefully transition
              from the old version to the new one. Keeping the older versions
              available avoids breaking applications that cannot be updated.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Developers should be able to transition easily from one version
              of the API to another. Applications that are impractical to
              transition should continue to work. The API version should not be
              updated when data versions are updated, only when the API itself
              changes, and that should be infrequent.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Release updates to your API under a slightly different base URI
              so that older versions remain available under the previous base
              URI. For example, <a href="http://myapi.org/v1/dogs/alfred">http://myapi.org/v1/dogs/alfred</a>
              retrieves the older version of data about a dog named Alfred, and
              <a href="http://myapi.org/v2/dogs/alfred">http://myapi.org/v2/dogs/alfred</a>
              retrieves the newer version of data about Alfred. Keeping the
              version number as far to the left as possible in the API call
              allows developers to switch to the newer version with the least
              effort.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Existing calls to the API should continue to work when the API is
              updated. New calls to a slightly different base URI should
              retrieve data according to the new rules.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:</p>
          </section>
        </div>
        <!-- end of versions For API BP --> </section>
      <!-- end of Data Versioning -->
      <!-- begin of Data Preservation -->
      <section id="dataPreservation">
        <h3>Data Preservation</h3>
        <p>Data preservation is a well understood and commonly performed tasks
          for static and self-contained data. This commonly includes the
          following steps:</p>
        <ul>
          <li>Ingest the data and assign a persistent identifier to it</li>
          <li>Ensure the data is correctly stored and prevent bit rot</li>
          <li>Provide access to the data and perform format translation if
            needed</li>
        </ul>
        <p>The model most commonly referred to is <a href="http://en.wikipedia.org/wiki/Open_Archival_Information_System">
            Open Archival Information System</a>. Many institutions taking care
          of digital preservation are implementing this model or some variant of
          it. Web pages can be preserved following the same strategies,
          considering a Web site as a static data set that is self-contained and
          can be all snap-shoted and preserved at a fixed time. When it comes to
          Web data some new elements have to be taken into account, namely:</p>
        <ul>
          <li>The persistent identifiers (IRI) used across the Web are related
            to live data that can change</li>
          <li>The meaning of a resource is contextualized by the other resources
            it is linked to</li>
          <li>Documents fetched in HTML, RDF of JSON, for instance, are only one
            of the many possible serialisation of the data they represent</li>
        </ul>
        <p>The preservation of Web data should generaly focus on the
          preservation of the description of entities.</p>
        <!-- begin of list of resources BP -->
        <div class="practice">
          <p><span id="list_resources" class="practicelab">Maintain a list of
              resources described in a dataset</span></p>
          <p class="practicedesc">A dataset <em class="rfc2119">should</em> be
            preserved together with a list of all the resources it describes</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Web data is about the description of resources identified with a
              IRI.It is to be expected that queries made by data consumers will
              resolve around finding a preserved description about a particular
              resource. </p>
            <p>Web data is essentially about the description of entities
              identified by a unique, Web-based, identifier (a URI). Once the
              data is dumped and sent to a institute specialised in digital
              preservation the link with the Web is broken (de-referencing) but
              the role of the URI as a unique identifier still remains. In order
              to increase the usability of preserved dataset dumps it is
              relevant to maintain a list of these identifiers.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>It <em class="rfc2119">should</em> be possible to look for a
              preserved dataset based on the resources contained in it.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The list of resources can be created by the data depositor or the
              digital repository at ingestion time. A dataset dump is scanned
              for all the subject described and this list is stored separately.
              For RDF and JSON-LD, this corresponds to all the resources in the
              "subject" position of statements.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Every resource listed in the resource list <em class="rfc2119">must</em>
              have some kind of description in the dataset</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a></p>
          </section>
        </div>
        <!-- end of list of resources BP -->
        <!-- begin of assess dataset BP -->
        <div class="practice">
          <p><span id="evaluate" class="practicelab">Assess dataset coverage</span></p>
          <p class="practicedesc">The coverage of a dataset <em class="rfc2119">should</em>
            be assessed prior to its preservation</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>A chunk of Web data is by definition dependent on the rest of the
              global graph. This global context influences the meaning of the
              description of the resources found in the dataset. Ideally, the
              preservation of a particular dataset would involve preserving all
              its context. That is the entire Web of Data. </p>
            <p>At ingestion time an evaluation of the linkage of Web data
              dataset dump to already preserved resources is assessed. The
              presence of all the vocabularies and target resources in uses is
              sought in a set of digital archives taking care of preserving Web
              data. Datasets for which very few of the vocabularies used and/or
              resources pointed out are already preserved somewhere should be
              flagged as being at risk.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>An evaluation of the preservation coverage for a given dataset.
              The outcome of this evaluation <em class="rfc2119">should</em> be
              used to take an informed decision concerning the ingestion, or
              not, of the dataset</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The assessement could be performed by the digital preservation
              institute or the dataset depositor. It essentially consists in
              checking whether all the resources used are either already
              preserved somewhere or provided along with the new dataset
              considered for preservation.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Datasets making references to portions of the Web of Data which
              are not preserved <em class="rfc2119">should</em> receive a lower
              score than those using common resources.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a></p>
          </section>
        </div>
        <!-- end of assess dataset BP -->
        <!-- begin of serialisation BP -->
        <div class="practice">
          <p><span id="serialisation" class="practicelab">Use a trusted serialisation format for preserved data dumps</span></p>
          <p class="practicedesc">Data depositors willing to send a datadump for
            long term preservation <em class="rfc2119">must</em> use a well
            established serialisation</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Web data is a abtract data model that can be expressed in
              different ways (RDF, JSON-LD, ...). Using a well established
              serialisation of this data increases its chances of re-use. </p>
            <p>Institute doing digital preservation are tasked with monitoring
              file format obsolescence. Datasets which have been acquired in
              some format some years ago may have to be converted into another
              format in order to still be usable with more modern software (see
              [[ROSENTHAL]]). This tasks can be made more challenge, or even
              impossible, if non standard serialisation formats are used by data
              depositors.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>The dataset can still be read and loaded into a data base even
              after the support for the software that produced it dropped.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Give preference to Web data serialisation formats available as
              open standards. For instance those provided by the W3C
              [[FORMATS]]. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <!--<p>Try to open the data dump with different
            software.</p> -->
            <p>Try to dereference the URI of the data dump with Content-Type
              header according to the format you expect to get, using for
              example [[cURL]]</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-Archive">R-Archive</a></p>
          </section>
        </div>
        <!-- end of serialisation BP -->
        <!-- begin of resource status BP -->
        <div class="practice">
          <p><span id="resourcestatus" class="practicelab">Update the status of
              a URI</span></p>
          <p class="practicedesc">Preserved datasets <em class="rfc2119">should</em>
            be linked with their "live" counterparts</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>URI dereferencing is a primary interface to Web data. Linking
              preserved datasets with resolving URI inform the data consumer of
              the status of these resources. </p>
            <p>During its live cycle a Web data dataset may undergo several
              modifications. Although IRIs assigned to things are not expected
              to change, the description of these resource will evolve over
              time. There are also some new IRIs that will be put into use, some
              other that will become deprecated, and some that will get deleted.
              Along to this evolution several snapshots could be made available
              for preservation. An example of this is DBpedia which has undergo
              several releases since its first publication and always use the
              same IRI for its resources. Every resource is de-referenced to the
              most up to date description available for it along with a link to
              preserved descriptions using the protocol Memento (see <a href="http://mementoweb.org/depot/native/dbpedia/">Memento
                gateway for DBpedia</a>)</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>A link is maintained between the IRI of a things, the most
              up-to-date description available for it and preserved
              descriptions. If the resource does not exist any more the
              description <em class="rfc2119">should</em> say so and refer to
              the last preserved description that was available for it.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>There is a variety of HTTP status code that could be put into use
              to relate the IRI with its preserved description. In particular,
              200, 404, 410, 303 and 209 can be used for different scenarios:</p>
            <ul>
              <li>200 =&gt; there is a new description which contains pointers
                to archived description</li>
              <li>404 =&gt; the resource just died, the URI consumer has to go
                find an archive to look for it</li>
              <li>410 =&gt; dead again but this time it's a controlled process</li>
              <li>303 =&gt; the description of this URI is no longer served here
                but there is a preserved description at a different location</li>
              <li>209 =&gt; this resource does not exist any more but we have
                some information about it. The description could include a list
                of locations having different preserved descriptions over
                different times.</li>
            </ul>
            Next to the status codes, HTTP header can also be used to relate
            resources. </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>The presence of relations can be checked with a software looking
              for links between all the target resources</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-PersistentIdentification">
                R-PersistentIdentification</a></p>
          </section>
        </div>
      <!-- end of resource status BP -->
      </section>
      <!-- end of Data Preservation -->
      <!-- begin Feedback -->
      <section id="feedback">
        <h3>Feedback</h3>
        <p>Publishing data on the Web enables data sharing on a large scale,
          providing data access to a wide range of audiences with different
          levels of expertise. Data publishers want to ensure that the data
          published is meeting the data consumer needs and user feedback is
          crucial. Feedback has benefits for both data publishers and data
          consumers, helping data publishers to improve the integrity of their
          published data, as well as to encourage the publication of new data.
          Feedback allows data consumers to have a voice describing usage
          experiences (e.g. applications using data), preferences and needs.
          When possible, feedback should also be publicly available for other
          data consumers to examine. Making feedback publicly available, allows
          users to become aware of other data consumers, supports a
          collaborative environment, and allows user community experiences,
          concerns or questions are currently being addressed.</p>
        <p> From a user interface perspective there are different ways to gather
          feedback from data consumers, including site registration, contact
          forms, quality ratings selection, surveys and comment boxes for
          blogging. From a machine perspective the data publisher can also
          record metrics on data usage or information about specific
          applications consumers are currently relying upon. Feedback such as
          this establishes a line of communication channel between data
          publishers and data consumers. In order to quantify and analyze usage
          feedback, it should be recorded in a machine-readable format.Blogs and
          other publicly available feedback should be displayed in a
          human-readable form through the user interface. </p>
        <p> This section provides some BP to be followed by data publishers in
          order to enable data consumers to provide feedback about the consumed
          data. This feedback can be for humans or machines. </p>
        <!-- begin of BP Gather Feedback -->
        <div class="practice">
          <p><span id="GatherFeedback" class="practicelab">Gather feedback from
              data consumers </span></p>
          <p class="practicedesc"> Data consumers <em class="rfc2119">should</em>
            have a way of sharing feedback and rating data.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing feedback contributes to improve the quality of
              published data, may encourage publication of new data, helps data
              publishers understand data consumers needs better, and when
              feedback is made publicly available enhances the consumers
              collaborative experience. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data consumers <em class="rfc2119">should</em> be able to
              provide feedback and rate data in both human and machine-readable
              formats. If feedback is made Web accessible then the feedback <em

                class="rfc2119">must</em> provide a URL reference to the
              corresponding dataset.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide data consumers including but not limited to: registration
              form, contact form, point and click data quality rating buttons,
              or a comment box for blogging.</p>
            <p> Collect feedback in machine-readable formats to represent the
              feedback and use a vocabulary to capture the semantics of the
              feedback information. The definition of a Data Usage Vocabulary is
              included in the activity of the DWBP group in order to support in
              the implementation of this best practice. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <ul>
              <li>Demonstrate using an HTML form how feedback can be collected
                from data consumers. </li>
              <li> Verify that the feedback is persistently stored. If the
                feedback is made publicly available verify that a URL links back
                to the published data being referenced.</li>
              <li> Check that the feedback format conforms to a known
                machine-readable format specification in current use among
                anticipated data users. </li>
            </ul>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UsageFeedback">R-UsageFeedback</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">R-QualityOpinions</a></p>
          </section>
        </div>
        <!-- end of BP Gather Feedback --> </section>
      <!-- end Feedback -->
      <!-- end best practices --> </section>
    <section id="conclusions">
      <h2>Conclusions</h2>
    </section>
  </body>
</html>
