<!DOCTYPE html>
<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <meta name="generator" content="HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/c63cc39">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <title>Data on the Web Best Practices</title>
    <script class="remove" src="http://www.w3.org/Tools/respec/respec-w3c-common">
</script> <script class="remove" src="bpconfig.js">
</script> <style type="text/css">

#bp-summary ul {
  list-style-type: none;
  padding-left: 0;
  line-height:1.6em;
  background-color: #FCFAEE;
}

@media screen and (min-width: 600px) {
  #bp-summary ul {
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
    column-gap: 1em;
  }
}
    


.practice, #tempPractice {
  padding-left: 1em;
  background-color: #FCFAEE;
  border: thin solid black;
}

#tempPractice .tempPracticelab {
  background-color:#dfffff;
  position: relative;
  top: -1.5em;
  font-weight:bold;
}

.practice p.practicedesc, #tempPractice p.tempPracticedesc {
  font-style:italic;
  border-bottom: thin solid black;
  position:relative;
  top:-1.5em;
  margin: 0 2em -1em 1em;;
}

.subhead{
  font-weight:bold;
}

.practice dl dt #tempPractice dl dt{
  font-weight:normal;
}

figure {
  text-align:center;
}

figure figcaption {
  text-align:center;
  font-style:italic;
}

.stmt
{       
    padding: 3pt}

.stmt1
{
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
    column-gap: 1em;
    background-color: #FCFAEE;
 }
    
    

  </style>
  </head>
  <body>
    <section id="abstract">
      <p>This document provides best practices related to the
        publication and usage of data on the Web designed to help support a
        self-sustaining ecosystem. Data should be discoverable and
        understandable by humans and machines. Where data is used in some way,
        whether by the originator of the data or by an external party, such
        usage should also be discoverable and the efforts of the data publisher
        recognized. In short, following these best practices will facilitate
        interaction between publishers and consumers.</p>
    </section>
    <section id="sotd">
      <p>This early version of the document shows its expected scope and future
        direction. A template is used that shows the what, why and how of each
        best practice. Comments are sought on the usefulness of this approach
        and the expected scope of the final document.</p>
    </section>
    <section id="intro" class="informative">
      <h2>Introduction</h2>
      <div class="note">
        <p>This is the first working draft of this document to be formally
          published and all text is explicitly open to review. In this first
          version, 29 best practices are proposed and more than 25 requirements
          have been addressed. However, there are still many ongoing discussions
          in the group about important subjects, like terminology and scope. The
          group is still working towards consensus on the meaning and
          application of some important terms including: vocabulary, metadata,
          data model, data format, schema and dataset. Other important issues
          relate to the definition of best practices for vocabularies. For
          example it is not clear if providing advice to data publishers to
          create and re-use vocabularies is in the scope of the <abbr title="Data on the Web Best Practices">DWBP</abbr>.
          Likewise, there is not yet consensus on whether data preservation is
          in scope. The Working Group is therefore particularly keen to receive
          comments to ensure that its future work is relevant, useful and
          comprehensive. Please send comments to <a href="mailto:public-dwbp-wg@w3.org">public-dwbp-wg@w3.org</a>
          (<a href="mailto:public-dwbp-wg-request@w3.org?subject=subscribe">subscribe</a>,
          <a href="http://lists.w3.org/Archives/Public/public-dwbp-wg/">archives</a>).</p>
      </div>
      <p>The best practices described below have been developed to encourage and
        enable the continued expansion of the Web as a medium for the exchange
        of data. The growth of open data by governments across the world
        [[OKFN-INDEX]], the increasing publication of research data encouraged
        by organizations like the Research Data Alliance [[RDA]], the harvesting
        and analysis of social media, crowd-sourcing of information, the
        provision of important cultural heritage collections such as at the
        Bibliothèque nationale de France [[BNF]] and the sustained growth in the
        Linked Open Data Cloud [[LODC]], provide some examples of this
        phenomenon.</p>
      <p>In broad terms, data publishers aim to share data either openly or with
        controlled access. Data consumers (who may also be producers themselves)
        want to be able to find and use data, especially if it is accurate,
        regularly updated and guaranteed to be available at all times. This
        creates a fundamental need for a common understanding between data
        publishers and data consumers. Without this agreement, data publishers'
        efforts may be incompatible with data consumers' desires.</p>
      <p>Publishing data on the Web creates new challenges, such as how to
        represent, describe and make data available in a way that it will be
        easy to find and to understand. In this context, it becomes crucial to
        provide guidance to publishers that will improve consistency in the way
        data is managed, thus promoting the re-use of data and also to foster
        trust in the data among developers, whatever technology they choose to
        use, increasing the potential for genuine innovation.</p>
      <p>This document sets out a series of best practices that will help
        publishers and consumers face the new challenges and opportunities posed
        by data on the Web. </p>
      <p>Best practices cover different aspects related to data publishing and
        consumption, like data formats, data access, data identification and
        metadata. In order to delimit the scope and elicit the required features
        for Data on the Web Best Practices, the <abbr title="Data on the Web Best Practices">DWBP</abbr>
        working group compiled a set of use cases [[UCR]] that represent
        scenarios of how data is commonly published on the Web and how it is
        used. The set of requirements derived from these use cases were used to
        guide the development of the best practice.</p>
      <p>The Best Practices proposed in this document are intended to serve a
        more general purpose than the practices suggested in Best Practices for
        Publishing Linked Data [[LD-BP]] since it is domain-independent and
        whilst it upholds the use of Linked Data, it also recommends best
        practices for data on the web in formats such as [[CSV]] and [[JSON]]. The Best
        Practices related to the use of vocabularies incorporate practices that
        stem from Best Practices for Publishing Linked Data where appropriate.<!-- While
        that document was published in its final version by the Government Linked        Data Working Group as a Working Group Note, the charter of the Data on        the Web Best Practices (DWBP) Working Group advances that this document        should be published ultimately as a W3C Recommendation.--></p>
    </section>
    <section id="conformance"> </section>
    <section id="audience" class="informative">
      <h2>Audience</h2>
      <p>This document provides best practices to those who publish data on the
        Web. The best practices are designed to meet the needs of information
        management staff, developers, and wider groups such as scientists
        interested in sharing and re-using research data on the Web. While data
        publishers are our primary audience, we encourage all those engaged in
        related activities to become familiar with it. Every attempt has been
        made to make the document as readable and usable as possible while still
        retaining the accuracy and clarity needed in a technical specification.</p>
      <p>Readers of this document are expected to be familiar with some
        fundamental concepts of the architecture of the Web [[!WEBARCH]], such
        as resources and URIs, as well as a number of data formats. The
        normative element of each best practice is the <em>intended outcome</em>.
        Possible implementations are suggested and, where appropriate, these
        recommend the use of a particular technology such as <abbr title="Comma Separataed Variables">CSV</abbr>,
        JSON or RDF. A basic knowledge of vocabularies and data models would be
        helpful to better understand some aspects of this document. </p>
    </section>
    <section id="scope" class="informative">
      <h2>Scope</h2>
      <p>This document is concerned solely with best practices that:</p>
      <ul>
        <li>are specifically relevant to data published on the Web;</li>
        <li>encourage publication or re-use of data on the Web;</li>
        <li>can be tested by machines, humans or a combination of the two.</li>
      </ul>
      <p>As noted above, whether a best practice has or has not been followed
        should be judged against the <em>intended outcome</em>, not the
        specific implementation which is offered as guidance. A best practice is
        always subject to improvement as we learn and evolve the Web together.</p>
    </section>
    <!--<section id="context" class="informative">
      <h2>Context</h2> -->
    <section id="challenges">
      <h2>Data on the Web Challenges</h2>
      <p>The openness and flexibility of the Web creates new challenges for data
        publishers and data consumers. In contrast to conventional databases,
        for example, where there is a single data model to represent the data
        and a database management system (DBMS) to control data access, data on
        the Web allows for the existence of multiple ways to represent and to
        access data. Furthermore, publishers and consumers may be unknown to
        each other and be part of entirely disparate communities with different
        norms and in-built assumptions so that it becomes essential to provide
        information about data structure, quality, provenance and any terms of
        use. The following list summarizes some of the main challenges faced
        when publishing or consuming data on the Web. These challenges were
        identified from the <abbr title="Data on the Web Best Practices">DWBP</abbr>
        Use Cases and Requirements [[UCR]] and are described by one or more
        questions.</p>
      <dl>
        <dt>Metadata</dt>
        <dd><em>What kind of metadata should be considered when describing data
            on the Web?<br>
            How can metadata be provided in a machine readable way?</em></dd>
        <dt>Data Identification</dt>
        <dd><em>How can unique re-use be provided for data resources?<br>
            How should identifiers be designed and managed for persistence?</em></dd>
        <dt>Data Formats</dt>
        <dd><em>What kind of data formats should be considered when publishing
            data on the Web?</em></dd>
        <dt>Data Vocabularies</dt>
        <dd><em>How can existing vocabularies be used to provide semantic
            interoperability?<br>
            How can a new vocabulary be designed if needed?</em></dd>
        <dt>Data Licenses</dt>
        <dd><em>How can data licenses be made machine readable?<br>
            How can license information about data published on the Web be
            provided/gathered?</em></dd>
        <dt>Data Provenance</dt>
        <dd><em>How can data provenance information about data published on the
            Web be provided/gathered?</em></dd>
        <dt>Data Quality</dt>
        <dd><em>How can data quality information about data on the Web be
            provided/gathered?</em></dd>
        <!--<dt>Data Granularity</dt>
          <dd><em>How can publishers decide what kind of data granularity is            most appropriate when publishing data on the Web?</em></dd> -->
        <dt>Sensitive Data</dt>
        <dd><em>How can data be published without infringing a person's right to
            privacy or an organization's security?</em></dd>
        <dt>Data Access</dt>
        <dd><em>What kind of data access should be considered when publishing
            data on the Web?<br>
            What requirements should be taken into account when deciding how to
            make data available on the Web?</em></dd>
        <dt>Data Versioning</dt>
        <dd><em>How can different versions of a dataset be tracked and managed?</em></dd>
        <dt>Data Preservation</dt>
        <dd><em>How can publishers decide when and how data on the Web should be
            archived?</em></dd>
        <dt>Feedback</dt>
        <dd><em>How can user feedback about data consumed from the Web be
            gathered?</em></dd>
      </dl>
      <p> Each one of these challenges originated one or more requirements as
        documented in <a href="http://www.w3.org/TR/dwbp-ucr/#requirements">the
          use-cases document</a>. The development of Data on the Web Best
        Practices were guided by these requirements, in such a way that each
        best practice should have at least one of these requirements as an
        evidence of its relevance.</p>
      <!-- </section>--> </section>
    <div class="issue"> Should we include a section to present a glossary with
      definitions (or link to existing definitions) of the main terms used in
      the doc ? <a href="https://www.w3.org/2013/dwbp/track/issues/134">Issue-134</a>
    </div>
    <section id="bp-template">
      <h2>Best Practices Template</h2>
      <p>This section presents the template used to describe Data on the Web
        Best Practices.</p>
      <div id="tempPractice">
        <p><span id="template" class="tempPracticelab">Best Practice Template</span></p>
        <p class="tempPracticedesc">Short description of the BP, including the
          relevant RFC2119 keyword(s)</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>This section answers two crucial questions:</p>
          <ul>
            <li>Why this is unique to publishing or re-using data on the Web? </li>
            <li>How does this encourages publication or re-use of data on the
              Web? </li>
          </ul>
        </section>
        <section class="description">A full text description of the problem
          addressed by the best practice may also be provided. It can be any
          length but is likely to be no more than a few sentences. </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>What it should be possible to do when a data publisher follows the
            best practice. </p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>A description of a possible implementation strategy is provided.
            This represents the best advice available at the time of writing but
            specific circumstances and future developments may mean that
            alternative implementation methods are more appropriate to achieve
            the intended outcome.</p>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Information on how to test the BP has been met. This might or might
            not be machine testable.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p>Information about the relevance of the BP. It is described by one
            or more relevant requirements as documented in the <a href="http://www.w3.org/TR/dwbp-ucr/">Data
              on the Web Best Practices Use Cases &amp; Requirements document</a></p>
        </section>
      </div>
      <div class="issue">Is this the correct template? Where exactly should the
        normative statement be? This is <a href="https://www.w3.org/2013/dwbp/track/issues/146">Issue-146</a>.</div>
    </section>
    <section id="bp-summary"> </section>
    <section id="bestPractices">
      <h2>The Best Practices</h2>
      <p>This section contains the best practices to be used by data publishers
        in order to help them and data consumers to overcome the different
        challenges faced during the data on the Web lifecycle. One or more best
        practices were proposed for each one of the previously described
        challenges. Each BP is related to one or more requirements from the <a

          href="http://www.w3.org/TR/dwbp-ucr/">Data on the Web Best Practices
          Use Cases &amp; Requirements document.</a></p>
      <div class="issue"> Do we over-use RFC2119? Is it used correctly? This
        issue may be applied to all BPs. <a href="https://www.w3.org/2013/dwbp/track/issues/135">
          Issue-135</a> </div>
      <div class="issue">Some sections of the document have a technological
        bias. <a href="https://www.w3.org/2013/dwbp/track/issues/144">
          Issue-144</a> </div>
      <section id="metadata">
        <h3>Metadata</h3>
        <p>Metadata is data about data. It provides additional information that
          helps consumers better understand the meaning of data, its structure,
          and to clarify other issues, such as rights and license terms, the
          organization that generated the data, data quality, data access
          methods, the update schedule of datasets, etc.</p>
        <p>Metadata can be used to help tasks such as dataset discovery and
          re-use, and can be assigned considering different levels of
          granularity from a single property of a resource to a whole dataset,
          or all datasets from a specific organization.</p>
        <p>Metadata can be of different types. These types can be classified in
          different taxonomies, with different grouping criteria. For example, a
          specific taxonomy could define three metadata types according to
          descriptive, structural and administrative features. Descriptive
          metadata serves to identify a dataset, structural metadata serves to
          understand the format(s) in which the dataset is distributed and
          administrative metadata serves to provide information about the
          version, update schedule etc. A different taxonomy could define
          metadata types with a scheme according to tasks where metadata are
          used, for example, discovery and re-use.</p>
        <p> The Web is an open information space; in the absence of a specific
          context, such a company's internal information system, metadata is
          essential. Data will not be discoverable or reusable by anyone other
          than the publisher if insufficient metadata is provided.</p>
        <p>Data consumers must be able to:</p>
        <ol>
          <li>discover the data;</li>
          <li>understand the nature and structure of the data, i.e. what the
            data describes and how it does it;</li>
          <li>find out the origin of the data and under what terms it may be
            used.</li>
        </ol>
        <p> Not just data consumers should be able to read the metadata, but
          also machines should be able to automatically process the metadata
          associated to a given dataset. It is also important that standard
          terms are used when specfying metadata to help the automatic
          processing of metadata as well as to improve data interoperability . </p>
        <p> This section presents best practices to help data publishers to face
          challenges related to metadata. Initially, general best practices are
          presented (Document data, Use
              machine-readable formats to provide metadata and Use standard terms to define metadata), then best
          practices concerning specific kinds of metadata are proposed. These
          specific best practices are specializations of the more general best
          practices. </p>
        <!-- begin of Document Metadata BP -->
        <div class="practice">
          <p><span id="DocumentMetadata" class="practicelab"> Document data</span></p>
          <p class="practicedesc">A metadata document <em class="rfc2119">must</em>
            be published together with the data </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing information about data, i.e. metadata, in a way that
              data consumers may understand is fundamental when publishing data
              on the Web. Given that data publishers and data consumers may be
              unknown to each other, becomes essential to provide information
              that helps data consumers to understand the data as well as other
              important aspects that describes a dataset. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> It must be possible for data consumers to read metadata that
              describes a dataset, which makes it human readable metadata.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            Metadata for humans is most easily provided as part of an HTML Web
            page. </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a human user can easily read the metadata associated
              with a dataset. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataDocum">R-MetadataDocum</a></p>
          </section>
        </div>
        <div class="issue"> Should we mention multilingualism in BP <em>Document
            data</em>? This issue applies to all BPs about providing
          documentation for humans. <a href="https://www.w3.org/2013/dwbp/track/issues/142">Issue-142</a>
        </div>
        <!-- end of BP -->
        <!-- begin of Provide Metadata in machine-readable formats BP -->
        <div class="practice">
          <p><span id="ProvideMetadataMachine" class="practicelab">Use
              machine-readable formats to provide metadata </span></p>
          <p class="practicedesc">Metadata in machine-readable formats <em class="rfc2119">must</em>
            be published together with the data</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Metadata can be used by machines, notably search engines, to
              discover and classify data. Further metadata can be used by
              machines to process the data once discovered. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> It should be possible for computer applications, notably search
              tools, to locate and process the metadata easily, which makes it
              human readable metadata, machine readability metadata.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            Metadata for machines is best provided either as an alternative
            representation of the Web page in a serialization format such as
            Turtle or [[JSON-LD]] (for [[RDF]]) or it can be embedded in the HTML page,
            again as [[JSON-LD]], or [[HTML-RDFA]] or [[Microdata]].
            <p>If the multiple formats are published separately, they should be
              served from the same URL using content negotiation. Maintenance of
              multiple formats is best achieved by generating each available
              format on the fly based on a single source of the metadata.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Access the same URL either with a user agent that accepts a more
              data oriented format, such as [[RDF]], or a tool that extracts the
              data from an HTML page such as the <a href="http://rdf-translator.appspot.com/">RDF
                Translator</a>.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>
            </p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin of Provide Metadata Standardized BP -->
        <div class="practice">
          <p><span id="ProvideMetadataStandardized" class="practicelab">Use
              standard terms to define metadata</span></p>
          <p class="practicedesc"> Standard terms <em class="rfc2119">should</em>
            be used for metadata definition.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The provision of metadata is fundamental to data on the Web. It
              is the shop window, the user-manual and the conditions of use. It
              is possible to provide this information an an infinite number of
              ways: <i>maker</i>, <i>author</i>, <i>originator</i>, <i>person
                responsible</i> and <i>source</i> are among the many near
              synonyms for <i>creator</i>. And of course those examples are all
              just in a single language. The task of finding and processing
              relevant data among the vast amounts available on the Web, for
              people and the computer systems they use, is made substantially
              more achievable if different publishers use the same terms as each
              other, or rather, use <em>common re-use</em> for the terms used,
              however those terms are presented to humans. Only in this way can
              the same tools and methods be used for multiple tasks.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Metadata should be provided using standard vocabularies.</p>
          </section>
          <div class="issue">MUST or SHOULD? <a href="https://www.w3.org/2013/dwbp/track/issues/133">Issue-133</a>.
            This issue could readily be applied to all BPs.</div>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Metadata is best provided using RDF vocabularies. Each term in an
              RDF vocabulary has its own HTTP URI to which labels and
              descriptions in multiple languages can be attached. If labels are
              not provided in your language, you can add them. If your context
              demands that a term be specialized, you can create a sub class or
              sub property but retain the benefits of the original vocabulary's
              semantics.</p>
            <p>Detailed advice on the best practices for the selection, use and
              extension of vocabularies is provided in Best Practices for
              Publishing Linked Data [[LD-BP]].</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that standard vocabularies have been used wherever
              possible. In particular mark as an error instances where
              vocabularies such as [[DC-TERMS]] and [[VOCAB-DCAT]] could have
              been used but were not.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
          </section>
        </div>
        <!-- end of BP -->
        <section id="discovery">
          <h3>Data Discovery</h3>
          In order to be discoverable on the Web, typically through a search
          engine or a data portal's own search function, it is essential to
          provide the kind of information that such tools need. Unlike a natural
          language document that, to a greater or lesser extent, can be
          processed and its content 'understood,' a dataset must be described
          and it is that description that forms the basis of any classification,
          or indexing.
          <!-- begin Discovery Metadata BP -->
          <div class="practice">
            <p><span id="DiscoveryMetadata" class="practicelab">Provide
                discovery metadata</span></p>
            <p class="practicedesc">The overall features of a dataset <em class="rfc2119">must</em>
              be described by metadata.</p>
            <p>This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">
                Use machine-readable formats to provide metadata</a>. </p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p>Explicitly providing data discovery information allows user
                agents to automatically discover datasets available on the Web.
              </p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p>User agents must be able to discover datasets.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>The vocabulary recommended by W3C is the Data Catalog
                Vocabulary [[VOCAB-DCAT]].</p>
              <p>This provides a framework in which datasets can be described as
                abstract entities with one or more distributions, that is, means
                of accessing the data. This might be through one or more
                downloads or APIs. Aspects covered include:</p>
              <ul>
                <li>The <strong>title</strong> and a <strong>description</strong>
                  of the data.</li>
                <li>The <strong>data format(s)</strong> in which the data could
                  be downloaded (e.g. XML, CSV, TSV, JSON, JSON-LD, RDF/XML,
                  Turtle, N-Triples etc.)</li>
                <li>Any <strong>variants</strong> (e.g. different
                  human-language translations) of data.</li>
                <li><strong>Access mechanisms</strong> though which the data be
                  accessed, e.g. SPARQL endpoints, Linked Data Platform [[LDP]],
                  REST interfaces, SOAP-based web services, etc. (see <a href="#access">Data
                    Access</a>). </li>
              </ul>
              <!--<p>See also <a href="#AdministrativeMetadata">Provide
                Administrative Metadata</a></p> --> </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p>A human test might simply be to use an appropriate search tool
                and check that the dataset is discoverable as expected since
                that is the intended outcome. However, a more structured test
                would be to ensure that the basic metadata fields listed above
                are filled. It may be possible to machine-test this using the
                work of the <a href="http://www.w3.org/2014/data-shapes/">RDF
                  Data Shapes</a> Working Group.</p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>,
                <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>,
                <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
            </section>
          </div>
        </section>
        <!-- end of BP -->
        <!-- begin Locale Parameters BP -->
        <section id="localeparameters">
          <h3>Locale Parameters</h3>
          <p> A locale is a set of parameters that defines specific data
            aspects, such as language and formatting used for numeric values and
            dates. When publishing data on the Web is important to provide such
            information in order to improve the common understanding between
            data publishers and data consumers. Some data fields may differ
            subtly but significantly with changes in locale, for example.
            Providing information about the locality for which the data is
            currently published aids data users in interpreting its meaning.
            Date, time, and number formats can have very different meanings,
            despite similar appearances. Making the language explicit allows
            users to determine how readily they can work with the data and may
            enable automated translation services. </p>
          <div class="practice">
            <p><span id="LocaleParametersMetadata" class="practicelab">Provide
                locale parameters metadata </span></p>
            <p class="practicedesc">Information about locale parameters (date,
              time, and number formats, language) <em class="rfc2119">should</em>
              be made available. </p>
            <p>This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">Use
              machine-readable formats to provide metadata</a>.</p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p> Providing locale parameters helps data consumers to understand
                and to manipulate the data, improving the re-use of the data. </p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p>It should be possible for data consumers to interpret the
                meaning of dates, times and numbers accurately by referring to
                locale information.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>Provide locale metadata for date, time, and number fields, and
                include the language in which the data is published in the
                dataset metadata. Where an international format specification
                exists, e.g., ISO 8601 for dates and times, use it. </p>
            </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p> Check that the metadata for the dataset itself includes the
                language in which it is published and that all numeric, date,
                and time fields have locale metadata provided either with each
                field or as a general rule. </p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatLocalize">R-FormatLocalize</a>,
                <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a></p>
            </section>
          </div>
        </section>
        <!-- end of Locale Parameters BP -->
        <!-- begin of Data Licenses -->
        <section id="licenses">
          <h3>Data Licenses</h3>
          <p>A license is a very useful piece of information to be attached to
            data on the Web. As defined by the Dublin Core Metadata Initiative,
            a license is a legal document giving official permission to do
            something with the data with which it is associated. According to
            the type of license adopted by the publisher, there might be more or
            fewer restrictions on sharing and re-using data. In the context of
            data on the Web, the license of a dataset can be specified within
            the data, or outside of it, in a separate document to which it is
            linked.
            <!--However, in line with the Linked
          Data principles, licenses for such datasets should          be specified in RDF, for instance through the Dublin Core vocabulary          [[DC-TERMS]].</p> -->
            <!-- begin of Provide Data License BP --> </p>
          <!-- begin of machine detectable license BP -->
          <div class="practice">
            <p><span id="ProvideDataLicense" class="practicelab">Provide data
                license information</span></p>
            <p class="practicedesc"> Data license information <em class="rfc2119">should</em>
              be available </p>
            <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">Use
              machine-readable formats to provide metadata</a>. </p>
            <div class="axioms">
              <p class="subhead">Why</p>
              <p>The presence of license information is essential for assessing
                the usability of data. User agents, including search tools, may
                use the presence/absence of license information as a trigger for
                inclusion or exclusion of data presented to a potential
                consumer. Even though the license may be presented in natural
                language, where data links to the URL of a well known license,
                the user agent may be able to present the well known features to
                the potential consumer.</p>
            </div>
            <div class="description">
              <p class="subhead">Intended outcome</p>
              <p>Machines should be able to automatically detect whether a given
                dataset does or does not carry a license.</p>
            </div>
            <div class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>There are several well known vocabularies that include
                properties for linking to a license. These include Dublin Core
                [[DC-TERMS]], Creative Commons [[CC-ABOUT]], schema.org
                [[SCHEMA-ORG]] and XHTML [[XHTML-VOCAB]]. There are also a
                number of machine readable rights languages, including The
                Creative Commons Rights Expression Language [[ccREL]], the Open
                Data Rights Language [[ODRL]] and the Open Data Rights Statement
                Vocabulary [[ODRS]].</p>
              <p>Links to the license can be provided from the data itself, from
                an HTML page that describes the data (via a Link element), or
                via an HTTP Link Header, the latter two with a <code>@rel</code>
                value of <code>license</code>. </p>
              <p>Further information about open data licensing can be found in
                the Publisher's Guide to Open Data Licensing, published by the
                Open Data Institute [[ODI-LICENSING]]. </p>
            </div>
            <div class="test">
              <p class="subhead">How to Test</p>
              <p>Check for the presence of one or more of:</p>
              <p></p>
              <ol>
                <li>the presence of an RDF predicate;</li>
                <li>an HTML Link element;</li>
                <li>an HTTP Link header;</li>
              </ol>
              <p>that links the dataset to a license and/or rights information.</p>
            </div>
            <div class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant use cases</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseAvailable">R-LicenseAvailable</a>
                and <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>
              </p>
            </div>
          </div>
          <!-- end of machine detectable license BP --> </section>
        <!-- end of Data Licenses -->
        <!-- begin of Data Provenance -->
        <section id="provenance">
          <h3>Data Provenance</h3>
          <p>Provenance originates from the French term "provenir" (to come
            from), which is used to describe the curation process of artwork as
            art is passed from owner to owner. Data provenance, in a similar
            way, is metadata, that allows data providers to pass details about
            the data history to data users. Provenance becomes particularly
            important when data is shared between collaborators who might not
            have direct contact with one another either due to proximity or
            because the published data outlives the lifespan of the data
            provider projects or organizations.</p>
          <p>The Web brings together business, engineering, and scientific
            communities creating collaborative opportunities that were
            previously unimaginable. The challenge in publishing data on the Web
            is providing an appropriate level of detail about its origin. The
            data publishers may not necessarily be the data provider and so
            collecting and conveying this corresponding metadata is particularly
            important. Without provenance, consumers have no inherent way to
            trust the integrity and credibility of the data being shared. Data
            publishers in turn need to be aware of the needs of prospective
            consumer communities to know how much provenance detail is
            appropriate. </p>
          <!-- <p>To meet this need, the W3C community offers the Provenance Ontology
            [[PROV-O]] so that data publishers can formally describe data            provenance and methodologies so that consumers can query and use            provenance information. </p> -->
          <!-- begin of Provide Data Provenance BP -->
          <div class="practice">
            <p><span id="ProvideDataProvenance" class="practicelab">Provide data
                provenance information</span></p>
            <p class="practicedesc">Data provenance information <em class="rfc2119">should</em>
              be available </p>
            <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">Use
              machine-readable formats to provide metadata</a>. </p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p>Without accessible data provenance, consumers will not know the
                origin or history of the published data.</p>
              <p>Data provenance is data that shows the history of a dataset or data. Data
                provenance can be built upon existing vocabularies that make
                provenance identifiable such as the Provenance Ontology
                [[PROV-O]]. </p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p>Data published on the Web should include, or link to,
                provenance information.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>Data provenance can be published in a number of ways:</p>
              <ol>
                <li>Use the Provenance Ontology [[PROV-O]] to describe data
                  provenance.</li>
                <li>Use an appropriate level of detail that will be meaningful
                  to the intended audience. </li>
                <li>Write the data provenance in either a machine readable form
                  such as Turtle or RDF/XML or embed provenance in an HTML page
                  using [[JSON-LD]], or [[HTML-RDFA]] </li>
                <li>Verify that the data provenance references published data</li>
              </ol>
            </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p>The PROV Implementation Report [[PROV-IMP]] lists a number of
                validator tools that can be used to test for the presence of
                provenance information provided using [[PROV-O]].</p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-ProvAvailable">R-ProvAvailable</a>,
                <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>
              </p>
            </section>
          </div>
          <!-- end of Provide Data Provenance BP --> </section>
        <!-- end of Data Provenance -->
        <!-- begin of Data Quality -->
        <section id="quality">
          <h3>Data Quality</h3>
          <p>Data quality is commonly defined as “fitness for use” for a
            specific application or use case. It can affect the potentiality of
            the application that use data, as a consequence, its inclusion in
            the data publishing and consumption pipelines is of primary
            importance.</p>
          <p>Usually, the assessment of quality involves different kinds of
            quality dimensions, each representing groups of characteristics that
            are relevant to publishers and consumers. Measures and metrics are
            defined to assess the quality for each dimension. There are
            heuristics designed to fit specific assessment situations that rely
            on quality indicators, namely, pieces of data content, pieces of
            data meta-information, and human ratings that give indications about
            the suitability of data for some intended use.</p>
          <p>Dimensions and metrics to adopt might largely depend on the
            specific application scenario, or even on the data domain. A
            systematic review of dimensions, metrics adopted in the context of
            Linked Open Data can be found in the recent literature (e.g., see
            [[ZAVERI]]). </p>
          <!-- begin of Provide Data Quality BP -->
          <div class="practice">
            <p><span id="ProvideDataQuality" class="practicelab">Provide data
                quality information</span></p>
            <p class="practicedesc">Data Quality information <em class="rfc2119">should</em>
              be available </p>
            <p>This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">Use
              machine-readable formats to provide metadata</a>. </p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p>Data quality might seriously affect the suitability of data for
                specific applications, including applications very different
                from the purpose for which it was originally generated.
                Documenting data quality significantly eases the process of data
                selection, increasing the chances of re-use.</p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p> Information about the quality of the data should be provided
                for humans. Ideally it is also made available in machine
                readable manner for processing by applications.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>Depending on the application domain, information pertaining to
                the quality may rely on specific quality metrics or
                feedback-opinion. Specific quality metadata fields may or may
                not be explicitly included in the metadata vocabularies adopted
                by catalogs. Independently from domain-specific peculiarities,
                the quality of data should be documented and known quality
                issues should be explicitly stated in metadata. </p>
              <!--            <p>The definition of a Quality Vocabulary is included in the
              activity of the DWBP group in order to support in the              implementation of this best practice. The Quality Vocabulary is              foreseen as an extension to DCAT to cover the quality of the data,              how frequently is it updated, whether it accepts user corrections,              persistence commitments etc. When used by publishers, this              vocabulary will foster trust in the data amongst developers. </p> -->
            </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p>Check whether the metadata explicitly includes a description of
                the quality of the data.</p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p>Information about the relevance of the BP is described by
                requirements documented in <a href="http://www.w3.org/TR/dwbp-ucr/">the
                  Data on the Web Best Practices Use Cases &amp; Requirements
                  document</a>: <a href="http://www.w3.org/TR/dwbp-ucr/#requirements-for-quality-and-granularity-description-vocabulary">Requirements
                  for Data Quality</a></p>
            </section>
            <!-- end of Provide Data Quality BP --> </div>
          <div class="issue"> Should we provide more specific/ detailed
            strategies on how to attach quality info in metadata apart from the
            use of the data quality vocabulary the group is working on? <a href="https://www.w3.org/2013/dwbp/track/issues/116">
              Issue-116</a> </div>
        </section>
        <!-- end of Data Quality -->
        <!-- begin of Data Versioning -->
        <section id="dataVersioning">
          <h3>Data Versioning</h3>
          <p>Data on the web often changes over time. Many datasets are updated
            on a scheduled basis, such as census data or funding data that
            changes every fiscal year. Other datasets are changed as
            improvements in collecting the data make updates worthwhile. Still
            other data changes in real time or near real time. All these types
            of data need a consistent, informative approach to versioning, so
            that data consumers can understand and work with the changing data.
            The following best practices address issues that arise in tracking
            and managing different versions of datasets.</p>
          <!-- begin of provide Versioning Info BP -->
          <div class="practice">
            <p><span id="provideVersioningInfo" class="practicelab">Provide
                versioning information</span></p>
            <p class="practicedesc">Data that will be updated over time <em class="rfc2119">should</em>
              be assigned a unique version number or, at a minimum, a unique version date, and
              that unique identifier <em class="rfc2119">should</em> be distributed
              with the data in the form of metadata. </p>
            <p>This best practice is a specialization of the higher level <a href="#ProvideMetadataMachine">Use
              machine-readable formats to provide metadata</a>. </p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p>Version information makes a dataset uniquely identifiable.
                Uniqueness can be used by data consumers to determine how data has changed
                over time and to determine specifically which version of a dataset
                they are working with. 
                Good data versioning enables consumers to understand if a newer version
                of a dataset is available. Explicit versioning allows for
                repeatability in research, enables comparisons, and prevents
                confusion. Using unique version numbers that follow a standardized
                approach can also set consumer expectations about how the
                versions differ.</p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p>It should be possible for data consumers to easily determine
                which version of the data they are working with.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <!-- <p>Providing version information is a topic of <a href="https://lists.w3.org/Archives/Public/public-vocabs/2015Jan/0120.html"
                  title="A versioning model for schema.org">much debate</a>. -->
              <p> The precise method adopted for providing versioning
                information may vary according to the context, however there are
                some basic guidelines that can be followed, for example: </p>
              <ul>
                <li> Include a unique version number as part of the metadata for the
                  dataset. </li>
                <li> Use a consistent numbering scheme with a meaningful
                  approach to incrementing digits, such as [[SchemaVer]]. </li>
                <li> Provide a description of what has changed since the
                  previous version. The Web Ontology Language provides a number
                  of annotation properties for version information
                  [[OWL2-QUICK-REFERENCE]] and the Provenance Ontology
                  [[PROV-O]] defines several types of link between versions. </li>
                <li>If the data is made available through an API, the URI used
                  to request the latest version of the data should not change as
                  the versions change, but it should be possible to request a
                  specific version through the API.
                  <!--See <a href="#VersioningVocabularies">Vocabulary
                  versioning</a> for more on assigning stable URIs for the 'latest version' and for each snapshot.</p> -->
                </li>
              </ul>
            </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p>Check that a unique version number or date is provided with the
                metadata describing the dataset.</p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataVersion">R-DataVersion</a></p>
            </section>
          </div>
          <!-- end of provide Versioning Info BP -->
          <!-- begin of provide version history BP -->
          <div class="practice">
            <p><span id="provideVersionHistory" class="practicelab">Provide
                version history</span></p>
            <p class="practicedesc">A version history <em class="rfc2119">should</em>
              be available for versioned data.</p>
            <section class="axioms">
              <p class="subhead">Why</p>
              <p>In creating applications that use data, it can be helpful to
                understand the variability of that data over time. Interpreting
                the data is also enhanced by an understanding of its dynamics.
                Determining how the various versions of a dataset differ from
                each other is typically very laborious unless a summary of the
                differences is provided.</p>
            </section>
            <section class="outcome">
              <p class="subhead">Intended Outcome</p>
              <p>It should be possible for data consumers to understand how the
                data typically changes from version to version and how any two
                specific versions differ.</p>
            </section>
            <section class="how">
              <p class="subhead">Possible Approach to Implementation</p>
              <p>Provide a list of published versions and a description for each
                version that explains how it differs from the previous version.
                An API can expose a version history with a single dedicated URL
                that retrieves the latest version of the complete history.</p>
            </section>
            <section class="test">
              <p class="subhead">How to Test</p>
              <p>Check that a list of published versions is available, and that
                each version is described.</p>
            </section>
            <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataVersion">R-DataVersion</a></p>
            </section>
          </div>
          <!-- end of provide version history BP --> </section>
        <!-- end of Metadata --> </section>
      <!-- begin of Data Identification -->
      <section id="dataIdentification">
        <h3>Data Identification</h3>
        <p>Identifiers are simple conventions of labels that allow us to
          distinguish what is being identified from anything else. Identifiers
          have being extensively used in every information system, making it
          possible to refer to any particular element. On the Web, a friendly
          and uniform system of identification will be required to enable data
          persistency and re-use, being a crucial element for the process of
          data sharing and connecting.</p>
        <!-- begin of Data Identification BP -->
        <div class="practice">
          <p><span id="ProvideUniqueIdentifiers" class="practicelab">Use unique
              identifiers</span></p>
          <p class="practicedesc">Data, datasets and the different dataset
            versions <em class="rfc2119">must</em> be associated with a unique
            identifier. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Adopting a common identification system enables basic data
              identification and comparison processes by any stakeholder in a
              reliable way. They are an essential pre-condition for proper data
              management and re-use.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data and datasets must be discoverable and citable.</p>
            <p>A number of basic requirements should be fulfilled during the
              definition of an identification system:</p>
            <ol>
              <li>Ensure that data and datasets can be identified by its unique
                identifier.</li>
              <li>The unique identifier needs to remain persistent through time,
                regardless of the status of the associated resource (data or
                dataset).</li>
              <li>Each version of a dataset must be identified by a URI.</li>
              <li>Always use a consistent and uniform, but also flexible and
                extensible, structure for the composition of identifiers.</li>
            </ol>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The architecture of the World Wide Web [[WEBARCH]] is based on
              links between resources based on globally unique identifiers. They
              can identify people, places and concepts just as much as the more
              familiar <abbr title="Uniform Resource Location">URL</abbr>
              identifiers for Web pages, images etc. HTTP <abbr title="Internationalized Resource Identifier">IRI</abbr>s,
              the internationalized version of <abbr title="Uniform Resource Identifier">URI</abbr>s,
              themselves a super-set of URLs, are a fundamental aspect of the
              Web.</p>
            <p>Internationalized Resource Identifiers (IRIs) [[!RFC3987]] should
              be used when needed. The use of URI or IRIs depends on the
              intended audience. For global audience one should use language and
              cultural neutral URIs; for local audience one could use IRIs.</p>
            <pre title="URI and IRIs" class="highlight example">              http://example.com/中国                  # For Chinese speaker: good mnemonic - non-Chinese speakers: bad mnemonic
              http://example.com/china                 # For Chinese speaker: acceptable - non-Chinese speakers: better
            </pre>
            <p>Some best practices to adopt while using URIs as a data
              identification system:</p>
            <ul>
              <li>Associate every data, or dataset, resource with an unique
                identifier using a representational URI.</li>
              <li>Use the HTTP protocol to ensure that the resolution of any URI
                on the Web is possible.</li>
              <li>When someone looks up an identifier URI, always provide useful
                information or metadata.</li>
              <li>Build standard URIs that follow a well-defined and extensible
                scheme or pattern to provide consistency and uniformity.</li>
              <li>Avoid broken URIs. In the event that a resource has been
                modified or deleted, those changes must be communicated using
                the appropriate response code [[RFC7231]]. If the resource has
                changed location, HTTP 3XX codes should be used, whereas if the
                resource has been deleted a HTTP 410 code should be used.</li>
              <li>Do not expose information on the technical implementation of
                the resources represented within the URI. Any information about
                the underlying technology should be omitted (e.g. file
                extensions).</li>
            </ul>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that there is a documented scheme of Web identifiers for
              the data in question. For any of the existing identifiers test
              that the associated data can always be retrieved by means of its
              identifier and in a technologically neutral way.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a></p>
          </section>
        </div>
        <!-- <div class="issue"> Should we change the title of BP <em>Provide unique
            identifiers?</em> <a href="https://www.w3.org/2013/dwbp/track/issues/145">            Issue-145</a> </div> -->
        <!-- end of Data Identification BP --> </section>
      <!-- end of Data Identification -->
      <!-- begin of Data Formats -->
      <section id="dataFormats">
        <h3>Data Formats</h3>
        <p>The formats in which data is made available to consumers are a key
          aspect of making that data usable. The best, most flexible access
          mechanism in the world is pointless unless it serves data in formats
          that enable use and reuse. Below we detail best practices in selecting
          formats for your data, both at the level of files and that of
          individual fields. W3C encourages use of formats that can be used by
          the widest possible audience and processed most readily by computing
          systems. Source formats, such as database dumps or spreadsheets, used
          to generate the final published format, are out of scope. This
          document is concerned with what is actually published rather than
          internal systems used to generate the published data.</p>
        <!-- begin of Machine-Readable Standardized Format BP -->
        <div class="practice">
          <p><span id="MachineReadableStandardizedFormat" class="practicelab">Use
              machine-readable standardized data formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">must</em> be
            available in a machine-readable standardized data format that is
            adequate for its intended or potential use.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>As data becomes more ubiquitous, and datasets become larger and
              more complex, processing by computers becomes ever more crucial.
              Posting data in a format that is not machine readable places
              severe limitations on the continuing usefulness of the data. Using
              non-standard data formats is costly and inefficient, and the data
              may lose meaning as it is transformed. On the other hand,
              standardized data formats enable interoperability as well as
              future uses, such as remixing or visualization, many of which
              cannot be anticipated when the data is first published.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Published data on the Web must be readable and processable by
              typical computing systems. Any data consumer who wishes to work
              with the data and is authorized to do so must be able to do so
              with computational tools typically available in the relevant
              domain.</p>
            <!--<p> A machine must be able to: </p>
            <ol>              <li>Open and read the data using commonly available software
                packages. </li>              <li>Process the data. </li>
              <li>Store the data for future use.</li>            </ol> --> </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Consider which data formats potential users of the data are most
              likely to have the necessary tools to parse. Non-proprietary data
              formats include, but are not limited to, CSV, NetCDF, XML, JSON
              and RDF. Standard data formats as well as the use of standard data
              vocabularies will better enable machines to process the data.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that the data format conforms to a known machine-readable
              data format specification in current use among anticipated data
              users. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMachineRead">R-FormatMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatStandardized">R-FormatStandardized</a></p>
          </section>
        </div>
        <div class="issue"> Should we use machine-readable standardized data
          formats BP be split in two? <a href="https://www.w3.org/2013/dwbp/track/issues/138">
            Issue-138</a> </div>
        <!-- end of Machine-Readable Standardized FormatBP -->
        <!-- begin of Open Format BP -->
        <div class="practice">
          <p><span id="OpenFormat" class="practicelab">Use open data formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            available in a nonproprietary data format. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Open data formats are usable by anyone. Proprietary data formats
              may be difficult or impractical for some data users to view or
              parse. Thus, the use of open data formats increases the
              possibilities for use and re-use of data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>It should be possible for any person who wants to use or re-use
              the data to do so without investment in proprietary software.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Make data available in open data formats including but not
              limited to CSV, XML, Turtle, NetCDF and JSON.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check if it is possible to read, process, and store the data
              without using any proprietary software package. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatOpen">R-FormatOpen</a></p>
          </section>
        </div>
        <!-- end of Open Formats BP -->
        <!-- begin of Multiple Formats BP -->
        <div class="practice">
          <p><span id="MultipleFormats" class="practicelab">Provide data in
              multiple formats </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            available in multiple data formats. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing data in more than one format reduces costs incurred in
              data transformation. It also minimizes the possibility of
              introducing errors in the process of transformation. If many users
              need to transform the data into a specific data format, publishing
              the data in that format from the beginning saves time and money
              and prevents errors many times over. Lastly it increases the
              number of tools and applications that can process the data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> It should be possible for data consumers to work with the data
              without transforming it.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Consider the data formats most likely to be needed by intended
              users, and consider alternatives that are likely to be useful in
              the future. Data publishers must balance the effort required to
              make the data available in many formats, but providing at least
              one alternative will greatly increase the usability of the data.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that the complete dataset is available in more than one
              data format.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMultiple">R-FormatMultiple</a></p>
          </section>
        </div>
        <!-- end of Multiple Formats BP --> </section>
      <!-- end of Data Formats -->
      <!-- begin of Data Vocabularies -->
      <section id="dataVocabularies">
        <h3>Data Vocabularies</h3>
        <div class="issue">The section needs terminological discussion on
          whether we keep "vocabularies", which could be replaced by "data
          models" or "schemas" and whether we should remove "controlled
          vocabularies" from the picture. <a href="https://www.w3.org/2013/dwbp/track/issues/134">Issue-134</a>
        </div>
        <div class="issue">A big part of the section (starting by the section
          name) is biased towards linked data technology. It should be completed
          with other references and alternative implementation approaches. <a href="https://www.w3.org/2013/dwbp/track/issues/144">Issue-144</a></div>
        <p>Data is often represented in a structured and controlled way, making
          reference to a range of vocabularies, for example, by defining types
          of nodes and links in a data graph or types of values for columns in a
          table, such as the subject of a book, or a relationship “knows”
          between two persons. Additionally, the values used may come from a
          limited set of pre-existing values or resources: for example object
          types, roles of a person, countries in a geographic area, or possible
          subjects for books. Such vocabularies ensure a level of control,
          standardization and interoperability in the data. They can also serve
          to improve the usability of datasets. Say, a dataset contains a
          reference to a concept described in several languages. Such reference
          allows applications to localize their display of their search
          depending on the language of the user. </p>
        <p>According to W3C, <a href="http://www.w3.org/standards/semanticweb/ontology">vocabularies</a>
          define the concepts and relationships (also referred to as “terms”)
          used to describe and represent an area of concern. Vocabularies are
          used to classify the terms that can be used in a particular
          application, characterize possible relationships, and define possible
          constraints on using those terms. Several categories of vocabularies
          have been coined, for example, ontology, controlled vocabularies,
          thesaurus, taxonomy, semantic network.</p>
        <p>There is no strict division between the artifacts referred to by
          these names. “Ontology” tends however to denote the vocabularies of
          classes and properties that structure the descriptions of resources in
          (linked) datasets. In relational databases, these correspond to the
          names of tables and columns; in XML, they correspond to the elements
          defined by an XML Schema. Ontologies are the key building blocks for
          inference techniques on the Semantic Web. The first means offered by
          W3C for creating ontologies is the RDF Schema [[RDF-SCHEMA]] language.
          It is possible to define more expressive ontologies with additional
          axioms using languages such as those in The Web Ontology Language
          [[OWL2-OVERVIEW]]. </p>
        <p>On the other hand, “controlled vocabularies”, “concept schemes”,
          “knowledge organization systems” enumerate and define resources that
          can be employed in the descriptions made with the former kind of
          vocabulary. A concept from a thesaurus, say, “architecture”, will for
          example be used in the subject field for a book description (where
          “subject” has been defined in an ontology for books). For defining the
          terms in these vocabularies, complex formalisms are most often not
          needed. Simpler models have thus been proposed to represent and
          exchange them, such as the ISO 25964 data model [[ISO-25964]] or W3C's
          Simple Knowledge Organization System [[SKOS-PRIMER]].</p>
        <p>This section presents best practices for data vocabularies accessible
          as URI sets on the Web, which are applicable to any kind of
          vocabulary.</p>
        <!-- begin of Document Vocabularies BP -->
        <div class="practice">
          <p><span id="DocumentVocabularies" class="practicelab"> Document
              vocabularies </span></p>
          <p class="practicedesc">Vocabularies <em class="rfc2119">should</em>
            be clearly documented.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Documentation defines what is within the vocabulary and the
              better the documentation the higher the possibility of re-use the
              vocabulary and the datasets built with it.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>The vocabulary should be human-readable.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>A vocabulary may be published together with human-readable Web
              pages, as detailed in the recipes for serving vocabularies with
              HTML documents in the Best Practice Recipes for Publishing RDF
              Vocabularies [[SWBP-VOCAB-PUB]]. Elements from the vocabulary are
              defined with attributes containing human-understandable labels and
              definitions, such as rdfs:label, rdfs:comment, dc:description,
              skos:prefLabel, skos:altLabel, skos:note, skos:definition,
              skos:example, etc.. Documentation may benefit from the additional
              presence of visual documentation such as the UML-style diagram of
              the W3C Organization Ontology [[ORG]]</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a human user can understand the documentation
              associated with a vocabulary. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabDocum">R-VocabDocum</a>
            </p>
          </section>
        </div>
        <!-- end of Document Vocabularies BP -->
        <!-- begin of Share Open Vocabularies BP -->
        <div class="practice">
          <p><span id="ShareOpenVocabularies" class="practicelab"> Share
              vocabularies in an open way </span></p>
          <p class="practicedesc"> Vocabularies <em class="rfc2119">should</em>
            be shared in an open way </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Sharing vocabularies in an open way may increase the usage of a
              data vocabulary and help to understand the relationships among
              different vocabularies.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>The vocabulary should be available for data consumers to use or
              re-use it.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide the vocabulary under an open license such as Creative
              Commons Attribution License CC-BY [[CC-ABOUT]]. Create entries for
              the vocabulary in repositories such as <a href="http://lov.okfn.org/"><abbr

                  title="Linked Open Vocabularies">LOV</abbr></a>, <a href="http://prefix.cc">Prefix.cc</a>,
              <a href="http://bioportal.bioontology.org/">Bioportal</a> and the
              European Commission's <a href="https://joinup.ec.europa.eu/catalogue/repository">Joinup</a>.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that an open license is available looking for URL or link
              to the document where the copyright is provided. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabOpen">R-VocabOpen</a></p>
          </section>
        </div>
        <!-- end of Share Open Vocabularies BP -->
        <!-- begin of Versioning Vocabularies BP -->
        <div class="practice">
          <p><span id="VersioningVocabularies" class="practicelab"> Vocabulary
              versioning </span></p>
          <p class="practicedesc">Vocabularies <em class="rfc2119">should</em>
            include versioning information </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Versioning information guarantees compatibility over time by
              providing a way to compare different versions as the vocabulary
              evolves.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>It should be possible to identify changes to a vocabulary over
              time.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>A vocabulary may be given a unique identifier for 'the latest version'
              that remains stable over time, even as the vocabulary evolves. In
              addition, each version of the vocabulary has its own unique identifier.
              URI versioning for W3C documents provides examples. The latest version of this
              document is always found at <a href="http://www.w3.org/TR/dwbp/">http://www.w3.org/TR/dwbp/</a>
              but individual versions such as <a href="http://www.w3.org/TR/2015/WD-dwbp-20150224/">http://www.w3.org/TR/2015/WD-dwbp-20150224/</a>
              each have their own URL as well so that
              an initial effort can be made towards understanding, characterizing and tracking data evolution 
              and specific versions pointed to if required.</p>
            <p>Several vocabularies, including OWL [[OWL2-OVERVIEW]] and
              schema.org [[SCHEMA-ORG]], include properties for version numbers.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Different versions of a vocabulary can be easily identified; </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabVersion">R-VocabVersion</a>
            </p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin of re-use Vocabularies BP -->
        <div class="practice">
          <p><span id="re-usingVocabularies" class="practicelab">Re-use
              vocabularies</span></p>
          <p class="practicedesc"> Existing reference vocabularies <em class="rfc2119">should</em>
            be re-used where possible </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>re-using vocabularies increases interoperability and reduces
              redundancies between vocabularies, encouraging re-use of the data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Datasets (and vocabularies) should re-use core vocabularies.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <!--
            <p>Before defining any new vocabulary, a first preliminary step               is to analyze whether there are any              other public vocabularies that have been previously applied to the              same scope of knowledge we intend to work with. In case we find              any, there are several criteria that we <em class="rfc2119">should</em>              consider to assess the suitability of re-using that vocabulary for              our use case:</p>            <ul>              <li>Frequent use: Although there is an increasingly number of                available vocabularies, just a reduced number of them have been                internationally recognized as standards de jure or de facto.                Common vocabularies greatly facilitate re-use, so we should                prioritize those that have demonstrated previous broad adoption.</li>              <li>Expressiveness: it is important to assess to what extent the                candidate vocabulary may cover all aspects included in our                dataset, as well as whether the expressiveness degree is                sufficient for the disaggregation level of our data.</li>              <li>Activity and maintenance: the vocabulary <em class="rfc2119">should</em>                be actively maintained, and offer a clear policy to collect                feedback and perform updates.</li>              <li>Quality of publication: as per our best practice "Document                vocabularies" above, the vocabularies <em class="rfc2119">should</em>                have sufficient documentation to be able to interpret the                meaning of their elements in a unambiguous way. In addition,                vocabularies that are <a href="http://www.w3.org/TR/swbp-vocab-pub/">designed                  and published under the Linked Data paradigm</a> will offer                enhanced reusability.</li>            </ul> -->
            <p>The <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Standard
                Vocabularies</a> section of the W3C Best Practices for
              Publishing Linked Data [[LD-BP]] provides guidance on the
              discovery, evaluation and selection of existing vocabularies.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that terms used do not replicate those defined by
              vocabularies in common use within the same domain.</p>
            <!--
            <p>Verify whether for any new vocabulary developed an analog              reference one may already be publicly available on the Web.</p>            <ol>              <li>Vocabularies Search tools: <a href="http://ws.nju.edu.cn/falcons/objectsearch/index.jsp">                  Falcons</a>, <a href="http://watson.kmi.open.ac.uk/WatsonWUI/">Watson</a>,                <a href="http://sindice.com/">Sindice</a>, <a href="http://swoogle.umbc.edu/">Swoogle</a>,                <a href="http://vocab.org">vocab.org</a> or others</li>              <li>Vocabularies Repositories: <a href="http://lov.okfn.org/dataset/lov/">LOV</a>,                <a href="http://bioportal.bioontology.org/">BioPortal</a>, and <a                  href="https://joinup.ec.europa.eu/catalogue/repository">JoinUp</a>;              </li>              <li>Inventories: <a href="http://www.w3.org/standards/">W3C                  Standards</a> or domain-specific inventories like this <a href="http://www.w3.org/2005/Incubator/lld/XGR-lld-vocabdataset/">Library                  Linked Data Incubator Group report</a>. </li>            </ol>            <p>Verify that when no analog reference vocabulary may already be              available at least core elements from base vocabularies, such as              the <a href="http://dublincore.org/documents/dcmi-terms/">DCMI                Metadata Terms</a>, <a href="http://xmlns.com/foaf/spec/">FOAF</a>,              <a href="http://rdfs.org/sioc/spec/">SIOC</a>, <a href="http://www.w3.org/TR/vcard-rdf/">vCard</a>,              the <a href="http://www.w3.org/ns/locn">Location Core Vocabulary</a>,              the <a href="http://www.w3.org/2003/01/geo/wgs84_pos">W3C WGS84                Geo Positioning vocabulary</a> or the <a href="http://creativecommons.org/ns">Creative                Commons Rights Expression Language</a>, are re-used instead of              re-defined.</p> -->
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>
            </p>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin of Not Over formalize Vocabularies BP -->
        <div class="practice">
          <p><span id="ChoseRightFormalizationLevel" class="practicelab">Choose
              the right formalization level</span></p>
          <p class="practicedesc">When creating or re-using a vocabulary for an
            application, a data publisher <em class="rfc2119">should</em> opt
            for a level of formal semantics that fit data and applications.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Formal semantics may help one to establish precise specifications
              that support establishing the intended meaning of the vocabulary
              and the performance of complex tasks such as reasoning. On the
              other hand, complex vocabularies require more effort to produce
              and understand, which could hamper their re-use, as well as the
              comparison and linking of datasets exploiting them. Highly
              formalized data is also harder to exploit by inference engines:
              for example, using an OWL class in a position where a SKOS concept
              is enough, or using OWL classes with complex OWL axioms raises the
              formal complexity of the data according to the OWL Profiles
              [[OWL2-PROFILES]]. Data producers should therefore seek to
              identify the right level of formalization for particular domains,
              audiences and tasks, and maybe offer different formalization
              levels when one size does not fit all.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>The data supports all application cases but should not be more
              complex to produce and re-use than necessary;</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Identify the "role" played by the vocabulary for the datasets,
              say, providing classes and properties used to type resources and
              provide the predicates for RDF statements, or elements in an XML
              Schema, as opposed to providing simple concepts or codes that are
              used for representing attributes of the resources described in a
              dataset. When simpler models are enough to convey the necessary
              semantics, represent vocabularies using them. For instance, for
              Linked Data, SKOS may be preferred for simple vocabularies as
              opposed to formal ontology languages like OWL; see for example how
              <a href="http://www.w3.org/TR/vocab-data-cube/#schemes">concept
                schemes and code lists</a> are used in the RDF Data Cube
              Recommendation [[QB]].</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>For formal knowledge representation languages, applying an
              inference engine on top of the data that uses a given vocabulary
              does not produce too many statements that are unnecessary for
              target applications.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabDocum">R-VocabDocum</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityComparable">R-QualityComparable</a>
            </p>
          </section>
        </div>
        <div class="issue">The best practice on formalization above (especially
          sections "Intended outcome" and "How to test") should be re-written in
          a more technology-neutral way. <a href="https://www.w3.org/2013/dwbp/track/issues/144">Issue-144</a></div>
        <!-- end of Not Over formalize Vocabularies BP -->
        <!--        <h3>How to choose vocabularies?</h3>
        <p> It is very important to know how to choose the vocabulary to be          re-used. For doing this, see <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Vocabulary            Checklist</a> </p>        <div class="issue"> The <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Vocabulary            Checklist</a> from the Best Practices for Publishing Linked Data          overlaps quite a lot with the best practices from this section. Should          we clarify the difference in positioning? Is there one?          <a href="https://www.w3.org/2013/dwbp/track/issues/124">              Issue-124</a></p>        </div> -->
      </section>
      <!-- end of Data Vocabularies -->
      <!-- begin of Data Granularity -->
      <!-- 
      <section id="granularity">        <h3>Data Granularity</h3>        <p>The section on granularity</p>              </section>      -->
      <!-- end of Data Granularity -->
      <!-- begin of Sensitive Data -->
      <section id="sensitive">
        <h3>Sensitive Data</h3>
        <p>Sensitive data is any designated data or metadata that is used in
          limited ways and/or intended for limited audiences. Sensitive data may
          include personal data, corporate or government data, and mishandling
          of published sensitive data may lead to damages to individuals or
          organizations.</p>
        <p>To support best practices for publishing sensitive data, data
          publishers should identify all sensitive data, assess the exposure
          risk, determine the intended usage, data user audience and any related
          usage policies, obtain appropriate approval, and determine the
          appropriate security measures needed to taken to protect the data.
          Appropriate security measures should also account for secure
          authentication, like the use of HTTPS.</p>
        <p>At times, because of sharing policies sensitive data may not be
          available in part or in its entirety. Data unavailability represents
          gaps that may affect the overall analysis of datasets. To account for
          unavailable data, data publishers should publish information about
          unavoidable data gaps.</p>
        <!-- begin of Preserve Privacy BP -->
        <div class="practice">
          <p><span id="PreservePrivacy" class="practicelab">Preserve people's
              right to privacy </span></p>
          <p class="practicedesc">Data <em class="rfc2119">must not</em>
            infringe a person's right to privacy.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Data publishers should preserve the privacy of individuals where
              the release of personal information would endanger safety
              (unintended accidents) or security (deliberate attack). Privacy
              information might include: full name, home address, mail address,
              national identification number, IP address (in some cases),
              vehicle registration plate number, driver's license number, face,
              fingerprints, or handwriting, credit card numbers, digital
              identity, date of birth, birthplace, genetic information,
              telephone number, login name, screen name, nickname, health
              records etc.</p>
            <p>Data publishers should identify all personal data, assess the
              exposure risk, determine the intended usage, data user audience
              and any related usage policies, obtain appropriate approval, and
              determine the appropriate security measures needed to taken to
              protect the data including secure authentication and use of HTTPS
              for data transmission.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data that can identify an individual person must not be published
              without their consent.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
          </section>
          <p>The data publisher should establish a security plan for publishing
            data and metadata. The plan should include preparatory steps to
            ensure personal data is protected or removed prior to publication.
            All steps need to be followed prior to publication of new data or
            new data formats particularly binary formats (word processing,
            spreadsheet etc) that may embed personal metadata in files.</p>
          <p>Identify any personal data exposure risks. Write a security plan
            for publishing data and metadata that includes clear guidelines to
            follow. Prior to publication put security measures in place and
            follow them. In preparation to publication review data to ensure
            compliance.</p>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Write and test a plan for reviewing, curating and vetting data
              prior to publication.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitivePrivacy">R-SensitivePrivacy</a></p>
          </section>
        </div>
        <!-- end of Preserve Privacy BP -->
        <!-- begin of Preserve Security BP
        <div class="practice">          <p><span id="PreserveSecurity" class="practicelab">Preserve              organization's security </span></p>          <p class="practicedesc">Data <em class="rfc2119">should</em> not            infringe an organization's security (local government, national            government, business). </p>          <section class="axioms">            <p class="subhead">Why</p>          </section>          <section class="description">            <p class="subhead">What</p>          </section>          <section class="outcome">            <p class="subhead">Intended Outcome</p>          </section>          <section class="how">            <p class="subhead">Possible Approach to Implementation</p>          </section>          <section class="test">            <p class="subhead">How to Test</p>            <p> </p>          </section>          <section class="ucr">            <p class="subhead">Evidence</p>            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitiveSecurity">R-SensitiveSecurity</a></p>          </section>        </div>        <!-- end of Preserve Security BP -->
        <div class="practice">
          <p><span id="DataUnavailabilityReference" class="practicelab">Provide
              data unavailability reference</span></p>
          <p class="practicedesc">References to data that is not open, or is
            available under different restrictions to the origin of the
            reference, <em class="rfc2119">should</em> provide context by
            explaining how or by whom the referred to data can be accessed. </p>
         <!-- <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataHumanMachine">Provide
              metadata for both humans and machines</a> best practice. </p> -->
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Publishing online documentation about unavailable data due to
              sensitivity issues provides a means for publishers to explicitly
              identify knowledge gaps. This provides a contextual explanation
              for consumer communities thus encouraging use of the data that <em>is</em>
              available.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Publishers should provide information about data that is referred
              to from the current dataset but that is unavailable or only
              available under different conditions.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Data publishers may publish an HTML document that gives a
              human-readable explanation for data unavailability. RDF may be
              used to provide a machine readable version of the same
              information. If appropriate, consider editing the server's 4xx
              response page(s) to provide the information.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>If the dataset includes references to other data that is
              unavailable, check whether an explanation is available in the
              metadata and/or description of it.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataUnavailabilityReference">R-DataUnavailabilityReference</a></p>
          </section>
        </div>
        <!-- end of BP --> </section>
      <div class="issue"> Should we use SHOULD or MUST on BP for Sensitive Data?
        <a href="https://www.w3.org/2013/dwbp/track/issues/123"> Issue-123</a></div>
      <!-- end of Data Sensitive -->
      <!-- begin of Data Access -->
      <section id="dataAccess">
        <h3>Data Access</h3>
        <p>Providing easy access to data on the Web enables both humans and
          machines to take advantage of the benefits of sharing data using the
          Web infrastructure. By default, the Web offers access using Hypertext
          Transfer Protocol (HTTP) methods. This provides access to data at an
          atomic transaction level. However, when data is distributed across
          multiple files or requires more sophisticated retrieval methods
          different approaches can be adopted to enable data access, including
          bulk download and <abbr title="Application Programming Interfaces">API</abbr>s.
          </p>
        <p>One approach is packaging data in bulk using non-proprietary file
          formats(for example zip files or tar files). Using this approach, bulk
          data is generally pre-processed server side where multiple files or
          directory trees of files are provided as one downloadable file. When
          bulk data is being retrieved from non-file system solutions, depending
          on the data user communities, the data publisher can offer APIs to
          support a series of retrieval operations representing a single
          transaction.</p>
        <p>For data that is streaming to the Web in “real time” or “near real
          time”, data publishers must publish data or use APIs to enable
          immediate access to data, allowing access to critical time sensitive
          data, such as emergency information, weather forecasting data, or
          published system metrics. In general, APIs should be available to
          allow third parties to automatically search and retrieve data
          published on the Web. </p>
        <!-- begin of BP Bulk Access-->
        <div class="practice">
          <p><span id="BulkAccess" class="practicelab">Provide bulk download </span></p>
          <p class="practicedesc">Data <em class="rfc2119">should</em> be
            available for bulk download. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>When web data is distributed across many URLs and logically
              organized as one container, accessing the data in bulk is useful.
              Bulk access provides a consistent means to handle the data as one
              container. Without it, individually accessing data is cumbersome
              leading to inconsistent approaches to handling the container.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> It should be possible to download data on the Web in bulk. Data
              publishers should provide a way either through bulk file formats
              or APIs for consumers to access this type of data.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Depending on the nature of the data and consumer needs possible
              approaches could include:</p>
            <ul>
              <li>Preprocessing a copy of the data in compressed archive format
                where the data more easily accessible as one URL. This is
                particularly useful for handling data that changes infrequently
                or on a scheduled basis.</li>
              <li>Hosting an API such as a REST or SOAP service that dynamically
                retrieves individual data and returns a bulk container. This
                approach is useful when for capturing a snapshot of the data.
                The API can also be useful for consumers to customize what they
                want included or excluded. </li>
              <li>Hosting a database, web page, or SPARQL endpoint that contains
                discoverable metadata [[VOCAB-DCAT]] describing the container
                and data URLs associated with the container.</li>
            </ul>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p class="subhead"></p>
            <p>Humans can retreive copies of preprocessed bulk data through
              existing tools such as a browser. Clients can test bulk access
              through an API or queries to web resources with discoverable
              metadata about the bulk data. </p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessBulk">R-AccessBulk</a></p>
          </section>
        </div>
        <!-- end of BP Bulk Access -->
        <!-- begin of BP Bulk Access 2-->
        <div class="practice">
          <p><span id="BulkAccess2" class="practicelab">Follow REST principles
              when designing APIs</span></p>
          <p class="practicedesc">APIs for accessing data <em class="rfc2119">should</em>
            follow <abbr title="Representational State Transfer">REST</abbr>
            architectural approaches.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Considering RESTful architectural aspects when designing an APIs
              can guarantee easier development, use of pre-existing
              infrastructure (the Web), a shorter learning curve for developers
              that want to build applications that access data. It also assures
              sustainability as "the technologies that make up this foundation
              include the Hypertext Transfer Protocol (HTTP), Uniform Resource
              Identifier (URI), markup languages such as HTML and XML, and
              Web-friendly formats" [[RICHARDSON]]. Furthermore, it can mitigate
              the use of specific clients or the need of <abbr title="Universal Description, Discovery and Integration">UDDI</abbr>.</p>
            <p>APIs are frequently constructed over different approaches, such
              as SOAP. For data on the Web context, the architecture of the Web
              itself described at the documentation of REST architectural style
              offers the same entry for humans and machines to access data. If
              humans already have access to data in URLs, it can be also
              structured for offering multiple representations for formats and
              use content negotiation between applications easily.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <ul>
              <li>It should be possible for machines to access data in a variety
                of formats from the same URI through content negotiation.</li>
              <li> It should be possible for data consumers to access data using
                browser as a client. </li>
            </ul>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Design always RESTful APIs using HTTP and good pragmatic REST
              principles. There is no unique agreed set of principles for REST
              APIs, some are implicitly defined by the HTTP standard and others
              have emerged on a consensus base or even are still under
              discussion. The following are a set of rules widely adopted so
              far:</p>
            <ul>
              <li>Use hierarchical, readable and technology agnostic Uniform
                Resource Identifiers (URIs) to address resources in a consisten
                way.</li>
              <li>Use the URI path to convey your Resources and Collections
                model.</li>
              <li>Use nouns but no verbs (except for Controllers that does not
                involve resources). Use HTTP verbs instead to operate on the
                Collections and Resources.</li>
              <li>Use standard HTTP methods accordingly to their expected
                default behavior. GET method and query parameters should not
                alter the state.</li>
              <li>Use HTTP headers to provide metadata and for the serialization
                of data formats. Support multiple formats.</li>
              <li>Use HTTP status codes (including error codes) accordingly to
                their original purpose.</li>
              <li>Simplify associations. Use query parameters to hide complexity
                and provide filtering, sorting, field selection and paging for
                collections.</li>
              <li>Version your API. Never release an API without a version and
                make the version mandatory.</li>
            </ul>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Use API testing tools to compare benefits of implementing RESTful
              design.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessBulk">R-AccessBulk</a></p>
          </section>
        </div>
        <!-- end of BP BulkAccess 2-->
        <!-- begin of BP Access Real-time-->
        <div class="practice">
          <p><span id="AccessRealTime" class="practicelab">Provide real-time
              access </span></p>
          <p class="practicedesc">Where data is produced in real-time, it <em class="rfc2119">should</em>
            be available on the Web in real-time. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> The presence of real-time data on the web enables access to
              critical time sensitive data, and encourages the development of
              real-time web applications. Real-time access is dependent on
              real-time data producers making their data readily available to
              the data publisher. The necessity of providing real-time access
              for a given application will need to be evaluated on a case by
              case basis considering refresh rates, latency introduced by data
              post processing steps, infrastructure availability, and the data
              needed by consumers. In addition to making data accessible, data
              publishers may provide additional information describing data
              gaps, data errors and anomolies, and publication delays.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data should be available at real time or near real time, where
              real-time means a range from milliseconds to a few seconds after
              the data creation, and near real time is a predetermined delay for
              expected data delivery. </p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Real-time data accessibility may be achieved through two means: </p>
            <ul>
              <li> Push - as data is produced the producers communicates data to
                the data publisher either by disseminating data to the publisher
                or making storage available accessible to the data producer.</li>
              <li>On-Demand (Pull) - available real-time data is made available
                upon request. In this case, data publishers will provide an API
                to facilitate these read-only requests.</li>
            </ul>
            In addition to data access, to ensure credibility providing access
            to error conditions, anomolies, and instrument "house keeping" data
            enhance real-time applications ability to interpret and convey
            real-time data quality to consumers.
            <p></p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            To adequately test real time data access, data will need to tracked
            from the time it is initially collected to the time it is published
            and accessed. [[PROV-O]] can be used to describe these activities.
            Caution should be used when analyzing real-time access for systems
            that consist of multiple computer systems. For example, tests that
            rely on wall clock time stamps may reflect inconsistences between
            the individual computer systems as opposed to data publication time
            latency. </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessRealTime">R-AccessRealTime</a></p>
          </section>
        </div>
        <!-- end of BP Access Real-time-->
        <!-- begin of BP Access Up to date -->
        <div class="practice">
          <p><span id="AccessUptoDate" class="practicelab">Provide data up to
              date </span></p>
          <p class="practicedesc"> Data <em class="rfc2119">must</em> be
            available in an up-to-date manner and the update frequency made
            explicit. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Data on the Web availability should closely coincide with data
              provided at creation time, collection time, or after it has been
              processed or changed. Carefully synchronizing data publication to
              the update frequency encourages data consumer confidence and
              re-use.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>When new data is provided or data is updated, it must be
              published to coincide with the data changes.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Implement an API to enable data access. When data is provided by
              bulk access, new files with new data should be provided as soon as
              additional data is created or updated. </p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Write test standard operating procedure for data publisher to
              keep test data on Web site up to date.</p>
            <p> Following standard operating procedure:</p>
            <ul>
              <li> Write test client to access published data. </li>
              <li> Access data and save first copy locally. </li>
              <li> Publish an updated version of data.</li>
              <li> Access data and save second copy locally.</li>
              <li> Compare first copy to second copy to verify change.</li>
            </ul>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessUptodate">R-AccessUptodate</a></p>
          </section>
        </div>
        <!-- begin of versions For API BP -->
        <div class="practice">
          <p><span id="versionsForAPI" class="practicelab">Maintain separate
              versions for a data API</span></p>
          <p class="practicedesc">If data is made available through an API, the
            API itself <em class="rfc2119">should</em> be versioned separately
            from the data. Old versions <em class="rfc2119">should</em>
            continue to be available.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Developers need to be made aware of changes to an API so that
              they can update their code to use it. When an API is changed, as
              opposed to when the data it makes available is changed, releasing
              it as a new version makes it possible to gracefully transition
              from the old version to the new one. Keeping the older versions
              available avoids breaking applications that cannot be updated.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>It should be possible for developers to transition easily from
              one version of the API to another. Applications that are
              impractical to transition should continue to work. The API version
              should not be updated when data versions are updated, only when
              the API itself changes, and that should be infrequent.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Release updates to your API under a slightly different base URI
              so that older versions remain available under the previous base
              URI. For example, <a href="http://myapi.org/v1/dogs/alfred">http://myapi.org/v1/dogs/alfred</a>
              retrieves the older version of data about a dog named Alfred, and
              <a href="http://myapi.org/v2/dogs/alfred">http://myapi.org/v2/dogs/alfred</a>
              retrieves the newer version of data about Alfred. Keeping the
              version number as far to the left as possible in the API call
              allows developers to switch to the newer version with the least
              effort.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Existing calls to the API should continue to work when the API is
              updated. New calls to a slightly different base URI should
              retrieve data according to the new rules.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataVersion">R-DataVersion</a></p>
          </section>
        </div>
        <!-- end of versions For API BP --> </section>
      <!-- end of BP Access Up to date-->
      <!-- end of Data Access -->
      <!-- begin of Data Preservation -->
      <section id="dataPreservation">
        <h3>Data Preservation</h3>
        <p>Data preservation is a well understood and commonly performed task
          for static and self-contained data. This commonly includes the
          following steps:</p>
        <ul>
          <li>ingest the data and assign a persistent identifier to it;</li>
          <li>ensure the data is correctly stored and prevent bit rot;</li>
          <li>provide access to the data and perform format translation if
            needed.</li>
        </ul>
        <p>The model most commonly referred to is the Open Archival Information
          System [[OAIS]]. Many digital preservation institutions are
          implementing this model or some variant of it. Web pages can be
          preserved following the same strategies, considering a Web site as a
          static data set that is self-contained and can be preserved as a snap
          shot at a fixed time. When preserving data on the Web some new
          elements have to be taken into account:</p>
        <ul>
          <li>the persistent re-use (URIs) used across the Web may be related to
            live data that can change;</li>
          <li>the meaning of a resource is contextualized by the other resources
            it is linked to;</li>
          <li>documents fetched in HTML, RDF/XML of JSON, for instance, are only
            one of the many possible serializations of the data they represent.</li>
        </ul>
        <p>The preservation of Web data should generally focus on the
          preservation of the description of entities.</p>
        <div class="issue"> The Working group has not yet reached consensus on
          whether data preservation is in scope and, if so, which aspects of it.
          <a href="https://www.w3.org/2013/dwbp/track/issues/143">Issue 143</a>.
        </div>
      </section>
      <!-- end of Data Preservation -->
      <!-- begin Feedback -->
      <section id="feedback">
        <h3>Feedback</h3>
        <p>Publishing data on the Web enables data sharing on a large scale,
          providing data access to a wide range of audiences with different
          levels of expertise. Data publishers want to ensure that the data
          published is meeting the data consumer needs and user feedback is
          crucial. Feedback has benefits for both data publishers and data
          consumers, helping data publishers to improve the integrity of their
          published data, as well as to encourage the publication of new data.
          Feedback allows data consumers to have a voice describing usage
          experiences (e.g. applications using data), preferences and needs.
          When possible, feedback should also be publicly available for other
          data consumers to examine. Making feedback publicly available allows
          users to become aware of other data consumers, supports a
          collaborative environment, and allows user community experiences,
          concerns or questions are currently being addressed.</p>
        <p>From a user interface perspective there are different ways to gather
          feedback from data consumers, including site registration, contact
          forms, quality ratings selection, surveys and comment boxes for
          blogging. From a machine perspective the data publisher can also
          record metrics on data usage or information about specific
          applications consumers are currently relying upon. Feedback such as
          this establishes a line of communication channel between data
          publishers and data consumers. In order to quantify and analyze usage
          feedback, it should be recorded in a machine-readable format. Blogs
          and other publicly available feedback should be displayed in a
          human-readable form through the user interface. </p>
        <p> This section provides some BP to be followed by data publishers in
          order to enable data consumers to provide feedback about the consumed
          data. This feedback can be for humans or machines. </p>
        <!-- begin of BP Gather Feedback -->
        <div class="practice">
          <p><span id="GatherFeedback" class="practicelab">Gather feedback from
              data consumers </span></p>
          <p class="practicedesc"> Data publishers <em class="rfc2119">should</em>
            provide a means for consumers to offer feedback.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing feedback contributes to improving the quality of
              published data, may encourage publication of new data, helps data
              publishers understand data consumers needs better and, when
              feedback is made publicly available, enhances the consumers'
              collaborative experience.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>It should be possible for data consumers to provide feedback and
              rate data in both human and machine-readable formats. The feedback
              should be Web accessible and it should provide a URL reference to
              the corresponding dataset.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide data consumers with one or more feedback mechanisms
              including, but not limited to: a registration form, contact form,
              point and click data quality rating buttons, or a comment box for
              blogging.</p>
            <p>Collect feedback in machine-readable formats to represent the
              feedback and use a vocabulary to capture the semantics of the
              feedback information.
              <!-- The definition of a Data Usage Vocabulary is
              included in the activity of the DWBP group in order to support in              the implementation of this best practice. --></p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <ul>
              <li>Demonstrate how feedback can be collected from data consumers.
              </li>
              <li>Verify that the feedback is persistently stored. If the
                feedback is made publicly available verify that a URL links back
                to the published data being referenced.</li>
              <li>Check that the feedback format conforms to a known
                machine-readable format specification in current use among
                anticipated data users. </li>
            </ul>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UsageFeedback">R-UsageFeedback</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">R-QualityOpinions</a></p>
          </section>
        </div>
        <!-- end of BP Gather Feedback --> </section>
      <!-- end Feedback -->
      <!-- end best practices --> </section>
    <section id="conclusions">
      <h2>Conclusions</h2>
    </section>
    <section class="appendix">
      <h2>Acknowledgements</h2>
      <p>The editors gratefully acknowledge the contributions made to this
        document by all members of the working group and the chairs: Hadley
        Beeman, Steve Adler, Yaso Córdova, Deirdre Lee.</p>
    </section>
  </body>
</html>
