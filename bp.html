<!DOCTYPE html>
<html>
  <head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type">
    <meta name="generator" content="HTML Tidy for HTML5 (experimental) for Linux https://github.com/w3c/tidy-html5/tree/c63cc39">
    <meta content="width=device-width,initial-scale=1" name="viewport">
    <title>Data on the Web Best Practices</title>
    <script class="remove" src="http://www.w3.org/Tools/respec/respec-w3c-common"></script>
    <script class="remove" src="bpconfig.js"></script>
    <script src="cross-dom.js" type="text/javascript"></script>
    <script>
/* *********************************************
This script auto-generates the lists of BPs by benefit. It works by picking
up the ul of class 'benefitsList'. If there is no JavaScript, that list still
exists as a normal ul. If JS is active, the list is replaced by the icons
************************************************ */

      window.onload=init;

function bpObject(t,id,b,reqs) {
  this.title = t;   // The BP's title
  this.id = id      // Its id
  if (b != undefined) {
    var benefitList = new Array () ;
    for (var i = 0; i < b.length; i++) {
      benefitList.push(b[i].textContent);
    }
    this.benefits = benefitList;       // Its benefits in an array
  }
	var requirementList = new Array();
	for (var i = 0; i < reqs.length; i++) {
		requirementList.push(reqs[i].hash.substring(1));
	}
	this.requirements = requirementList;
}

function benefitObject(b) {
  this.name = b;   // The benefit's name
  this.id = b.toLowerCase();  // The benefit's id which is an all lower case version of the name
  // I'd like to create the image object here and reuse it but it doesn't seem to work properly sadly.
/*  var img = document.createElement('img');
  img.src= 'images/' + b.toLowerCase() + '.svg';
  img.alt= b;
  img.classList.add('benefitIcon');
  this.img = img; */
}

function createBenefitsTable(BPList) {

  // function to generate table of bp vs. benefits

  var benefitsTable = document.getElementById('bpbenefitstable');
  var tbody = benefitsTable.getElementsByTagName('tbody')[0];

  BPList.forEach(function(bp){
    var row = tbody.insertRow(tbody.rows.length); // new row for the table
    var cellBp = row.insertCell(0);               // cell for BP title
    var cellBenefits = row.insertCell(1);         // cell for benefits
    var bpTitle = document.createTextNode(bp.title);
    var bpLink = document.createElement('a');

    bpLink.setAttribute('href', '#'+bp.id);
    bpLink.appendChild(bpTitle);
    cellBp.appendChild(bpLink);  // put BP link on the cell

    var ul = document.createElement('ul');
    ul.setAttribute('class', 'benefitsList');  // create a new ul for benefitsList

    bp.benefits.forEach(function(benefit){  // iterate over benefits of the BP
      var li = document.createElement('li');
      var benefitText = document.createTextNode(benefit);
      li.appendChild(benefitText);
      ul.appendChild(li);
    });
    cellBenefits.appendChild(ul);
  });
}

function updateBenefitListReuse() {
  var benefitListReuse = document.getElementById('benefitListReuse');
  var ul = benefitListReuse.getElementsByTagName('ul')[0];

  benefitListReuse.removeChild(ul);

  var p = document.createElement('p');
  p.appendChild(document.createTextNode('All Best Practices'));
  benefitListReuse.appendChild(p);
}

function createRequirementsTable(BPlist) {
	var reqs = new Array();
  var requirmentsTable = document.getElementById('requirementsbpstable');
  var tbody = requirmentsTable.getElementsByTagName('tbody')[0];

	BPlist.forEach(function(bp){
		bp.requirements.forEach(function(req){
			if (reqs[req] !== undefined) {
				reqs[req].push(bp);
			}
			else {
        reqs.push(req);
        reqs[req] = new Array();
        reqs[req].push(bp);
      }

		});
	});
  reqs.forEach(function(req){
    var row = tbody.insertRow(tbody.rows.length); // new row for the table
    var cellReq = row.insertCell(0);         // cell for requirement
    var cellBps = row.insertCell(1);               // cell for BPs
    var reqLink = document.createElement('a');

    reqLink.setAttribute('href', 'https://www.w3.org/TR/dwbp-ucr/#'+req);
    reqLink.appendChild(document.createTextNode(req));
    cellReq.appendChild(reqLink);

    reqs[req].forEach(function(bp){
      var p = document.createElement('p');
      var bpLink = document.createElement('a');

      bpLink.setAttribute('href', '#'+bp.id);
      bpLink.appendChild(document.createTextNode(bp.title));
      p.appendChild(bpLink);
      cellBps.appendChild(p);
    });
  });

}

function init() {

  // Need an array of objects for the benefits

  var theBenefits = new Array ();
  theBenefits.push(new benefitObject('Reuse')) ;
  theBenefits.push(new benefitObject('Access')) ;
  theBenefits.push(new benefitObject('Discoverability')) ;
  theBenefits.push(new benefitObject('Processability')) ;
  theBenefits.push(new benefitObject('Trust')) ;
  theBenefits.push(new benefitObject('Interoperability')) ;
  theBenefits.push(new benefitObject('Linkability')) ;
  theBenefits.push(new benefitObject('Comprehension')) ;


  // Get list of our BPs and put them in an array of objects

  var BPlist = new Array (); // This will be our array of BPs from the document
  var BPdivs = new Array ();
  BPdivs = document.getElementsByClassName('practice'); // This is the info we have effectively scraped from the page

  // Need the title and id of each one
  for (var i = 0; i < BPdivs.length; i++) {
    var t; var id; var b; var reqs;
    var BPtop = BPdivs[i].getElementsByClassName('practicelab');
    t = BPtop[0].textContent; // There should only be values in BPtop[0]
    id = BPtop[0].id;
    // Now we need the list of benefits for that BP
    var BPbenefitsList = BPdivs[i].getElementsByClassName('benefitsList');
    if (BPbenefitsList[0] != undefined) {
      b = BPbenefitsList[0].getElementsByTagName("li");
    } else {
      b = undefined;
    }
		var BPrequirementsList = BPdivs[i].getElementsByClassName('ucr')[0].getElementsByTagName('a');
		reqs = BPrequirementsList;
    BPlist.push(new bpObject(t, id, b, reqs)) ;
  }

  createBenefitsTable(BPlist); // Call function to create Benefits Table
  createRequirementsTable(BPlist); // Call function to create Requirements Table

  // Now create the panels
  var r;

  for (var i = 0; i < theBenefits.length; i++) {               // Working through the list of benefits
    r = document.createElement('div');                         // Need to create the div, ready to add the list items for this benefit
    r.classList.add('benefit-list-panel');
    r.id = 'benefitList' + theBenefits[i].name;
/*    var img = document.createElement('img');                    // Put the icon at the top
    img.src= 'images/' + theBenefits[i].name.toLowerCase() + '.svg';
    img.alt= theBenefits[i].name;
    img.classList.add('benefitIconPanel');
    r.appendChild(img); */
    var h = document.createElement('p');
    h.classList.add('benefitsPanelTitle');
    var ht = document.createTextNode(theBenefits[i].name);      // Create the heading for the div which is the benefit
    h.appendChild(ht);
    r.appendChild(h);
    // And add a UL
    var ul = document.createElement('ul');                      // Create the ul element that we're going to add each relevant BP to
    ul.id = theBenefits[i].id + 'BPs';

    for (var j = 0; j < BPlist.length; j++) {                   // Go through list of BPs in the doc
      if (typeof BPlist[j].benefits == 'object') {              // Do we have a list of benefits for this BP?
        for (var k = 0; k < BPlist[j].benefits.length; k++) {   // We need to look at the benefits the BP offers
          if (theBenefits[i].name == BPlist[j].benefits[k]) {   // We're looking at the i benefit in the list of possibles and the k benefit of BP j
            var li = document.createElement('li');              // If there's a match, create the li with the hyperlink
            var a = document.createElement('a');
            a.href = '#' + BPlist[j].id;
            var t = document.createTextNode(BPlist[j].title);
            a.appendChild(t);
            li.appendChild(a);
            ul.appendChild(li);                                 // Add this BP to the benefit div's list
          }
        }
      }
    }
    r.appendChild(ul);                                          // Add the ul with all its li elements to the div
    document.getElementById('benefitsTables').appendChild(r);   // Add the div to the doc
  }

  // Next we want to replace all text benefits with the relevant icon
  var bList = document.getElementsByClassName('benefitsList');  // get the set of ul elements we need to process
  for (var i = 0; i < bList.length; i++) {
    var listElements = bList[i].getElementsByTagName('li');       // Get the li elements within this ul
    for (var j = 0; j < listElements.length; j++) {
      for (var k = 0; k < theBenefits.length; k++) {              // Go through the benefits
        if (listElements[j].textContent == theBenefits[k].name) {  // The text in the current li element matches the current benefit, so we can make the swap

//          bList[i].removeChild(listElements[j]);                // This works but it destroys things as they're created. Should rearrange the loop but for now...
          listElements[j].classList.add('hidden');                // Hide the original li
          var l = document.createElement('li');                   // Create a new li
          l.classList.add('icon');
          var img = document.createElement('img');                // This is repetitive but I tried to create an img element in theBenefits but
          img.src= 'images/' + theBenefits[k].name.toLowerCase() + '.svg';  // For reasons I don't understand, it dowsn't work properly, this does.
          img.alt= theBenefits[k].name;
          img.classList.add('benefitIcon');
          img.classList.add(theBenefits[k].id + 'Icon');
          l.appendChild(img);                      // Add the img element from the current benefit
          bList[i].appendChild(l);                                // Add the li back into the current ul
        }
      }
    }
  }

  updateBenefitListReuse(); // replace ul>li of Benefits Reuse to text "All Best Practices"

  // Separately, we need to set up the cross dom for the challenges SVG

  initCrossDom();

}

    </script>
    <style type="text/css">

#bp-summary ul {
  list-style-type: none;
  padding-left: 0;
  line-height:1.6em;
  background-color: #FCFAEE;
}


.hidden {display:none}

ul.benefitsList li.icon {
  display:inline;
  list-style-type: none;
}

ul.benefitsList li.icon img {
  padding:0;
  margin-right:1em;
  max-width:60px;
  max-height: 70px;
}

ul.benefitsList li.icon img.comprehensionIcon, ul.benefitsList li.icon img.discoverabilityIcon, ul.benefitsList li.icon img.interoperabilityIcon, ul.benefitsList li.icon img.processabilityIcon {
  max-width:80px;
}

ul.benefitsList li.icon img.discoverabilityIcon, ul.benefitsList li.icon img.interoperabilityIcon, ul.benefitsList li.icon img.processabilityIcon {
  max-width:73px;
}

/* *************************************************************
These styles are for the lists of benefits
************************************************************** */
#benefitsTables {
	width: 100%;
	margin: 0 auto;
}

.benefit-list-panel {
  border-radius: 1em; /*(padrão)*/
  -moz-border-radius: 1em; /*(navegadores Flock e Firefox)*/
  -webkit-border-radius: 1em; /*(navegadores Chrome e Safari)*/
  padding: 0.2em 1em;
}

.benefit-list-panel ul {
  list-style-type:none;
  padding-left:0;
}

.benefit-list-panel ul li {
  font-size:smaller;
  line-height:1.4em;
}

.benefit-list-panel p.benefitsPanelTitle {
	font-weight: bold;
	text-transform: uppercase;
	text-align: center;
}

#benefitListReuse {
	background: #B0CC9B;
	border: 1px solid #387F05;
}

#benefitListAccess {
	background: #E8F1FA;
	border: 1px solid #81B3E0;
}

#benefitListTrust {
	background: #E6BE9F;
	border: 1px solid #BF5B0E;
}

#benefitListDiscoverability {
	background: #CCBEB5;
	border: 1px solid #7F5C46;
}

#benefitListProcessability {
	background: #C5B5DE;
	border: 1px solid #6E46AD;
}

#benefitListInteroperability {
	background: #F3E09A;
	border: 1px solid #E0B200;
}

#benefitListLinkability {
	background: #B9C1CC;
	border: 1px solid #50637F;
}

#benefitListComprehension {
	background: #B3B3B3;
	border: 1px solid #404040;
}


/* *******************************************
We reuse the 2 column style (for screens > 600 wide) from the list of BPs
to create the columns for the lists of benefits
********************************************** */

@media screen and (min-width: 600px) {
  #bp-summary ul, #benefitsTables {
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
    column-gap: 1em;
  }

/* We need to re-set the column number to 1 so that within each panel there is only 1 column */

  #benefitsTables .benefit-list-panel {
    column-count:1;
    -moz-column-count:1;
    -webkit-column-count:1;
    margin:.1em;
    display:inline-block;   /* This prevents single lists spanning multiple columns, thank you http://stackoverflow.com/questions/6682501/css3-columns-widows-orphans */
    width:90%; /* For somr reason some of the panels are wider than others, this stops that heppening */
  }
}

/* And we can go to three columns for bigger screens */

@media screen and (min-width: 850px) {
  #benefitsTables {
    column-count:3;
    -moz-column-count:3;
    -webkit-column-count:3;
    column-gap: 1em;
  }
}

/* Styles for the BPs themsevles */

.practice, #tempPractice {
  padding-left: 1em;
  background-color: #FCFAEE;
  border: thin solid #CCC;
  /*border-radius: 10px;*/
  margin-bottom: 1.5em;
}

#tempPractice .tempPracticelab {
  background-color:#dfffff;
  position: relative;
  top: -1.5em;
  font-weight:bold;
}

.practice p.practicedesc, #tempPractice p.tempPracticedesc {
  font-style:italic;
  border-bottom: thin solid black;
  position:relative;
  top:-1.5em;
  margin: 0 2em -1em 1em;
}

.subhead{
  font-weight:bold;
}
.benefits .stamp {
  height: 52px;
  width: 52px;
  margin-right: 4px;
  margin-bottom: 4px;
}

.benefits .stamp-template {
  height: 82px;
  width: 82px;
  margin-right: 4px;
  margin-bottom: 4px;
}


.practice dl dt #tempPractice dl dt{
  font-weight:normal;
}

figure {
  text-align:center;
}

figure#contextDiagram {
  width:60%;
  margin:0 auto;
}

figure figcaption {
  text-align:center;
  font-style:italic;
}

table#uripatternstable,
table.bptable {
  border-collapse: collapse;
  caption-side:bottom;
}
table#uripatternstable th, table#uripatternstable td,
table.bptable th, table.bptable td {
  border: 1px solid black;
  padding:0.3em;
}

table#uripatternstable caption,
table.bptable caption {
  margin:0.5em;
  font-style:italic;
}

.stmt
{
    padding: 3pt}

.stmt1
{
    column-count:2;
    -moz-column-count:2;
    -webkit-column-count:2;
    column-gap: 1em;
    background-color: #FCFAEE;
 }

  .expand{
    display:block;
    cursor: pointer;
  }
  .expand:hover {
    color: #3D3D3D;
  }
  .expand:before {
    font-weight: bold;
    content: "\25C6  Example (click to expand or collapse)";
  }
  .expand + input{
    display:none;
  }
  .expand + input + *{
    display:none;
  }
  .expand + input:checked + *{
    display:block;
  }

      				.benefits-itens {
					width: 100%;
					margin: 0 auto;
				}

				.benefits-itens .item {
					border-radius: 22px; /*(padrão)*/
					-moz-border-radius: 22px; /*(navegadores Flock e Firefox)*/
					-webkit-border-radius: 22px; /*(navegadores Chrome e Safari)*/
					width: 28%;
					padding: 20px;
					margin: 2px;
					font-size: 13px;
					line-height: 150%;
					float: left;
				}

				.benefits-itens .item .title {
					font-size: 16px;
					font-weight: 800;
					text-transform: uppercase;
					text-align: center;
				}
				.benefits-itens .reuse {
					background: #B0CC9B;
					border: 1px solid #387F05;
				}

				.benefits-itens .access {
					background: #E8F1FA;
					border: 1px solid #81B3E0;
				}

				.benefits-itens .trust {
					background: #E6BE9F;
					border: 1px solid #BF5B0E;
					float: right;
				}

				.benefits-itens .discoverability {
					background: #CCBEB5;
					border: 1px solid #7F5C46;
				}

				.benefits-itens .processability {
					background: #C5B5DE;
					border: 1px solid #6E46AD;
				}

				.benefits-itens .interoperability {
					background: #F3E09A;
					border: 1px solid #E0B200;
					float: right;
				}

				.benefits-itens .linkability {
					background: #B9C1CC;
					border: 1px solid #50637F;
				}

				.benefits-itens .comprehension {
					background: #B3B3B3;
					border: 1px solid #404040;
					float: right;
				}

				@media screen and (min-width: 1024px) {
					.benefits-itens .item {
							margin-left: 1.6%;
						}
				}

				@media screen and (max-width: 900px) {
					.benefits-itens .item {
								clear: both;
								display: inline-block;
								float: left !important;
								width: 90%;
						}
				}




  </style>
  </head>
  <body>
    <section id="abstract">
      <p>This document provides best practices related to the
        publication and usage of data on the Web designed to help support a
        self-sustaining ecosystem. Data should be discoverable and
        understandable by humans and machines. Where data is used in some way,
        whether by the originator of the data or by an external party, such
        usage should also be discoverable and the efforts of the data publisher
        recognized. In short, following these best practices will facilitate
        interaction between publishers and consumers.</p>
    </section>
    <section id="sotd">
      <p>This version of the document shows its expected scope and future
        direction. A template is used to show the "what", "why" and "how" of
        each best practice. Comments are sought on the usefulness of this
        approach and the expected scope of the final document.</p>
    </section>
    <section id="intro" class="informative">
      <h2>Introduction</h2>
      <p>The best practices described below have been developed to encourage and
        enable the continued expansion of the Web as a medium for the exchange
        of data. The growth of open data by governments across the world
        [[OKFN-INDEX]], the increasing publication of research data encouraged
        by organizations like the Research Data Alliance [[RDA]], the harvesting
        and analysis of social media, crowd-sourcing of information, the
        provision of important cultural heritage collections such as at the
        Bibliothèque nationale de France [[BNF]] and the sustained growth in the
        Linked Open Data Cloud [[LODC]], provide some examples of this
        phenomenon.</p>
      <p>In broad terms, data publishers aim to share data either openly or with
        controlled access. Data consumers (who may also be producers themselves)
        want to be able to find and use data, especially if it is accurate,
        regularly updated and guaranteed to be available at all times. This
        creates a fundamental need for a common understanding between data
        publishers and data consumers. Without this agreement, data publishers'
        efforts may be incompatible with data consumers' desires.</p>
      <p>The openness and flexibility of the Web creates new challenges for data
        publishers and data consumers, such as how to
        represent, describe and make data available in a way that it will be
        easy to find and to understand. In contrast to conventional databases,
        for example, where there is a single data model to represent the data
        and a database management system (DBMS) to control data access, data on
        the Web allows for the existence of multiple ways to represent and to
        access data. For more details about the challenges see the section <a href="#challenges">Data on the Web Challenges</a>.</p>
      <p>In this context, it becomes crucial to
        provide guidance to publishers that will improve consistency in the way
        data is managed, thus promoting the reuse of data and also to foster
        trust in the data among developers, whatever technology they choose to
        use, increasing the potential for genuine innovation.</p>
      <p>A general best practice to publish Data on the Web is to use standards. Different types of organizations specify standards that are specific to the publishing of datasets related to particular domains/applications, involving communities of users interested in that data. These standards define a common way of communicating information among the users of these communities. For example, publishing of timetables have two standards, the General Transit Feed Specification [[GTFS]] and the Service Interface for Real Time Information [[SIRI]], that specify, in a mixed way, standardize terms, standardized data formats and standardized data access. As was said before, the Best Practices proposed in this document serve a general purpose of publishing and using Data on the Web. These Best Practices are domain/application independent. They could be extended or complemented by other best practices documents or standards that cover the publishing of datasets in a more restricted universe.</p>
      <p>Taking that into account, this document sets out a series of best practices that will help publishers and consumers face the new challenges and opportunities posed by data on the Web. They intend to serve a general purpose of publishing and using Data on the Web, but they may be specialized according to specific domains, such as Spatial Data on the Web Best Practices [[SDW]].</p>
      <p>Best practices cover different aspects related to data publishing and
        consumption, like data formats, data access, data identifiers and
        metadata. In order to delimit the scope and elicit the required features
        for Data on the Web Best Practices, the <abbr title="Data on the Web Best Practices">DWBP</abbr>
        working group compiled a set of use cases [[UCR]] that represent
        scenarios of how data is commonly published on the Web and how it is
        used. The set of requirements derived from these use cases were used to
        guide the development of the best practices.</p>
      <p>The Best Practices proposed in this document are intended to serve a
        more general purpose than the practices suggested in Best Practices for
        Publishing Linked Data [[LD-BP]] since it is domain-independent and
        whilst it recommends the use of Linked Data, it also promotes best
        practices for data on the Web in formats such as CSV [[RFC4180]] and
        JSON [[RFC4627]]. The Best Practices related to the use of vocabularies
        incorporate practices that stem from Best Practices for Publishing
        Linked Data where appropriate.</p>
      <p>In order to encourage data publishers to adopt the DWBP, benefits were set: comprehension; processability; discoverability; reuse; trust; linkability; access; and interoperability. They are described and related to the Best Practices in the section <a href="#BP_Benefits">Best Practices Benefits</a>.</p>
    </section>
    <!--     <section id="conformance"> </section> -->
    <section id="audience" class="informative">
      <h2>Audience</h2>
      <p>This document provides best practices to those who publish data on the
        Web. The best practices are designed to meet the needs of information
        management staff, developers, and wider groups such as scientists
        interested in sharing and reusing research data on the Web. While data
        publishers are our primary audience, we encourage all those engaged in
        related activities to become familiar with it. Every attempt has been
        made to make the document as readable and usable as possible while still
        retaining the accuracy and clarity needed in a technical specification.</p>
      <p>Readers of this document are expected to be familiar with some
        fundamental concepts of the architecture of the Web [[WEBARCH]], such as
        resources and URIs, as well as a number of data formats. The normative
        element of each best practice is the <em>intended outcome</em>.
        Possible implementations are suggested and, where appropriate, these
        recommend the use of a particular technology such as CSV, JSON and RDF.
        A basic knowledge of vocabularies and data models would be helpful to
        better understand some aspects of this document. </p>
    </section>
    <section id="scope" class="informative">
      <h2>Scope</h2>
      <p>This document is concerned solely with best practices that:</p>
      <ul>
        <li>are specifically relevant to data published on the Web;</li>
        <li>encourage publication or reuse of data on the Web;</li>
        <li>can be tested by machines, humans or a combination of the two.</li>
      </ul>
      <p>As noted above, whether a best practice has or has not been followed
        should be judged against the <em>intended outcome</em>, not the <em>possible
          approach to implementation</em> which is offered as guidance. A best
        practice is always subject to improvement as we learn and evolve the Web
        together.</p>
    </section>
    <section id="context" class="informative">
      <h2>Context</h2>
      <p> In general, the Best Practices proposed for publication and usage of
        Data on the Web refer to <a href="#dataset">datasets</a> and <a href="#distribution">
          distributions</a>. Data is published in different distributions, which
        is a specific physical form of a dataset. By data, "we mean known facts
        that can be recorded and that have implicit meaning" [[Navathe]]. These
        distributions facilitate the sharing of data on a large scale, which
        allows datasets to be used for several groups of <a href="#data_consumer">
          data consumers </a>, without regard to purpose, audience, interest,
        or license. Given this heterogeneity and the fact that data publishers
        and data consumers may be unknown to each other, it is necessary to
        provide some information about the datasets which may also contribute to
        trustworthiness and reuse, such as: structural metadata, descriptive
        metadata, access information, data quality information, provenance
        information, license information and usage information. </p>
      <p> Other important aspect of publishing and sharing data on the Web
        concerns the architectural bases of the Web as discussed in [[WEBARCH]].
        The <abbr title="Data on the Web Best Practices">DWBP</abbr> document
        is mainly interested on the Identification principle that says that URIs
        should be used to identify resources. In our context, a resource may be
        a whole dataset or a specific item of given dataset. All resources
        should be published with stable URIs, so that they can be referenced and
        make links, via URI, between two or more resources.</p>
      <p>The following diagram illustrates the dataset composition (data values
        and metadata) together with other components related to the dataset
        publication and usage. Data values correspond to the data itself and may
        be available in one or more distributions, which should be defined by
        the publisher considering data consumer's expectations. The Metadata
        component corresponds to the additional information that describes the
        dataset and dataset distributions, helping the manipulation and the
        reuse of the data. In order to allow an easy access to the dataset and
        its corresponding distributions, multiple Dataset Access mechanisms
        should be available. Finally, to promote the interoperability among
        datasets it is important to adopt Data Vocabularies and Standards. </p>
      <img src="images/context.jpg" alt="Our Context" height="280" width="480">
    </section>
    <section id="namespaces" class="informative">
      <h2> Namespaces </h2>
<p> The following namespace prefixes are used throughout this document. </p>
      <table id="uripatternstable">
              <caption>Namespaces used in the document</caption>
              <tbody>
                <tr>
                  <th>Prefix</th>
                  <th>Namespace IRI</th>
                </tr>
                <tr>
                  <td>cnt</td>
                  <td>http://www.w3.org/2011/content</td>
                </tr>
                <tr>
                  <td>dcat</td>
                  <td>http://www.w3.org/ns/dcat#</td>
                </tr>
                 <tr>
                  <td>dct</td>
                  <td>http://purl.org/dc/terms/</td>
                </tr>
                <tr>
                  <td>dqv</td>
                  <td>http://www.w3.org/ns/dqv#</td>
                </tr>
                <tr>
                  <td>duv</td>
                  <td>http://www.w3.org/ns/duv#</td>
                </tr>
                <tr>
                  <td>foaf</td>
                  <td>http://xmlns.com/foaf/0.1/</td>
                </tr>
                <tr>
                  <td>oa</td>
                  <td>http://www.w3.org/ns/oa#</td>
                </tr>
                <tr>
                  <td>owl</td>
                  <td>http://www.w3.org/2002/07/owl#</td>
                </tr>
                <tr>
                  <td>pav</td>
                  <td>http://pav-ontology.github.io/pav/</td>
                </tr>
                <tr>
                  <td>prov</td>
                  <td>http://www.w3.org/ns/prov#</td>
                </tr>
                 <tr>
                  <td>rdf</td>
                  <td>http://www.w3.org/1999/02/22-rdf-syntax-ns#</td>
                </tr>
                <tr>
                  <td>rdfs</td>
                  <td>http://www.w3.org/2000/01/rdf-schema#</td>
                </tr>
                <tr>
                  <td>skos</td>
                  <td>http://www.w3.org/2004/02/skos/core#</td>
                </tr>
              </tbody>
       </table>
    </section>
    <section id="bp-template">
      <h2>Best Practices Template</h2>
      <p>This section presents the template used to describe Data on the Web
        Best Practices.</p>
      <div id="tempPractice">
        <p><span id="template" class="tempPracticelab">Best Practice Template</span></p>
        <p class="tempPracticedesc">Short description of the BP</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>This section answers two crucial questions:</p>
          <ul>
            <li>Why this is unique to publishing or reusing data on the Web? </li>
            <li>How does this encourages publication or reuse of data on the
              Web? </li>
          </ul>
        </section>
        <section class="description">A full text description of the problem
          addressed by the best practice may also be provided. It can be any
          length but is likely to be no more than a few sentences. </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>What it should be possible to do when a data publisher follows the
            best practice. </p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>A description of a possible implementation strategy is provided.
            This represents the best advice available at the time of writing but
            specific circumstances and future developments may mean that
            alternative implementation methods are more appropriate to achieve
            the intended outcome.</p>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Information on how to test the BP has been met. This might or might
            not be machine testable.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p>Information about the relevance of the BP. It is described by one
            or more relevant requirements as documented in the <a href="http://www.w3.org/TR/dwbp-ucr/">Data
              on the Web Best Practices Use Cases &amp; Requirements document</a></p>
        </section>
        <section class="benefits" typeof="bibo:Chapter" resource="" property="bibo:hasPart">
          <p class="subhead">Benefits</p>
          A <a href="#BP_Benefits"> benefit </a> represents an improvement in the way how datasets are available on the Web. A Best Practice can have one or more benefits. 
          <ul class="benefitsList">
            <!-- This text list is replaced by the icons by scripting -->
            <li>Reuse</li>
            <li>Comprehension</li>
            <li>Linkability</li>
            <li>Discoverability</li>
            <li>Trust</li>
            <li>Access</li>
            <li>Interoperability</li>
            <li>Processability</li>
          </ul>
        </section>
      </div>
    </section>
    <section id="bp-summary"></section>
    <section id="bestPractices">
      <h2>The Best Practices</h2>
      <p>This section contains the best practices to be used by data publishers in order to help them and data consumers to overcome the different challenges faced when publishing and consuming data on the Web. One or more best practices were proposed for each one of the challenges, which are described in the section <a href="#challenges">Data on the Web Challenges</a>.</p>
      <p>Each BP is related to one or more requirements from the <a href="http://www.w3.org/TR/dwbp-ucr/">Data on the Web Best Practices Use Cases &amp; Requirements document</a> document and the development of Data on the Web Best Practices was guided by these requirements, in such a way that each best practice should have at least one of these requirements as an evidence of its relevance.</p>
      <section id="basicExample">
        <h3>Basic Example</h3>
        <!-- <p> The example below serve as a basis for elaboration that will be
          described in subsequent sections. It helps to illustrate how best
          practices may be applied. </p>
        <aside class="example"> -->
          <p> John works for the Transport Agency of MyCity and he is in charge of publishing the data about bus stops of the city on the Web. John wants to publish these data for different types of data consumers such as developers interested on creating applications but also for software agents. It is really important that both humans and software agents can easily understand and process the data. He also expects the data to be available up to date and to be easily discoverable on the Web. </p>
          <!-- <p> Some requirements that should be addressed:</p>
          <ul>
            <li> The dataset for bus timetables must be available in two
              languages: English and Portuguese; </li>
            <li> Both datasets must be available in CSV and JSON-LD formats; </li>
          </ul> -->
        
        When necessary RDF examples in Turtle syntax will be used to show the result of the
        application of some best practices. 
      </section>
      
      <section id="metadata">
        <h3>Metadata</h3>
        <p>The Web is an open information space, where the absence of a specific
          context, such a company's internal information system, means that the
          provision of metadata is a fundamental requirement. Data will not be
          discoverable or reusable by anyone other than the publisher if
          insufficient metadata is provided. Metadata provides additional
          information that helps data consumers better understand the meaning of
          data, its structure, and to clarify other issues, such as rights and
          license terms, the organization that generated the data, data quality,
          data access methods and the update schedule of datasets. <br>
        </p>
        Metadata can be used to help tasks such as dataset discovery and reuse,
        and can be assigned considering different levels of granularity from a
        single property of a resource to a whole dataset, or all datasets from a
        specific organization. <br>
        <p>Metadata can be of different types. These types can be classified in
          different taxonomies, with different grouping criteria. For example, a
          specific taxonomy could define three metadata types according to
          descriptive, structural and administrative features. A different taxonomy could define
          metadata types with a scheme according to tasks where metadata are
          used, for example, discovery and reuse. </p>
        <!-- begin of Provide Metadata BP -->
        <div class="practice">
          <p><span id="ProvideMetadata" class="practicelab">Provide metadata</span></p>
          <p class="practicedesc">Metadata must be provided for both human users
            and computer applications.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing metadata is a fundamental requirement when publishing
              data on the Web because data publishers and data consumers may be
              unknown to each other. Then, it is essential to provide information
              that helps human users and computer applications to understand the
              data as well as other important aspects that describes a dataset
              or a distribution.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Human-readable metadata will enable humans to understand the metadata and machine-readable metadata will enable computer applications, notably user agents, to process the metadata.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            Possible approaches to provide <em>human readable metadata:</em><br>
            <ul>
              <li>to provide metadata as part of an HTML Web page</li>
              <li>to provide metadata as a separate text file</li>
            </ul>
            Possible approaches to provide <em>machine readable metadata:</em><br>
            <ul>
              <li> machine readable metadata may be provided in a serialization
                format such as Turtle and JSON, or it can be embedded in the
                HTML page using [[HTML-RDFA]] or [[JSON-LD]]. If multiple
                formats are published separately, they should be served from the
                same URL using content negotiation. Maintenance of multiple
                formats is best achieved by generating each available format on
                the fly based on a single source of the metadata.</li>
              <li> when defining machine readable metadata, reusing existing
                standard terms and popular vocabularies are strongly
                recommended. For example, Dublin Core Metadata (DCMI) terms
                [[DC-TERMS]] and Data Catalog Vocabulary [[VOCAB-DCAT]] should
                be used to provide descriptive metadata.</li>
            </ul>
            <aside class="example">
              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with a
                human-readable description of an available dataset.</p>
              <h5>Machine-readable</h5>
              <p><a href="dwbp-example.ttl">Example file</a> with a
                machine-readable description of an available dataset.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if all provided metadata are coherent with the described resource.</p>
            <p>Check if the metadata is available in a valid machine-readable format and without syntax error.</p>

          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable,
                </a><a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataDocum">R-MetadataDocum,
                </a><a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <li>Discoverability</li>
              <li>Processability</li>
            </ul>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin Discovery Metadata BP -->
        <div class="practice">
          <p><span id="DescriptiveMetadata" class="practicelab">Provide
              descriptive metadata</span></p>
          <p class="practicedesc">The overall features of datasets and
            distributions must be described by metadata.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Explicitly providing dataset descriptive information allows user
              agents to automatically discover datasets available on the Web and
              it allows humans to understand the nature of the dataset and its
              distributions. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Descriptive metadata will enable humans to interpret the nature of the dataset and its distributions and software agents will be able to automatically discover datasets and distributions.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Descriptive metadata can include the following overall features
              of a dataset:</p>
            <ul>
              <li>The <strong>title</strong> and a <strong>description</strong>
                of the dataset.</li>
              <li>The <strong>keywords</strong> describing the dataset. </li>
              <li>The <strong>date of publication</strong> of the dataset. </li>
              <li> The <strong>entity responsible (publisher)</strong> for
                making the dataset available.</li>
              <li> The <strong> contact point </strong> of the dataset.</li>
              <li> The <strong>spatial coverage </strong> of the dataset.</li>
              <li> The <strong> temporal period </strong> that the dataset
                covers.</li>
              <li> The <strong> themes/categories </strong> covered by a
                dataset. </li>
              <!--<li>Any <strong>variants</strong> (e.g. different
                  human-language translations) of data.</li>                <li><strong>Access mechanisms</strong> through which the data be                  accessed (see <a href="#access">Data Access</a>). </li> -->
            </ul>


            <!-- <p> The information above should be included both in the human
                understandable and the machine understandable versions of the                metadata. </p> -->
            <p>Descriptive metadata can include the following overall features
              of a distribution:</p>
            <ul>
              <li>The <strong>title</strong> and a <strong>description</strong>
                of the distribution.</li>
              <li>The <strong>date of publication</strong> of the distribution.
              </li>
              <li>The <strong>media type</strong> of the distribution. </li>
            </ul>
            <p>The machine readable version of the descriptive metadata can be
              provided using the vocabulary recommended by W3C to
              describe datasets, i.e. the Data Catalog Vocabulary
              [[VOCAB-DCAT]]. This provides a framework in which datasets can be
              described as abstract entities. </p>
            <!--<p>See also <a href="#AdministrativeMetadata">Provide
                Administrative Metadata</a></p> -->
            <aside class="example">
              <h5>Machine-readable</h5>
              <p>The example below shows how to use [[VOCAB-DCAT]] to provide
                the machine readable <strong> discovery </strong> metadata for
                the bus stops dataset (<code>:bus-stops-2015-05-05</code>). The dataset has one CSV
                distribution (<code>:bus-stops-2015-05-05.csv</code>) that is also described using
                the [[VOCAB-DCAT]].
The dataset is classified under
                the domain represented by the relative URI <code>:mobility </code>. This
                domain may be defined as part of a set of domains identified by
                the URI <code>:themes </code>. 
                  To describe both concepts and schema
                concepts, John used <a href="http://www.w3.org/TR/skos-primer/">SKOS </a>.
                To express frequency of update an instance from the <a href="http://www.w3.org/TR/vocab-data-cube/#dsd-cog">Content-Oriented
                  Guidelines</a> developed as part of the <abbr title="World Wide Web Consortium">W3C</abbr>
                Data Cube Vocabulary efforts was used. John chose to describe
                the spatial and temporal coverage of the example dataset using
                URIs from <a href="http://www.geonames.org/">Geonames</a> and the <a

                  href="http://reference.data.gov.uk/id/interval"> Interval
                  dataset</a> from data.gov.uk, respectively.

                </p>
              <pre class="highlight">
  :bus-stops-2015-05-05
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport","mobility","bus" ;
      dct:issued "2015-05-05"^^xsd:date ;
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      dct:publisher :transport-agency-mycity ;
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dcat:theme :mobility ;
      dcat:distribution :bus-stops-2015-05-05.csv ;
      .

  :mobility
      a skos:Concept ;
      skos:inScheme :themes ;
      skos:prefLabel "Mobility"@en ;
      skos:prefLabel "Mobilidade"@pt
      .

  :themes
      a skos:ConceptScheme ;
      skos:prefLabel "A set of domains to classify documents" ;
      .

  :bus-stops-2015-05-05.csv
      a dcat:Distribution ;
      dct:title "CSV distribution of bus-stops-2015-05-05 dataset" ;
      dct:description "CSV distribution of the bus stops dataset of MyCity" ;
      dcat:mediaType "text/csv" ;
      .
</pre>
                            <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable description of dataset is available.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the metadata for the dataset itself includes the overall features of the dataset in a human-readable format.</p>
            <p>Check if the descriptive metadata is available in a valid machine-readable.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <li>Discoverability</li>
            </ul>
          </section>
        </div>
        <!-- end of BP -->
        <!-- begin Locale Parameters BP -->
        <div class="practice">
          <p><span id="LocaleParametersMetadata" class="practicelab">Provide
              locale parameters metadata </span></p>
          <p class="practicedesc">Information about locale parameters (date,
            time, and number formats, language) should be described by metadata.
          </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Providing <a href="#locale_parameter">locale</a> parameters metadata
              helps human users and computer applications to understand and to
              manipulate the data, improving the reuse of the data. Providing
              information about the locality for which the data is currently
              published aids data users in interpreting its meaning. Date, time,
              and number formats can have very different meanings, despite
              similar appearances. Making the language explicit allows users to
              determine how readily they can work with the data and may enable
              automated translation services.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Locale parameters metadata will enable humans and software agents to interpret the meaning of dates, times and numbers accurately by referring to locale information.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Locale parameters metadata should include the following
              information: </p>
            <ul>
              <li>The language(s) of the dataset.</li>
              <li>The formats used for numeric values, dates and time. </li>
            </ul>
            <p> The machine readable version of the discovery metadata may be
              provided according to the vocabulary recommended by W3C to
              describe datasets, i.e. the Data Catalog Vocabulary
              [[VOCAB-DCAT]].</p>
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> The example below shows the machine readable metadata for the
            bus stops dataset (<code>:bus-stops-2015-05-05</code>) with the inclusion of the <strong> locale
                  parameters </strong> metadata. The property <code>dct:language</code> is used to declare the languages the dataset is published in. If the dataset is available in multiple languages,
                use multiple values for this property [[VOCAB-DCAT]]. The property <a href="  http://purl.org/dc/terms/conformsTo"> dct:conformsTo </a> is used to specify the standard adopted for date and time formats. </p>
              <pre class="highlight">  
  :bus-stops-2015-05-05
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport","mobility","bus" ;
      dct:issued "2015-05-05"^^xsd:date ;
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      dct:publisher :transport-agency-mycity ;
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dcat:theme :mobility ;
      dcat:distribution :bus-stops-2015-05-05.csv ;
      <strong>dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt; ;</strong>
      <strong>dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/pt&gt; ;</strong>
      <strong>dct:conformsTo "ISO 8601" ; </strong>
      .
</pre>
               <!-- As proposed
                in Dataset Descriptions from HCLS Community [[HCLS-DATASET]]
                values were taken from the Lexvo.org Ontology [[Lexvo]]. -->
              
              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable description of dataset is available.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the metadata for the dataset itself includes information about local parameters (i.e. data, time, number formats, and language) in a human-readable format).</p>
            <p>Check if the metadata with locale information is available in a valid machine-readable format and without syntax errors.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatLocalize">R-FormatLocalize</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-GeographicalContext ">R-GeographicalContext</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <!--              <li>Linkability</li>
              <li>Discoverability</li>              <li>Trust</li>              <li>Access</li>              <li>Interoperability</li>
              <li>Processability</li>-->
            </ul>
          </section>
        </div>
        <!-- end of Locale Parameters BP -->
        <!-- begin of Provide Structural Metadata -->
        <div class="practice">
          <p><span id="StructuralMetadata" class="practicelab">Provide
              structural metadata </span> </p>
          <p class="practicedesc"> Information about the schema and internal
            structure of a distribution must be described by metadata.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p> Providing information about the internal structure of a
              distribution can be helpful when exploring or querying the
              dataset. Besides, structural metadata provides information that
              helps to understand the meaning of the data. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Structural metadata will enable humans to interpret the schema of a dataset and software agents to automatically process schema distributions.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Human readable strucutral metadata usually provides the properties or columns of the dataset schema.</p>
            <p>Machine readable structural metadata is available according to the format of a
              specific distribution and it may be provided within separate
              documents or embedded into the document. For more details see the
              links below. </p>
            <ul>
              <li> Tabular data: see <a href="https://www.w3.org/TR/tabular-data-model/#locating-metadata">
                  Model for Tabular Data and Metadata on the Web </a> </li>
              <li> JSON-LD: see <a href="http://www.w3.org/TR/json-ld/">
                  JSON-LD 1.0 </a> </li>
              <li> XML: see <a href="http://www.w3.org/XML/Schema"> XML Schema
                </a> </li>
            </ul>
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> John used the <a href = https://www.w3.org/TR/2015/REC-tabular-data-model-20151217/> Model for Tabular Data and Metadata on the Web  </a> for publishing the CSV distribution of the bus stops dataset (<code>:bus-stops-2015-05-05.csv</code>). The example below presents the structural metadata for this distribution .</p>
              <pre class="highlight">

{
  "@context": ["http://www.w3.org/ns/csvw", {"@language": "en"}],
  "url": "http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05.csv",
  "dc:title": "CSV distribution of bus-stops-2015-05-05 dataset",
  "dcat:keyword": ["bus", "stop", "mobility"],
  "dc:publisher": {
    "schema:name": "Transport Agency of MyCity",
    "schema:url": {"@id": "http://example.org"}
  },
  "dc:license": {"@id": "http://opendefinition.org/licenses/cc-by/"},
  "dc:modified": {"@value": "2015-05-05", "@type": "xsd:date"},
  "tableSchema": {
    "columns": [{
      "name": "stop_id",
      "titles": ["Identifier"],
      "dc:description": "An identifier for the bus stop.",
      "datatype": "string",
      "required": true
    }, {
      "name": "stop_name",
      "titles": ["Name"],
      "dc:description": "The name of the bus stop.",
      "datatype": "string"
    },  {
      "name": "stop_desc",
      "titles": ["Description"],
      "dc:description": "A description for the bus stop.",
      "datatype": "string"
   {
      "name": "stop_lat",
      "titles": ["Latitude"],
      "dc:description": "The latitude of the bus stop.",
      "datatype": "number"
    },
    {
      "name": "stop_long",
      "titles": ["Longitude"],
      "dc:description": "The longitude of the bus stop.",
      "datatype": "number"
    },
    {
      "name": "zone_id",
      "titles": ["ZONE"],
      "dc:description": "An identifier for the zone where the bus stop is located.",
      "datatype": "string"
    },
    {
      "name": "stop_url",
      "titles": ["URL"],
      "dc:description": "URL that identifies the bus stop.",
      "datatype": "string"
    }],
    "primaryKey: "stop_id"
  }
}
</pre>
              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html#dataset-strucutral-metadata">Example page</a> with
                human-readable structural metadata is available.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test </p>
            <p>Check if the structural metadata of the dataset is provided in a human-readable format.</p>
            <p>Check if the metadata of the distribution includes structural information about the dataset in a machine-readable format and without syntax errors.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <!--              <li>Linkability</li>
              <li>Discoverability</li>              <li>Trust</li>              <li>Access</li>              <li>Interoperability</li>-->
              <li>Processability</li>
            </ul>
          </section>
        </div>
        <!-- end of BP -->
        <!-- end if metadata section -->
      </section>
      <!-- begin of Data Licenses -->
      <section id="licenses">
        <h2>Data Licenses</h2>
        <p>A <a href="#license"> license </a> is a very useful piece of
          information to be attached to data on the Web. According to the type
          of license adopted by the publisher, there might be more or fewer
          restrictions on sharing and reusing data. In the context of data on
          the Web, the license of a dataset can be specified within the data, or
          outside of it, in a separate document to which it is linked.
          <!-- begin of machine detectable license BP --> </p>
        <div class="practice">
          <p><span id="DataLicense" class="practicelab">Provide data license
              information</span></p>
          <p class="practicedesc"> Data license information should be available.
          </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The presence of license information is essential for data
              consumers to assess the usability of data. User agents, for
              example, may use the presence/absence of license information as a
              trigger for inclusion or exclusion of data presented to a
              potential consumer. </p>
            <!--Even though the license may be presented in natural
                language, where data links to the URL of a well known license,                the user agent may be able to present the well known features to                the potential consumer.-->
          </section>
          <section class="description">
            <p class="subhead">Intended outcome</p>
            <p>Humans will be able to understand data license information describing possible restrictions placed on the use of a given distribution and software agents to automatically detect the data license of a distribution.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Data license information can be provided as a link to a human-readable license or as a link/embedded machine-readable license.</p>
            <p>The machine readable version of the data license metadata may be
              provided using one of the following vocabularies that include
              properties for linking to a license: </p>
            <ul>
              <li>Dublin Core [[DC-TERMS]] (<code class="highlith">dct:license</code>)</li>
              <li>Creative Commons [[CC-VOCAB]] (<code class="highlith">cc:license</code>)</li>
              <li>schema.org [[SCHEMA-ORG]] (<code class="highlith">schema:license</code>)</li>
              <li>XHTML [[XHTML-VOCAB]] (<code class="highlith">xhtml:license</code>)</li>
            </ul>
            There are also a number of machine readable rights languages,
            including:
            <ul>
              <li>The Creative Commons Rights Expression Language [[ccREL]]</li>
              <li>The Open Digital Rights Language [[ODRL]]</li>
              <li>The Open Data Rights Statement Vocabulary [[ODRS]]</li>
            </ul>
            <!-- <p>Links to the license can be provided from the data itself, from
                an HTML page that describes the data (via a Link element), or                via an HTTP Link Header, the latter two with a <code>@rel</code>                value of <code>license</code>. </p>                Further information about open data licensing can be found in                the Publisher's Guide to Open Data Licensing, published by the                Open Data Institute [[ODI-LICENSING]]. -->
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> The CSV distribution of the bus stops dataset (<code>:bus-stops-2015-05-05.csv</code>) will be published under the <a href= "http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported</a> license. The property <code>dct:license</code> is used to include this information as part of the distribution metadata. </p>
              <pre class="highlight">
  :bus-stops-2015-05-05.csv
      a dcat:Distribution ;
      dct:title "CSV distribution of bus-stops-2015-05-05 dataset" ;
      dct:description "CSV distribution of the bus stops dataset of MyCity" ;
      dcat:mediaType "text/csv" ;
      <strong>dct:license &lt;http://creativecommons.org/licenses/by-sa/3.0/&gt;</strong> ;
      .
</pre>
              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable data license information of the distribution.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the metadata for the dataset itself includes the data license information in a human-readable format.</p>
            <p>Check if a user agent can automatically detect /discover the data license of the dataset.</p>
          </section>
          <section class="ucr">
              <p class="subhead">Evidence</p>
              <p><span>Relevant use cases</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseAvailable">R-LicenseAvailable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataMachineRead">R-MetadataMachineRead</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseLiability">R-LicenseLiability</a>
              </p>
          </section>
          <section class="benefits">
              <p class="subhead">Benefits</p>
              <ul class="benefitsList">
                <li>Reuse</li>
                <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li> -->
                <li>Trust</li>
                <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
              </ul>
          </section>
        </div>
        <!-- end of machine detectable license BP -->
      </section>
      <!-- end of Data Licenses -->
      <!-- begin of Data Provenance -->
      <section id="provenance">
        <h3>Data Provenance</h3>
        <p> <a href="#data_provenance">Data provenance</a> becomes particularly
          important when data is shared between collaborators who might not have
          direct contact with one another either due to proximity or because the
          published data outlives the lifespan of the data provider projects or
          organizations.</p>
        <p>The Web brings together business, engineering, and scientific
          communities creating collaborative opportunities that were previously
          unimaginable. The challenge in publishing data on the Web is providing
          an appropriate level of detail about its origin. The <a href="#data_producer">
            data producer</a> may not necessarily be the data provider and so
          collecting and conveying this corresponding metadata is particularly
          important. Without provenance, consumers have no inherent way to trust
          the integrity and credibility of the data being shared. Data
          publishers in turn need to be aware of the needs of prospective
          consumer communities to know how much provenance detail is
          appropriate. </p>
        <!-- begin of Provide Data Provenance BP -->
        <div class="practice">
          <p><span id="DataProvenance" class="practicelab">Provide data
              provenance information</span></p>
          <p class="practicedesc">Data provenance information should be
            available. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Without accessible data provenance, data consumers will not know
              the origin or history of the published data.</p>
            <!-- <p>Data provenance is metadata that corresponds to data. Data
                provenance relies upon existing vocabularies that make                provenance easily identifiable such as the Provenance Ontology                [[PROV-O]].</p> -->
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data provenance information will enable humans to know the origin or history of the dataset and will enable software agents to automatically process provenance information about the dataset.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The machine readable version of the data provenance can be
              provided using an ontology recommended to describe provenance information, such as W3C's Provenance Ontology [[PROV-O]].
            </p>
            <!--
              <ol>                <li>Use an appropriate level of detail that will be meaningful                  to the intended audience. </li>                <li>Write the data provenance in either a machine readable form                  such as Turtle or RDF/XML or embed provenance in an HTML page                  using [[JSON-LD]], or [[HTML-RDFA]] </li>                <li>Verify that the data provenance references published data</li>              </ol> -->
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> The example below shows the machine readable metadata for the
                bus stops dataset (bus-stops) with the inclusion of the
                <strong>provenance</strong> metadata. The properties <code>dct:creator</code>, <code> dct:publisher</code> and <code>dct:issued </code> are used to give information about the origin of the dataset. The property <code> prov:actedOnBehalfOf </code> is used to designate that John acted on behalf of the Transport Agency of MyCity.</p>
              <pre class="highlight">
  :bus-stops-2015-05-05
      a dcat:Dataset, prov:Entity ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport", "mobility", "bus" ;
      <strong>dct:issued "2015-05-05"^^xsd:date ; </strong>
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      <strong>dct:publisher :transport-agency-mycity ; </strong>
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt; ;
      <strong>dct:creator :john ; </strong>
      .

  :john
      a foaf:Person, prov:Agent ;
      foaf:givenName "John" ;
      foaf:mbox &lt;mailto:john@mycitytransport.org&gt; ;
      <strong>prov:actedOnBehalfOf :transport-agency-mycity ; </strong>
      .
  :transport-agency-mycity
      a foaf:Organization, prov:Agent ;
      foaf:name "Transport Agency of Mycity" ;
      .

</pre>
              <h5>Human-readable</h5>
              <!--<p><a href="dwbp-example.html">Example page</a> with
                human-readable data provenance information.</p> -->
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable provenance information about the bus stops dataset is available.</p>

            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that the metadata for the dataset itself includes the provenance information about the dataset in a human-readable format.</p>
            <p>Check if a computer application can automatically process the provenance information about the dataset.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-ProvAvailable">R-ProvAvailable</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>
            </p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <!--              <li>Linkability</li>
              <li>Discoverability</li>-->
              <li>Trust</li>
              <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
            </ul>
          </section>
        </div>
        <!-- end of Provide Data Provenance BP -->
      </section>
      <!-- end of Data Provenance -->
      <!-- begin of Data Quality -->
      <section id="quality">
        <h3>Data Quality</h3>
        <p> The quality of a dataset can have a big impact on the quality of applications that use it. As a consequence, the inclusion of <a href="#data_quality"> data quality </a> considerations in data publishing and consumption pipelines is of primary importance. Usually, the assessment of quality involves
          different kinds of quality dimensions, each representing groups of
          characteristics that are relevant to publishers and consumers.
          Measures and metrics are defined to assess the quality for each
          dimension [[DQV]]. There are heuristics designed to fit specific
          assessment situations that rely on quality indicators, namely, pieces
          of data content, pieces of data meta-information, and human ratings
          that give indications about the suitability of data for some intended
          use.</p>
        <!--<p>Dimensions and metrics to adopt might largely depend on the
            specific application scenario, or even on the data domain. A            systematic review of dimensions, metrics adopted in the context of            Linked Open Data can be found in the recent literature (e.g., see            [[ZAVERI]]). </p> -->
        <!-- begin of Provide Data Quality BP -->
        <div class="practice">
          <p><span id="DataQuality" class="practicelab">Provide data quality
              information</span></p>
          <p class="practicedesc">Data Quality information should be available.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Data quality might seriously affect the suitability of data for
              specific applications, including applications very different from
              the purpose for which it was originally generated. Documenting
              data quality significantly eases the process of datasets
              selection, increasing the chances of reuse. Independently from
              domain-specific peculiarities, the quality of data should be
              documented and known quality issues should be explicitly stated in
              metadata.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data quality information will enable humans to know the quality of the dataset and its distributions, and software agents to automatically process quality information about the dataset and its distributions.</p>
            <!--<p> Information about the quality of the data should be provided
                for humans. Ideally it is also made available in machine                readable manner for processing by applications.</p> -->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <!-- <p>Depending on the application domain, information pertaining to
                the quality may rely on specific quality metrics or                feedback-opinion. Specific quality metadata fields may or may                not be explicitly included in the metadata vocabularies adopted                by catalogs. Independently from domain-specific peculiarities,                the quality of data should be documented and known quality                issues should be explicitly stated in metadata. </p> -->
            <!--            <p>The definition of a Quality Vocabulary is included in the
              activity of the DWBP group in order to support in the              implementation of this best practice. The Quality Vocabulary is              foreseen as an extension to DCAT to cover the quality of the data,              how frequently is it updated, whether it accepts user corrections,              persistence commitments etc. When used by publishers, this              vocabulary will foster trust in the data amongst developers. </p> -->
            <p>The machine readable version of the dataset quality metadata may
              be provided according to the vocabulary that is being developed by
              the <abbr title="Data on the Web Best Practices">DWBP</abbr>
              working group , i.e., the Data Quality Vocabulary [[DQV]]. </p>
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> The example below shows the metadata for the CSV distribution
                of the bus stops dataset with the inclusion of the data
                quality metadata. The metadata was defined according to the Data
                Quality Vocabulary. Further  examples can be found in the Data
                Quality Vocabulary document [[DQV]]. </p>
              <pre class="highlight">
  :bus-stops-2015-05-05.csv
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05.csv&gt; ;
      dct:title "CSV distribution of bus-stops-2015-05-05 dataset" ;
      dct:description "CSV distribution of the bus stops dataset of MyCity" ;
      dcat:mediaType "text/csv" ;
      dct:license &lt;http://creativecommons.org/licenses/by-sa/3.0/&gt; ;
      <strong>dqv:hasQualityMeasurement :measure1, :measure2 </strong> 
      .
  :measure1
      a dqv:QualityMeasurement ;
      dqv:computedOn :bus-stops.csv ;
      dqv:metric :downloadURLAvailabilityMetric ;
      dqv:value "true"^^xsd:boolean 
      .
  :measure2
      a dqv:QualityMeasurement ;
      dqv:computedOn :bus-stops.csv ;
      dqv:metric :csvCompletenessMetric ;
      dqv:value "0.5"^^xsd:double 
      .

#definition of dimensions and metrics
  :availability
      a dqv:Dimension ;
      skos:prefLabel "Availability"@en ;
      skos:definition "Availability of a dataset is the extent to which data (or some portion of it) is present, obtainable and ready for use."@en ;
      dqv:inCategory :accessibility 
      .
  :completeness
      a dqv:Dimension ;
      skos:prefLabel "Completeness"@en ;
      skos:definition "Completeness refers to the degree to which all required information is present in a particular dataset."@en ;
      dqv:inCategory :intrinsicDimensions	
      .
  :downloadURLAvailabilityMetric
      a dqv:Metric ;
      skos:definition "It checks if dcat:downloadURL is available and if its value is dereferenceable."@en ;
      dqv:inDimension :availability
      .
  :csvComplitenessMetric
      a dqv:Metric ;
      skos:definition "Ratio between the number of objects represented in the cvs and the number of objects expected to be represented according to the declared dataset scope."@en ;
      dqv:inDimension :completeness
      .
</pre>
              <h5>Human-readable</h5>
               <p><a href="dwbp-example.html">Example page</a> with
                human-readable data quality information.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that the metadata for the dataset itself includes quality information about the dataset.</p>
            <p>Check if a computer application can automatically process the quality information about the dataset.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p> Relevant Requirements: <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityMetrics">
                R-QualityMetrics</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataMissingIncomplete">
                R-DataMissingIncomplete</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">
                R-QualityOpinions</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataMissingIncomplete">R-DataMissingIncomplete</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityMetrics">R-QualityMetrics</a></p>
          </section>
          <!-- end of Provide Data Quality BP -->
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li> -->
              <li>Trust</li>
              <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li> -->
            </ul>
          </section>
        </div>
      </section>
      <!-- end of Data Quality -->
      <!-- begin of Data Versioning -->
      <section id="dataVersioning">
        <h3>Data Versioning</h3>
        <p> Datasets published on the Web may change over time. Some datasets
          are updated on a scheduled basis, and other datasets are changed as
          improvements in collecting the data make updates worthwhile. In order
          to deal with these changes, new versions of a dataset may be created.
          Unfortunately, there is no consensus about when changes to a dataset should 
          cause it to be considered a different dataset altogether rather than a new version. 
          In the following, we present some scenarios where most publishers would agree that
          the revision should be considered a new version of the existing dataset. </p>
        <ul>
          <li> Scenario 1: a new bus stop is created and it should to be added to the dataset;</li>
          <li> Scenario 2: an existing bus stop is removed and it
            should be deleted from the dataset;</li>
          <li> Scenario 3: an error was identified in one of the existing
            bus stops stored in the dataset and this error must be corrected.</li>
        </ul>
        <p> In general, multiple datasets that represent time series or
          spatial series, e.g. the same kind of data for different regions
          or for different years, are not considered multiple versions of the same
          dataset. In this case, each dataset covers a different set of observations
          about the world and should be treated as a new dataset. This is also the case with a dataset that
          collects data about weekly weather forecasts for a given city, where
          every week a new dataset is created to store data about that
          specific week. </p>
        <p>Scenarios 1 and 2 might trigger a major version, whereas Scenario 3 would likely trigger only a minor version.
          But how you decide whether versions are minor or major is less important than that you avoid making
          changes without incrementing the version indicator. Even for small changes, it is important to keep track of the
          different dataset versions to make the dataset trustworthy. Publishers
          should remember that a given dataset may be in use by one or more
          data consumers, and they should take reasonable steps to inform those consumers when a new version is released.
          For real-time data, an automated timestamp can serve as a version identifier. 
          For each dataset, the publisher should take a
          consistent, informative approach to versioning, so data consumers can
          understand and work with the changing data. </p>
        <p></p>
        <!-- begin of provide Versioning Info BP -->
        <div class="practice">
          <p><span id="VersioningInfo" class="practicelab">Provide a version
              indicator</span></p>
          <p class="practicedesc">An indication of the version number or date should be
            available for each dataset.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Version information makes a revision of a dataset uniquely identifiable.
              Uniqueness can be used by data consumers to determine whether and how data has
              changed over time and to determine specifically which version of a
              dataset they are working with. Good data versioning enables
              consumers to understand if a newer version of a dataset is
              available. Explicit versioning allows for repeatability in
              research, enables comparisons, and prevents confusion. Using
              unique version numbers that follow a standardized approach can
              also set consumer expectations about how the versions differ.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Version indicators will enable humans and software agents to easily determine which version of a dataset they are working with.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <!-- <p>Providing version information is a topic of <a href="https://lists.w3.org/Archives/Public/public-vocabs/2015Jan/0120.html"
                  title="A versioning model for schema.org">much debate</a>. -->
            <p> The best method for providing versioning information
              will vary according to the context; however, there are some basic
              guidelines that can be followed, for example: </p>
            <ul>
              <li>Include a unique version number or date as part of the metadata for
                the dataset. </li>
              <li>Use a consistent numbering scheme with a meaningful approach
                to incrementing digits, such as [[SchemaVer]]. </li>
              <!-- <li>Provide a description of what has changed since the previous
                version. </li> -->
              <li>If the data is made available through an API, the URI used to
                request the latest version of the data should not change as the
                versions change, but it should be possible to request a specific
                version through the API.
                <!--See <a href="#VersioningVocabularies">Vocabulary
                  versioning</a> for more on assigning stable URIs for the 'latest version' and for each snapshot.</p> -->
              </li>
              <li> Use Memento [[RFC7089]], or components thereof, to
                express temporal versioning of a dataset and to access the
                version that was operational at a given datetime. The Memento
                protocol aligns closely with the approach for assigning URIs to
                versions that is used for W3C
                specifications, described below.</li>
            </ul>
            <p>The Web Ontology Language [[OWL2-QUICK-REFERENCE]] and the
              Provenance, Authoring and versioning Ontology [[PAV]] provides a
              number of annotation properties for version information.</p>
            <aside class="example">
              <h5>Machine-readable</h5>
              <p> The example below shows the metadata for bus stops with
                the inclusion of the versioning metadata. The properties <code>owl:versionInfo</code> and <code>pav:version</code> are used to denote the version of the dataset. </p>
              <pre class="highlight">
  :bus-stops-2015-05-05
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport","mobility","bus" ;
      dct:issued "2015-05-05"^^xsd:date ;
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      dct:publisher :transport-agency-mycity ;
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt; ;
      dct:creator :john ;
      <strong>owl:versionInfo "1.0" ; </strong>
      <strong>pav:version "1.0" ; </strong>
      .
   </pre>

              <strong>Using Memento</strong>
              <p> Assume: </p>
              <ul>
                <li>
<code> http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops </code>
is the “generic URI” at which
                  the current version of a dataset is always available </li>
                <li>
<code> http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-17 </code>
is the versioned URI for
                  the current dataset </li>
                <li>
<code> http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05 </code>
is the versioned URI of
                  the prior version of the dataset </li>
              </ul>
              <p> In the Memento protocol, the versioned URIs provide HTTP
                response header information to express their version datetime
                and their relation to the generic URI: </p>
              <pre class="highlight">curl -I http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-17

HTTP/1.1 200 OK
Memento-Datetime: Thu, 17 Dec 2015 00:00:00 GMT
Link:&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;;
rel=“original”</pre>
              <p> The generic URI provides a link to a TimeGate, which
                supports datetime negotiation as a means to determine which
                version of a dataset was operational at a given datetime.
                Since the generic URI is not versioned,
                no version datetime is provided in the headers.</p>
              <pre class="highlight">curl -i -H http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops

HTTP/1.1 200 OK
Link: &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/timegate/bus-stops&gt;;
rel=“timegate” </pre>
              <p> The versioned URIs can also provide a link to a TimeGate: </p>
              <pre class="highlight">curl -I http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05

HTTP/1.1 200 OK
Memento-Datetime: Tue, 05 May 2015 00:00:00 GMT
Link: &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;;
rel=“original”,
&nbsp;&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/timegate/bus-stops&gt;;
rel=“timegate” </pre>
              <p>This is how a client determines which dataset version was
                operational on June 20 2015: </p>
              <pre class="highlight">curl -I -H "Accept-Datetime: Sat, 20 Jun 2015  12:00:00 GMT" http://data.mycity.example.com/public-transport/road/bus/dataset/timegate/bus-stops

HTTP/1.1 302 Found
Vary: accept-datetime
Location: http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05
Link: &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;
rel="original" </pre>
              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable data versioning information.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the metadata for the dataset/distribution provides a unique version number or date in a human-readable format.</p>
            <p>Check if a computer application can automatically detect/discover the unique version number or date of a dataset or distribution.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataVersion">R-DataVersion</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>-->
              <li>Trust</li>
              <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li> -->
            </ul>
          </section>
        </div>
        <!-- end of provide Versioning Info BP -->
        <!-- begin of provide version history BP -->
        <div class="practice">
          <p><span id="VersionHistory" class="practicelab">Provide version
              history</span></p>
          <p class="practicedesc">A version history for the dataset should be
            available.</p>
          <!-- <p class="practicedesc">A version history should
              be available for versioned data.</p> -->
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>In creating applications that use data, it can be helpful to
              understand the variability of that data over time. Interpreting
              the data is also enhanced by an understanding of its dynamics.
              Determining how the various versions of a dataset differ from each
              other is typically very laborious unless a summary of the
              differences is provided.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Version history will enable humans and software agents to understand how the dataset typically changes from version to version and how any two specific versions differ.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Provide a list of published versions and a description for each
              version that explains how it differs from the previous version. An
              API can expose a version history with a single dedicated URL that
              retrieves the latest version of the complete history.</p>
            <!--<div class="issue"> Which vocabulary should be used to describe the
              versioning history? This is <a href="https://www.w3.org/2013/dwbp/track/issues/168">Issue-168</a></div>-->
            <aside class="example">
              <h5> Machine-readable</h5>
              <p> Suppose that a new bus stop was created and a new dataset (<code>:bus-stops-2015-12-17</code>) is published to keep the data up to date. The new dataset is a version of <code>:bus-stops-2015-05-05</code>. The machine readable
                metadata of the new dataset is shown below with the corresponding versioning history information. </p>
              <pre class="highlight">
  :bus-stops-2015-12-17
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport","mobility","bus" ;
      dct:issued "2015-12-17"^^xsd:date ;
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      dct:publisher :transport-agency-mycity ;
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt; ;
      dct:creator :john ;
       ...
      <strong>dct:isVersionOf :bus-stops-2015-05-05 ;
      pav:previousVersion: bus-stops-2015-05-05 ;
      rdfs:comment "The bus stops dataset was updated to reflect the creation of a new bus stop at 1115 Pearl Street." ;
      owl:versionInfo "1.1" ;
      pav:version "1.1" ; </strong>
      .
</pre>
              <p> <strong> Using Memento:</strong> </p>
              Assume:
              <ul>
                <li>
<code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops </code>
is the “generic URI” at which
                  the current version of a dataset is always available </li>
                <li>
<code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-17</code>
is the versioned URI for
                  the current dataset </li>
                <li>
<code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05</code>
is the versioned URI of
                  the prior version of the dataset </li>
                <li> http://example.org/bus-stops-2015-01-01 is the
versioned URI of
                  the first version of the dataset </li>
              </ul>
              <p> The versioned URIs, the generic URI, and the TimeGate can
                provide a link to a TimeMap that provides an overview of all
                temporal versions of the dataset: </p>
              <pre class="highlight">curl -I http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05

HTTP/1.1 200 OK
Memento-Datetime: Tue, 05 May 2015 00:00:00 GMT
Link: &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;;
rel=“original”,
 &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/timemap/bus-stops&gt;;
rel=“timemap”;
&nbsp;type="application/link-format" </pre>
<p> This is how the TimeMap is retrieved: </p>
<pre class="highlight">curl -I http://data.mycity.example.com/public-transport/road/bus/dataset/timemap/bus-stops

HTTP/1.1 200 OK
Content-Type: application/link-format

&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;;rel="original”,
&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/timegate/bus-stops&gt;;rel="timegate”,
&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/timemap/bus-stops&gt;;rel="timemap”;
&nbsp;type="application/link-format",
&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-01-01&gt;;
rel=“first memento"; datetime="Thu, 01 Jan 2015 00:00:00 GMT",
&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05&gt;;
rel=“memento"; datetime=“Tue, 05 May 2015 00:00:00 GMT"
&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-07&gt;;
rel=“last memento"; datetime="Thu, 17 Dec 2015 00:00:00 GMT"
</pre>
              <p> The versioned URI can provide information regarding relations
                with other dataset versions: </p>
              <pre class="highlight">curl -I http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05

HTTP/1.1 200 OK
Memento-Datetime: Tue, 05 May 2015 00:00:00 GMT
Link: &lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops&gt;;
rel=“original”,
&nbsp;&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-01-01&gt;;
rel=“prev first memento";
&nbsp;datetime="Thu, 01 Jan 2015 00:00:00 GMT",
&nbsp;&lt;http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-17&gt;;
rel=“next last memento";
&nbsp;datetime="Thu, 17 Dec 2015 00:00:00 GMT"
</pre>

              <h5>Human-readable</h5>
              <p><a href="dwbp-example.html">Example page</a> with
                human-readable data versioning history information.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that a list of published versions is available as well as a change log describing precisely how each version differs from the previous one.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataVersion">R-DataVersion</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li> -->
              <li>Trust</li>
              <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li> -->
            </ul>
          </section>
        </div>
        <!-- end of provide version history BP -->

      <!-- end of versioning section -->
      </section>
      <!-- begning of data identifier section -->
      <section id="DataIdentifiers">
        <h3>Data Identifiers</h3>
        <p>Identifiers take many forms and are used extensively in every
          information system. Data discovery, usage and citation on the Web
          depends fundamentally on the use of HTTP (or HTTPS) URIs: globally
          unique identifiers that can be looked up by dereferencing them over
          the Internet [[RFC3986]]. It is perhaps worth emphasizing some key
          points about URIs in the current context.</p>
        <ol>
          <li>URIs are 'dumb strings', that is, they carry no semantics. Their
            function is purely to identify a resource.</li>
          <li>Although the previous point is accurate, it would be perverse for
            a URI such as http://example.com/dataset.csv to return anything
            other than a CSV file. Human readability is helpful.</li>
          <li>When de-referenced (looked up), a single URI may offer the same
            resource in more than one format. http://example.com/dataset may
            offer the same data in, say, CSV, JSON and XML. The server returns
            the most appropriate format based on <a href="http://www.w3.org/Protocols/HTTP/Negotiation">
              content negotiation </a>.</li>
          <li>One URI may redirect to another.</li>
          <li>De-referencing a URI triggers a computer program to run on a
            server so that the URI acts as a call to an API. The server may
            therefore do something as simple as return a single, static file, or
            it may carry out complex processing. Precisely what processing is
            carried out, i.e. the software on the server, is completely
            independent of the URI itself.</li>
        </ol>
        <!-- begin of Data Identification BP -->
        <div class="practice">
          <p><span id="UniqueIdentifiers" class="practicelab">Use persistent
              URIs as identifiers of datasets</span></p>
          <p class="practicedesc">Datasets must be identified by a persistent
            URI. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Adopting a common identification system enables basic data
              identification and comparison processes by any stakeholder in a
              reliable way. They are an essential pre-condition for proper data
              management and reuse.</p>
            <p>Developers may build URIs into their code and so it is important 
            that those URIs persist and that they dereference to the same 
            resource over time without the need for human intervention.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Datasets or information about datasets will be discoverable and citable through time, regardless of the status, availability or format of the data.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>To be persistent, URIs must be designed as such. This requires a 
            different mindset to that used when creating a Web site designed 
            for humans to navigate their way through. A lot has been 
            written on this topic, see, for example, the European Commission's
            Study on Persistent URIs [[PURI]] which in turn links to many other 
            resources.</p>
<!--            <table id="uripatternstable">
              <caption>Some sources of information related to URI persistence</caption>
              <tbody>
                <tr>
                  <th>Status</th>
                  <th>Title</th>
                  <th>Authors and Date</th>
                </tr>
                <tr>
                  <td rowspan="3">Background</td>
                  <td><a href="http://www.w3.org/Provider/Style/URI.html">Cool
                      URIs don't change</a></td>
                  <td>Tim Berners-Lee, 1998</td>
                </tr>
                <tr>
                  <td><a href="http://www.w3.org/TR/cooluris/">Cool URIs for the
                      Semantic Web</a></td>
                  <td>Leo Saurman, Richard Cyganiak, 2008</td>
                </tr>
                <tr>
                  <td><a href="http://www.w3.org/DesignIssues/LinkedData.html">Linked
                      Data</a></td>
                  <td>Tim Berners-Lee, 2009</td>
                </tr>
                <tr>
                  <td>Key Source</td>
                  <td><a href="http://www.cabinetoffice.gov.uk/sites/default/files/resources/designing-URI-sets-uk-public-sector.pdf">Designing
                      URI Sets for the UK Public Sector</a> (PDF)</td>
                  <td>UK Chief Technology Officer Council October 2009</td>
                </tr>
                <tr>
                  <td>Survey &amp; summary of techniques</td>
                  <td><a href="http://philarcher.org/diary/2013/uripersistence/">Study
                      on Persistent URIs</a></td>
                  <td>Phil Archer, Nikos Loutas, Stijn Goedertier, Saky
                    Kourtidis, 2013</td>
                </tr>
                <tr>
                  <td rowspan="4">Expansion</td>
                  <td><a href="http://www.jenitennison.com/blog/node/136/">Creating
                      Linked Data</a></td>
                  <td>Jeni Tennison, 2009</td>
                </tr>
                <tr>
                  <td><a href="http://linkeddatabook.com/editions/1.0/">Linked
                      Data: Evolving the Web into a Global Data Space</a></td>
                  <td>Tom Heath &amp; Christian Bizer, 2011</td>
                </tr>
                <tr>
                  <td><a href="http://patterns.dataincubator.org/book/">Linked
                      Data Patterns</a></td>
                  <td>Leigh Dodds &amp; Ian Davis, 2012</td>
                </tr>
                <tr>
                  <td><a href=" http://www.multilingualweb.eu/documents/dublin-workshop/dublin-program#linking">Best
                      Practices for Multilingual Linked Open Data</a></td>
                  <td>Jose Emilio Labra Gayo, 2012</td>
                </tr>
                <tr>
                  <td>Detail</td>
                  <td><a href="http://csarven.ca/statistical-linked-dataspaces">Statistical
                      Linked Dataspaces</a></td>
                  <td>Sarven Capadisli, 2012</td>
                </tr>
              </tbody>
            </table>-->
            <p>Where a data publisher is unable or unwilling to manage a URI
              space directly for persistence, an alternative approach is to use
              a redirection service such as 
              <a href="https://w3id.org/">Permanent Identifiers for the Web</a> 
              or <a href="http://purl.org/">purl.org</a>.
              These provide persistent URIs that can be redirected as required
              so that the eventual location can be ephemeral. The <a href="http://www.purlz.org/">software
              behind such services </a> is freely available so that it can be
              installed and managed locally if required.</p>
            <p>Digital Object Identifiers (<a href="http://www.doi.org/">DOI</a>s)
              offer a similar alternative. These identifiers are defined
              independently of any Web technology but can be appended to a 'URI
              stub.' DOIs are an important part of the digital infrastructure
              for research data and and libraries. </p>
            <aside class="example">
              <p>The URI <code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops</code>
                has several features that support persistence:</p>
              <ul>
                <li>All names are subject to change over time but in choosing a
                  domain name, it is reasonable for John to assume that MyCity
                  will continue to exist and that it will continue to have a
                  government. Therefore, while cases like Yugoslavia prove that
                  even country names change and top level domains disappear
                  (like .yu), a domain name based on the city's name is as persistent as any
                  domain name can be.</li>
                <li>By putting data on the <code>data.mycity.example.com</code>
                  subdomain, John is creating a specific domain that can be
                  managed independently of any particular department.</li>
                <li>It is <em>not</em> safe to assume that a specific <em>department</em>
                  will persist. The authorities in MyCity might very well decide
                  that the Transport Agency should be merged with another to
                  create the Transport and Environment Agency. It is right,
                  therefore, not to include the name of the Transport Agency in
                  the URI, but to include the task from which the data comes, in
                  this case that of providing public transport.</li>
                <li>Likewise, the path segments of <code>/road</code> and <code>/bus</code>
                  take us further towards the specific dataset for which John is
                  responsible.</li>
                <li>The <code>/dataset</code> path segment is an indication
                  that the URI identifies a dataset, rather than, say, a
                  specific bus route.</li>
                <li>Finally <code>/bus-stops</code> leads us to the dataset
                  concerning bus stops in MyCity.</li>
                <li>In DCAT terms, this would be the identifier for the dataset.
                  Specific distributions of the dataset are likely to be
                  identified by adding the relevant file extension to the URI,
                  such as <code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops.csv</code>,
                  <code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops.json</code>,
                  <code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops.ttl</code>
                  etc.</li>
              </ul>
<!--              <p>These points cover the design aspects of a persistent URI. To
                cover the organizational aspect, MyCity should publish
                information about its URI design principles as well as a
                commitment to maintain the service in the long term.</p>-->
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that each dataset in question is identified using a URI that has been assigned under a controlled process as set out in the previous section. Ideally, the relevant Web site includes a description of the process and a credible pledge of persistence should the publisher no longer be able to maintain the URI space themselves.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li> -->
              <li>Linkability</li>
              <li>Discoverability</li>
              <!--              <li>Trust</li>
              <li>Access</li> -->
              <li>Interoperability</li>
              <!--              <li>Processability</li> -->
            </ul>
          </section>
        </div>
        <!-- end of Data Identification BP -->
        <!-- begin of URIs as identifiers within datasets BP -->
        <div class="practice">
          <p><span id="identifiersWithinDatasets" class="practicelab">Use
              persistent URIs as identifiers within datasets</span></p>
          <p class="practicedesc">Datasets should use and reuse other people's
            URIs as identifiers where possible.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>The power of the Web lies in the <em>Network effect</em>. The
              first telephone only became useful when the second telephone meant
              there was someone to call; the third telephone made both of them
              more useful yet. Data becomes more valuable if it refers to other
              people's data about the same thing, the same place, the same
              concept, the same event, the same person, and so on. That means
              using the same identifiers across datasets and making sure that
              your identifiers can be referred to by other datasets. When those
              identifiers are HTTP URIs, they can be looked up and more data
              discovered.</p>
            <p>These ideas are at the heart of the <a href="http://www.w3.org/DesignIssues/LinkedData.html">5
                Stars of Linked Data</a> where one data point links to another,
              and of <a href="http://dret.github.io/webdata/">Hypermedia</a>
              where links may be to further data or to services (or more
              generally 'affordances') that act on or relate to the data in some
              way. Examples include a bug reporting mechanisms, processors, a
              visualization engine, a sensor, an actuator etc. In both Linked
              Data and Hypermedia, the emphasis is put on the ability for
              machines to traverse from one resource to another following links
              that express relationships.</p>
            <p>That's the Web of Data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>That one data item can be related to others across the Web creating a global information space accessible to humans and machines alike.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>This is a topic in itself and a general document such as this can
              only include superficial detail.</p>
            <p>Developers know that very often the problem they're trying to
              solve will have already been solved by other people. In the same
              way, if you're looking for a set of identifiers for obvious things
              like countries, currencies, subjects, species, proteins, cities
              and regions, Nobel prize winners – someone's done it already. The
              steps described for <a href="http://www.w3.org/TR/ld-bp/#how-to-find-existing-vocabularies">discovering
                existing vocabularies</a> [[LD-BP]] can readily be adapted.</p>
            <ul>
              <li>ensure URI sets you use are published by a trusted group or
                organization;</li>
              <li>ensure URI sets have persistent URIs.</li>
            </ul>
            <p>If you can't find an existing set of identifiers that meet your
              needs then you'll need to create your own, following the patterns
              for URI persistence so that others will add value to your data by
              linking to it.</p>
            <p>URIs can be long. In a dataset of even moderate size, storing
              each URI is likely to be repetitive and obviously wasteful.
              Instead, define locally unique identifiers for each element and
              provide data that allows them to be converted to globally unique
              URIs programmatically. The Metadata Vocabulary for Tabular Data
              [[tabular-metadata]] provides mechanisms for doing this within
              tabular data such as CSV files, in particular using <a href="http://www.w3.org/TR/tabular-metadata/#uri-template-properties">URI
                template properties</a> such as the <a href="http://www.w3.org/TR/tabular-metadata/#cell-aboutUrl">about
                URL</a> property.</p>
            <aside class="example">
              <p>The URI given as an example in the previous Best Practice (<code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops</code>)
                identifies a dataset. Much of the URI can be reused to identify
                bus stops, routes and the type of bus used on a given service.
                For example, a suitable persistent URI for the 'Airport -
                Bullfrog' route would be:</p>
              <p><code>http://data.mycity.example.com/public-transport/road/bus/route/id/AB</code></p>
              <p>This has the same initial structure as for the dataset but
                rather than <code>/dataset</code> it now includes the path
                segment <code>/route</code> so that humans can see that the
                type of thing identified is a bus route. The <code>/id</code>
                segment indicates that the URI identifies something that is not
                an information resource, i.e. something you cannot retrieve over
                the Internet, and <code>/AB</code> is the local identifier for
                the actual bus route. Dereferencing this URI should result in an
                HTTP 303 redirect to a similar URL such as <code>http://data.mycity.example.com/public-transport/road/bus/route/doc/AB</code>
                that <em>describes</em>, i.e. gives information about, the AB
                bus route (note the substitution of <code>/doc</code> for <code>/id</code>).
                Jeni Tennison's work on <a href="http://www.w3.org/TR/urls-in-data/">URLs
                  in Data</a> has more to say on this topic.</p>
              <p>In offering this advice, it is recognized that URIs can be
                long. In a dataset of even moderate size, storing each URI is
                likely to be repetitive and obviously wasteful. Instead, define
                locally unique identifiers for each element (such as <code>AB</code>
                in this example) and provide data that allows them to be
                converted to globally unique URIs programmatically. The Metadata
                Vocabulary for Tabular Data [[tabular-metadata]] provides
                mechanisms for doing this within tabular data such as CSV files,
                in particular using <a href="http://www.w3.org/TR/tabular-metadata/#uri-template-properties">URI
                  template properties</a> such as the <a href="http://www.w3.org/TR/tabular-metadata/#cell-aboutUrl">about
                  URL</a> property.</p>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that within the dataset, references to things that don't change or that change slowly, such as countries, regions, organizations and people, as referred to by URIs or by short identifiers that can be appended to a URI stub. Ideally the URIs should resolve, however, they have value as globally scoped variables whether they resolve or not.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li> -->
              <li>Linkability</li>
              <li>Discoverability</li>
              <!--              <li>Trust</li>
              <li>Access</li> -->
              <li>Interoperability</li>
              <!--              <li>Processability</li> -->
            </ul>
          </section>
        </div>
        <!-- end of URIs as identifiers within datasets BP -->
        <!-- begin of URI to dataset versions BP -->
        <div class="practice">
          <p><span id="VersionIdentifiers" class="practicelab">Assign URIs to
              dataset versions and series</span></p>
          <p class="practicedesc">URIs should be assigned to individual versions
            of datasets as well as the overall series. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Like documents, many datasets fall into natural series or groups.
              For example:</p>
            <ul>
              <li>noon temperature readings in central London 1850 to the
                present day;</li>
              <li>today's noon temperature in London;</li>
              <li>the temperature in London at noon on 3rd June 2015.</li>
            </ul>
            <p>In different circumstances, it will be appropriate to refer
              separately to each of these examples (and many like them). </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Assigning URIs to dataset versions and series will enable references to a specific version of a dataset and to concepts such as a 'dataset series' and 'the latest version'.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>The W3C provides a good example of how to do this. The
              (persistent) URI for this document is
              http://www.w3.org/TR/2015/WD-dwbp-20150224/. That identifier
              points to an immutable snapshot of the document on the day of its
              publication. The URI for the 'latest version' of this document is
              http://www.w3.org/TR/dwbp/ which is an identifier for a series of
              closely related documents that are subject to change over time. At
              the time of publication, these two URIs both resolve to this
              document. However, when the next version of this document is
              published, the 'latest version' URI will be changed to point to
              that. </p>

<aside class = "example">
              
<p> Suppose that a new bus stop was created. To keep <code>:bus-stops-2015-05-05 </code> up to date, a new version of the dataset (<code>:bus-stops-2015-12-17</code>) is created. <code>:bus-stops-2015-12-17 </code> includes all the data from <code>:bus-stops-2015-05-05 </code> plus the data about the new bus stop. The two versions can be identified by the following URIs: </p>
<pre class="highlight">  
http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05 is the versioned URI of the first version of the dataset 
http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-12-17 is the version URI of the current version of the dataset 

    </pre>

              <!--p>To complete the London temperature example, one might imagine
                URIs as follows: </p>
              <pre class="highlight">  http://weather.example.com/temperature/UK/London/noon
  http://weather.example.com/temperature/UK/London/noon/today
  http://weather.example.com/temperature/UK/London/noon/2015-06-03  </pre> -->
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that each version of a dataset has its own URI, and that logical groups of datasets are also identifiable.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>-->
              <li>Discoverability</li>
              <li>Trust</li>
              <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li> -->
            </ul>
          </section>
        </div>
      </section>
      <!-- end of Data Identifiers section -->
      <!-- begin of Data Formats -->
      <section id="dataFormats">
        <h3>Data Formats</h3>
        <p>The formats in which data is made available to consumers are a key
          aspect of making that data usable. The best, most flexible access
          mechanism in the world is pointless unless it serves data in formats
          that enable use and reuse. Below we detail best practices in selecting
          formats for your data, both at the level of files and that of
          individual fields. W3C encourages use of formats that can be used by
          the widest possible audience and processed most readily by computing
          systems. Source formats, such as database dumps or spreadsheets, used
          to generate the final published format, are out of scope. This
          document is concerned with what is actually published rather than
          internal systems used to generate the published data.</p>
        <!-- begin of Machine-Readable Standardized Format BP -->
        <div class="practice">
          <p><span id="MachineReadableStandardizedFormat" class="practicelab">Use
              machine-readable standardized data formats </span></p>
          <p class="practicedesc">Data must be available in a machine-readable
            standardized data format that is adequate for its intended or
            potential use.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>As data becomes more ubiquitous, and datasets become larger and
              more complex, processing by computers becomes ever more crucial.
              Posting data in a format that is not machine readable places
              severe limitations on the continuing usefulness of the data. Data
              becomes useful when it has been processed and transformed into
              information. </p>
            <p> Using non-standard data formats is costly and inefficient, and
              the data may lose meaning as it is transformed. On the other hand,
              standardized data formats enable interoperability as well as
              future uses, such as remixing or visualization, many of which
              cannot be anticipated when the data is first published. The use of
              non-proprietary data formats should also be considered since it
              increases the possibilities for use and reuse of data </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>

            <p> Machine-readable standardized data formats will enable machines to easily read and process data published on the Web and humans to use computational tools typically available in the relevant domain to work with the data. </p>

          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Make data available in a machine readable standardized data
              format that is easily parseable including but not limited to CSV,
              XML, Turtle, NetCDF, JSON and RDF. </p>
            <!--<p>Consider which data formats potential users of the data are most
              likely to have the necessary tools to parse. Formats suggestion              are shown in the <a href="#OpenFormat"></a>.               Standard data              formats as well as the use of standard data vocabularies will              better enable machines to process the data.-->
            <!--<aside class="example">
        <p>The Census Team of the Office for Statistics of MyCity is in charge
          of the publication of data about census. They decided to
          publish one dataset about usual resident population collected in the 2001 Census.
A usual resident was generally defined as someone who spent most of their time at a specific address. This dataset shows both the 2001 population, the 1991 population, along with the rate of change, the split of the population between those living in households and those living in communal establishments, the size of the area in hectares, population density and the number of students away from home in the area.</p>
              <pre class="highlight">   
  :census
      a dcat:Dataset ;
      dcat:distribution :census.csv ;
      .
   :census.csv
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/census/2001/population.csv&gt; ;
      dct:title "CSV distribution of the usual resident population of MyCity, collected in the 2001 Census." ;
      dcat:mediaType "text/csv" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt; ;
      .
</pre> </aside> -->
<aside class="example">
        <p>John decides to provide data about the bus stops of the route that goes from the airport to the central bus station of MyCity. The information provided includes, besides others, the name, the description, the latitude and the longitude of the bus stops.</p>
              <pre class="highlight">   
  :busstops_airport_to_centralstation
      a dcat:Dataset ;
      dcat:distribution :busstops_airport_to_centralstation.csv
      .
  :busstops_airport_to_centralstation.csv
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/transport/bustops/airport_to_centralstation.csv&gt; ;
      dct:title "CSV distribution of the bus stops of the route that goes from the airport to the central bus station of MyCity." ;
      dcat:mediaType "text/csv" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt;
      .
</pre> </aside>

          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the data format conforms to a known machine-readable data format specification.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMachineRead">R-FormatMachineRead</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatStandardized">R-FormatStandardized</a>
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatOpen">R-FormatOpen</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>              <li>Access</li>
              <li>Interoperability</li> -->
              <li>Processability</li>
            </ul>
          </section>
        </div>
        <!-- end of Machine-Readable Standardized FormatBP -->
        <!-- begin of Multiple Formats BP -->
        <div class="practice">
          <p><span id="MultipleFormats" class="practicelab">Provide data in
              multiple formats </span></p>
          <p class="practicedesc">Data should be available in multiple data
            formats. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Providing data in more than one format reduces costs incurred in
              data transformation. It also minimizes the possibility of
              introducing errors in the process of transformation. If many users
              need to transform the data into a specific data format, publishing
              the data in that format from the beginning saves time and money
              and prevents errors many times over. Lastly it increases the
              number of tools and applications that can process the data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Data in multiple formats will enable data consumers to work with the data without transforming it.</p>
            <!--<p> It should be possible for data consumers to work with the data
              without transforming it.</p> -->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> Consider the data formats most likely to be needed by intended
              users, and consider alternatives that are likely to be useful in
              the future. Data publishers must balance the effort required to
              make the data available in many formats, but providing at least
              one alternative will greatly increase the usability of the data.</p>
            
<aside class="example">
              <p>In order to reach a larger number of data consumers, John
                decided to also provide a XML distribution of bus stops of the route that goes from the airport to the central bus station of MyCity.</p>
              <pre class="highlight">
  :busstops_airport_to_centralstation
      a dcat:Dataset ;
      dcat:distribution :busstops_airport_to_centralstation.csv ;
      dcat:distribution :busstops_airport_to_centralstation.xml
      .
  :busstops_airport_to_centralstation.csv
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/transport/bustops/airport_to_centralstation.csv&gt; ;
      dct:title "CSV distribution of the bus stops of the route that goes from the airport to the central bus station of MyCity." ;
      dcat:mediaType "text/csv" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt;
      .
  :busstops_airport_to_centralstation.xml
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/transport/bustops/airport_to_centralstation.xml&gt; ;
      dct:title "XML distribution of the bus stops of the route that goes from the airport to the central bus station of MyCity." ;
      dcat:mediaType "text/xml" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt;
      .
           </pre>
            </aside>

            <!-- <aside class="example">
              <p>In order to reach a larger number of data consumers, the Census Team
                decided to also provide a XML distribution of the usual resident population
                dataset.</p>
              <pre class="highlight">
  :census-001
      a dcat:Dataset;
      dcat:distribution :census.csv ;
      dcat:distribution :census.xml ;
      .
  :census.csv
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/census/2001/population.csv&gt; ;
      dct:title "CSV distribution of the usual resident population of MyCity, collected in the 2001 Census." ;
      dcat:mediaType "text/csv" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt; ;
      .
  :census.xml
      a dcat:Distribution ;
      dcat:downloadURL &lt;http://data.mycity.example.com/census/2001/population.xml&gt; ;
      dct:title "XML distribution of the usual resident population of MyCity, collected in the 2001 Census." ;
      dcat:mediaType "text/xml" ;
      dct:license &lt;http://reference.data.gov.uk/id/open-government-licence&gt; ;
      .
            </pre>
            </aside> -->
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if the complete dataset is available in more than one data format.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMultiple">R-FormatMultiple</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>              <li>Access</li>
              <li>Interoperability</li> -->
              <li>Processability</li>
            </ul>
          </section>
        </div>
        <!-- end of Multiple Formats BP -->
      </section>
      <!-- end of Data Formats -->
      <!-- begin of Data Vocabularies -->
      <section id="dataVocabularies">
        <h3>Data Vocabularies</h3>
        <!--<div class="issue"> There is a discussion going on in the group if the
          creation (and publication) of vocabularies is in the scope of the DWBP          document.</div>-->
        <p>Data is often represented in a structured and controlled way, making
          reference to a range of vocabularies, for example, by defining types
          of nodes and links in a data graph or types of values for columns in a
          table, such as the subject of a book, or a relationship “knows”
          between two persons. Additionally, the values used may come from a
          limited set of pre-existing values or resources: for example object
          types, roles of a person, countries in a geographic area, or possible
          subjects for books. Such vocabularies ensure a level of control,
          standardization and interoperability in the data. They can also serve
          to improve the usability of datasets. Say, a dataset contains a
          reference to a concept described in several languages. Such reference
          allows applications to localize their display of their search
          depending on the language of the user. </p>
        <p>According to W3C, <a href="http://www.w3.org/standards/semanticweb/ontology">vocabularies</a>
          define the concepts and relationships (also referred to as “terms” or
          “attributes”) used to describe and represent an area of concern.
          Vocabularies are used to classify the terms that can be used in a
          particular application, characterize possible relationships, and
          define possible constraints on using those terms. Several categories
          of vocabularies have been coined, for example, ontology, controlled
          vocabulary, thesaurus, taxonomy, code list, semantic network.</p>
        <p>There is no strict division between the artifacts referred to by
          these names. “Ontology” tends however to denote the vocabularies of
          classes and properties that structure the descriptions of resources in
          (linked) datasets. In relational databases, these correspond to the
          names of tables and columns; in XML, they correspond to the elements
          defined by an XML Schema. Ontologies are the key building blocks for
          inference techniques on the Semantic Web. The first means offered by
          W3C for creating ontologies is the RDF Schema [[RDF-SCHEMA]] language.
          It is possible to define more expressive ontologies with additional
          axioms using languages such as those in The Web Ontology Language
          [[OWL2-OVERVIEW]]. </p>
        <p>On the other hand, “controlled vocabularies”, “concept schemes”,
          “knowledge organization systems” enumerate and define resources that
          can be employed in the descriptions made with the former kind of
          vocabulary. A concept from a thesaurus, say, “architecture”, will for
          example be used in the subject field for a book description (where
          “subject” has been defined in an ontology for books). For defining the
          terms in these vocabularies, complex formalisms are most often not
          needed. Simpler models have thus been proposed to represent and
          exchange them, such as the ISO 25964 data model [[ISO-25964]] or W3C's
          Simple Knowledge Organization System [[SKOS-PRIMER]].</p>

<div class="note"> There is an ongoing discussion about Use
              standardized terms x Reuse Vocabularies <a href="https://www.w3.org/2013/dwbp/track/issues/253"> ISSUE-253 </a>. We are keen to have comments about this issue. </div>
        <!-- begin of Provide Metadata Standardized BP -->
        <div class="practice">
          <p><span id="MetadataStandardized" class="practicelab">Use
              standardized terms</span></p>
          <p class="practicedesc">Standardized terms should be used to provide
            data and metadata.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Using standardized lists of codes other commonly used terms for data
              and metadata values as much as possible helps avoiding
              ambiguity and clashes between these values.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Standardized code lists and other commonly used terms will enhance interoperability and consensus among data publishers and consumers. </p>

            <!--<p>The benefit of using standardized code lists and other commonly
              used terms is to enhance interoperability and consensus among
              data publishers and consumers.</p>-->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Values in datasets should refer as much as possible to
              standardization efforts or organizations, which defines terms or codes as a
              clear reference.</p>
            <p>Organizations like the Open Geospatial Consortium (OGC), ISO, W3C, libraries and research data services, etc., provide
              list of codes, terminologies or even Linked Data vocabularies that can be used for this.</p>
            <p>A key point is to make sure the dataset or its documentation provides enough (human- and machine-readable) context
              for the values, so that data consumers can retrieve and exploit the standardized meaning
              of these values. In the context of the Web, using unambiguous, Web-based identifiers for standardized values
              is an efficient way to do this.</p>
            <aside class="example">
            <p>1. The Library of Congress publishes lists of ISO 639 country codes as Linked Data (see [[ISO639-1-LOC]] for two-letter codes):</p>
<pre class="highlight prettyprint prettyprinted">:bus-stops
    dct:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt; .
</pre>
            <p>2. The <a href="http://www.bodc.ac.uk/products/web_services/">British Oceanographic Data Center Web Services</a> publishes a reference list of URIs for types of tools to perform scientific measures, such as <code>http://vocab.nerc.ac.uk/collection/L05/current/357/</code> for acoustic tracking systems:</p>
<pre class="highlight prettyprint prettyprinted">:measurement-001 a prov:Activity ;
    prov:used :sensor-001 .
:sensor-001 a prov:Agent ;
    dct:type &lt;http://vocab.nerc.ac.uk/collection/L05/current/357/&gt; .
</pre>
           <p>(note that real-life data should use more specific classes and properties than the PROV ones for
              typing a measurement activity, an instrument and the relationship between these)</p>
            <p>3. Australia's <a href="http://www.bodc.ac.uk/products/web_services/">Solid Earth and Environment Grid</a> publish a reference list of URIs for geologic timescale elements from the International Commission on Stratigraphy's Chronostratigraphic Chart, such as <code>http://resource.geosciml.org/classifier/ics/ischart/Paleozoic</code> for the Paleozoic Era:</p>
<pre class="highlight prettyprint prettyprinted">:dataset-005 a dcat:Dataset ;
    dct:temporal &lt;http://resource.geosciml.org/classifier/ics/ischart/Paleozoic&gt; .
</pre>
            <p>4. Google maintains a <a href="https://developers.google.com/transit/gtfs/">General Transit Feed Specification</a> that defines
              a format for publishing public transportation data. This format relies on a set of fields like <code>route_short_name</code> or
              <code>route_type</code> that are
              <a href="https://developers.google.com/transit/gtfs/reference#field-definitions">carefully defined</a>
              and exposed to constant community feedback in order to facilitate consensus, which leads to easier adoption and greater interoperability.
              Definitions include specifications of coded values for some fields, as in the following extract for <code>route_type</code> codes:</p>
<pre class="highlight prettyprint prettyprinted">
0 - Tram, Streetcar, Light rail. Any light rail or street level system within a metropolitan area.
1 - Subway, Metro. Any underground rail system within a metropolitan area.
2 - Rail. Used for intercity or long-distance travel.
</pre>
              <p>Note that in a non-linked data fashion, these fields and codes have no individual Web identifiers nor machine-readable semantics.
             Exploiting them thus requires implementers to parse the documentation and encode interpretations in each individual application consuming the data.
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test </p>
            <p>Check if the terms or codes to be used are defined in a standard organization/working group of body such as IETF, OGC, W3C, etc.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataStandardized">R-MetadataStandardized</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataDocum">R-MetadataDocum</a>
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityComparable">R-QualityComparable</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <!--<li>Linkability</li>  <li>Discoverability</li> -->
              <li>Trust</li> <!-- <li>Access</li> -->
              <li>Interoperability</li>
            </ul>
          </section>
        </div>
        <!-- end of Provide Metadata Standardized BP -->
        <!-- begin of Reuse vocabularies BP -->
        <div class="practice">
          <p><span id="ReuseVocabularies" class="practicelab">Reuse vocabularies</span></p>
          <p class="practicedesc">Shared vocabularies should be used to encode
            data and metadata.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>Use of shared vocabularies captures and facilitates consensus in communities.
              Reusing existing vocabularies to encode datasets and metadata increases interoperability and reduces
              redundancies, encouraging reuse of these data. In particular, the
              use of shared vocabularies for metadata (especially structural, provenance, quality
              and versioning metadata) helps the automatic processing of both data and metadata.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> Using the same vocabulary to describe metadata will make datasets and metadata sets easier to be compared by humans or machines. 
When two datasets or metadata sets use the same vocabulary, (automatic) processing tools designed for one can be more easily applied to the other. This greatly facilitates re-use of datasets.
</p>
            <!--<p>Datasets and metadata sets are easier to be compared by humans or machines when
              they use the same vocabulary to describe metadata.</p>
            <p>When two datasets or metadata sets use the same vocabulary, (automatic) processing tools
              designed for one can be more easily applied to the other. This greatly facilitates re-use of datasets.</p>-->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p> The <a href="http://www.w3.org/TR/ld-bp/#VOCABULARIES">Vocabularies</a> section of the <abbr title="World Wide Web Consortium">W3C</abbr> Best Practices for
              Publishing Linked Data [<cite><a href="#bib-LD-BP" class="bibref">LD-BP</a></cite>] provides guidance on the
              discovery, evaluation and selection of existing vocabularies.</p>
            <aside class="example">
	    <p>1. All examples in this document show how common vocabularies (PROV, SKOS, etc) can be reused
              to express data and metadata statements, instead of minting entirely new classes and properties.</p>
              <p>2. The DCAT vocabulary to express metadata on datasets [<cite><a href="#bib-VOCAB-DCAT" class="bibref">VOCAB-DCAT</a></cite>]
              re-uses elements from Dublin Core, FOAF, SKOS and vCard, see its
              <a href="https://www.w3.org/TR/vocab-dcat/#namespaces-1">namespaces</a> section.
              For example, reusing Dublin Core properties like <code>dct:title</code> instead of
              creating new ones (say, <code>dcat:title</code>) enables DCAT-based metadata
              to be consumed by any application that can read and manipulate Dublin Core statements.</p>
              <p>3. In the digital culture sector, the data model for the initiative
              <a href="http://europeana.eu">Europeana</a> (<a href="http://www.europeana.eu/schemas/edm/">EDM</a>)
              also widely re-uses existing shared vocabularies like Dublin Core, FOAF, SKOS, etc.
              This has facilitated adoption of EDM by Europeana's data providers and helped
              position it as a best practice for similar initiatives in the same sector.
              For instance, <a href="http://dp.la/info/map/">metadata application profile</a> from the
              <a href="http://dp.la">Digital Public Library of America</a> reuses EDM and thus
              the various vocabularies that EDM builds on. As a result, large amounts of
              digital culture data have become more interoperable within the sector. That data is
              also easier to reuse by consumers from other communities, who are not familiar
              with the traditional models and terminologies used by library, archives and museums.</p>
            </aside>
          </section>
          <section>
            <p class="subhead">How to Test</p>
            <p>Using vocabulary repositories like the <a href="http://lov.okfn.org">Linked Open Vocabularies repository</a>
              or lists or services mentioned in technology-specific best practices
              such as the Best Practices for Publishing Linked Data [<cite><a href="#bib-LD-BP" class="bibref">LD-BP</a></cite>],
              or the <a href="https://www.w3.org/2011/rdfa-context/rdfa-1.1">Core Initial Context for RDFa and JSON-LD</a>,
              check that classes, properties, terms, elements or attributes used to represent a dataset do not replicate those
              defined by vocabularies used for other datasets.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityComparable">R-QualityComparable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabOpen">R-VocabOpen</a>,
              <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>
            </p>
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Processability</li>
              <!-- <li>Comprehension</li><li>Linkability</li><li>Discoverability</li><li>Trust</li><li>Access</li>-->
              <li>Interoperability</li>
            </ul>
          </section>
        </div>
      <!-- end of Reuse vocabularies BP -->
      <!-- begin of Choose the right formalization level BP -->
      <div class="practice">
        <p><span id="ChooseRightFormalizationLevel" class="practicelab">Choose the right formalization level</span></p>
        <p class="practicedesc">When reusing a vocabulary, a data publisher
          should opt for a level of formal semantics that fit data and
          applications.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Formal semantics help to establish precise specifications
            that support establishing the intended meaning of the vocabulary and
            the performance of complex tasks such as reasoning. On the other
            hand, complex vocabularies require more effort to produce and
            understand, which could hamper their reuse, as well as the
            comparison and linking of datasets exploiting them. Highly
            formalized data is also harder to exploit by inference engines: for
            example, using an OWL class in a position where a SKOS concept is
            enough, or using OWL classes with complex OWL axioms raises the
            formal complexity of the data according to the OWL Profiles
            [[OWL2-PROFILES]]. Data producers should therefore seek to identify
            the right level of formalization for particular domains, audiences
            and tasks, and maybe offer different formalization levels when one
            size does not fit all.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>The data supports all application cases but should not be more
            complex to produce and reuse than necessary;</p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Identify the "role" played by the vocabulary for the datasets, say,
            providing classes and properties used to type resources and provide
            the predicates for RDF statements, or elements in an XML Schema, as
            opposed to providing simple concepts or codes that are used for
            representing attributes of the resources described in a dataset.
            When simpler data models are enough to convey the necessary semantics,
            represent vocabularies using them.</p>
          <p>Even when a language with rich formal semantics like OWL is used to
            express a vocabulary, it is preferable that this vocabulary has a minimal
            <em>ontological commitment</em>, i.e. by featuring only the formal axioms
            that enable inferences and validation checks
            that have been explicitly identified as relevant for the domain or application at hand.
            The more axioms are used to specify a vocabulary, the narrower its usage is;
            unnecessary axioms unnecessarily constrain the reuse of a vocabulary
            across applications.</p>
          <aside class="example">
          <p>1. For expressing simple vocabularies like thesauri or code lists as Linked Data,
            a simpler data model like SKOS may be preferred over formal
            ontology languages like OWL; see for example how <a href="http://www.w3.org/TR/vocab-data-cube/#schemes">concept
              schemes and code lists</a> are represented and used in the RDF Data Cube
            Recommendation [[VOCAB-DATA-CUBE]].</p>
          <p>2. Designers of the SKOS ontology itself have minimized its ontological commitment by questioning
            all formal axioms that were suggested for its classes and properties. Often they have been rejected
            because their use, while beneficial to many applications, would have created
            formal inconsistencies for the data from other applications, making SKOS not usable at all
            for these. As an example, the property <code>skos:broader</code> was not defined
            as a transitive property, even though it would have fit the way hierarchical links between concepts
            are created for many thesauri [[SKOS-DESIGN]].</p>
          <p>3. The vocabularies for Data Quality [[DQV]] and Data Usage [[DUV]] created by the W3C Working
            Group publishing this document have also sought to minimize the number of formal
            axioms involved in their definition. For instance, the property <code>dqv:hasQualityMeasurement</code>
            has no formal domain in the RDFS/OWL sense, even though it is expected to be most often used with
            resources that are of type <code>dcat:Dataset</code> or <code>dcat:Distribution</code>.
            This allows application designers to employ it for other types of entities, for which
            quality measurements would also be relevant but that were not in the focus of
            the design process for DQV.</p>
          <p>4. The <a href="http://schema.org">Schema.org</a> schemas for publishing structured
            data on the Web have adopted an informative rather than normative approach for defining
            the types of objects these properties can be used with. For instance, the values of the property
            <a href="http://schema.org/author"><code>author</code></a> are only "expected" to be
            of type <code>Organization</code> or <code>Person</code>. <code>author</code> "can be used" on the
            type <code>CreativeWork</code> but this is not a strict constraint.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>For formal knowledge representation languages, applying an inference engine on top of the data that uses a given vocabulary does not produce too many statements that are unnecessary for target applications.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a>,
            <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityComparable">R-QualityComparable</a>
          </p>
        </section>
        <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>
              <li>Comprehension</li>
              <!--<li>Linkability</li>  <li>Discoverability</li> <li>Trust</li> <li>Access</li> -->
              <li>Interoperability</li>
            </ul>
        </section>
      </div>
      <!-- end of Choose the right formalization level BP -->
    </section>
    <!-- end of Data Vocabularies -->
    <!-- begin of Sensitive Data -->
    <section id="sensitive">
      <h3>Sensitive Data</h3>
      <p>To support best practices for publishing sensitive data, data
        publishers should identify all sensitive data, assess the exposure risk,
        determine the intended usage, data user audience and any related usage
        policies, obtain appropriate approval, and determine the appropriate
        security measures needed to taken to protect the data, which should also
        account for secure authentication and use of HTTPS.</p>
      <p>Data publishers should preserve the privacy of individuals where the
        release of personal information would endanger safety (unintended
        accidents) or security (deliberate attack). Privacy information might
        include: full name, home address, mail address, national identification
        number, IP address (in some cases), vehicle registration plate number,
        driver's license number, face, fingerprints, or handwriting, credit card
        numbers, digital identity, date of birth, birthplace, genetic
        information, telephone number, login name, screen name, nickname, health
        records etc.</p>
      <p> At times, because of sharing policies sensitive data may not be
        available in part or in its entirety. Data unavailability represents
        gaps that may affect the overall analysis of datasets. To account for
        unavailable data, data publishers should publish information about
        unavoidable data gaps.</p>
      <div class="practice">
        <p><span id="DataUnavailabilityReference" class="practicelab">Provide
            data unavailability reference</span></p>
        <p class="practicedesc">References to data that is not open, or
          available under different restrictions to the origin of the reference,
          should provide explanation about how the referred data can be accessed
          and who can access it. </p>
        <!-- <p> This best practice is a specialization of the higher level <a href="#ProvideMetadataHumanMachine">Provide
              metadata for both humans and machines</a> best practice. </p> -->
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Publishing online documentation about unavailable data due to
            sensitivity issues provides a means for publishers to explicitly
            identify knowledge gaps. This provides a contextual explanation for
            consumer communities thus encouraging use of the data that <em>is</em>
            available.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Data unavailability reference will enable data consumers to know data that is referred to from the current dataset but that is unavailable or only available under different conditions.</p>
          <!--<p>Publishers should provide information about data that is referred
            to from the current dataset but that is unavailable or only
            available under different conditions.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p> Depending on the machine/human context there are a variety of ways to indicate data unavailability. Data publishers may publish an HTML document that gives a
            human-readable explanation for data unavailability.  From a machine application interface perspective, appropriate HTTP status codes with customized human readable messages can be used.  Examples of status codes include: 404 (file not found), 410 (permanently removed), 503 (service *providing data* unavailable).

<!-- p> RDF may be used
            to provide a machine readable version of the same information. If
            appropriate, consider editing the server's 4xx response page(s) to
            provide the information. </p>
            <p> </p> -->
            </p>
          <aside class="example">
            <p>The dataset created for the bus stops can contain sensitive
              data, for instance, privacy information about the bus' driver. In this case, the publisher provides an explanation informing that the personal data about the
              bus' driver is not available.</p>
            <!--<p>The information bellow was omitted from the dataset:</p>
            <p>driver_id, driver_name, driver_address, driver_license.</p> -->
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Check if the dataset includes references to other data that is unavailable in a human-readable way.</p>
          <p>Check whether an explanation is available in the metadata and/or description of it in a machine-readable format and without syntax error.</p>

        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessLevel">R-AccessLevel</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitivePrivacy">R-SensitivePrivacy</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-SensitiveSecurity">R-SensitiveSecurity</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>-->
            <li>Trust</li>
            <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of versions For API BP -->
    </section>
    <!-- end of Data Sensitive -->
    <!-- begin of Data Access -->
    <section id="dataAccess">
      <h3>Data Access</h3>
      <p>Providing easy access to data on the Web enables both humans and
        machines to take advantage of the benefits of sharing data using the Web
        infrastructure. By default, the Web offers access using Hypertext
        Transfer Protocol (HTTP) methods. This provides access to data at an
        atomic transaction level. However, when data is distributed across
        multiple files or requires more sophisticated retrieval methods
        different approaches can be adopted to enable data access, including
        bulk download and <abbr title="Application Programming Interfaces">API</abbr>s.
        </p>
      <p>One approach is packaging data in bulk using non-proprietary file
        formats (for example tar files). Using this approach, bulk data is
        generally pre-processed server side where multiple files or directory
        trees of files are provided as one downloadable file. When bulk data is
        being retrieved from non-file system solutions, depending on the data
        user communities, the data publisher can offer APIs to support a series
        of retrieval operations representing a single transaction.</p>
      <p>For data that is streaming to the Web in “real time” or “near real
        time”, data publishers should publish data or use APIs to enable
        immediate access to data, allowing access to critical time sensitive
        data, such as emergency information, weather forecasting data, or
        published system metrics. In general, APIs should be available to allow
        third parties to automatically search and retrieve data published on the
        Web. </p>
      <!--p>On a further note, it can be observed that data on the Web is
        essentially about the description of entities identified by a unique,
        Web-based, identifier (an URI). Once the data is dumped and sent to an
        institute specialised in digital preservation the link with the Web is
        broken (dereferencing) but the role of the URI as a unique identifier
        still remains. In order to increase the usability of preserved dataset
        dumps it is relevant to maintain a list of these identifiers. </p-->
      <!-- begin of BP Bulk Access-->
      <div class="practice">
        <p><span id="BulkAccess" class="practicelab">Provide bulk download </span></p>
        <p class="practicedesc">Datasets should be available for bulk download. </p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>When Web data is distributed across many URIs but might logically
            be organized as one container, accessing the data in bulk can be useful.
            Bulk access provides a consistent means to handle the data as one
            dataset. Individually accessing data over many retrievals can be cumbersome
            and, if used to reassemble the complete dataset, can lead to inconsistent approaches to handling the data.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Bulk download will enable large file transfers (which would require more time than a typical user would consider reasonable) by dedicated file-transfer protocols. </p> 

          <!--<p> It should be possible to download data on the Web in bulk. Data
            publishers should provide a way, through either a single-file download or
            a single API call, for consumers to access all the data. Large file transfers (which would require more time than a typical user would consider reasonable) should be enabled by dedicated file-transfer protocols. The bulk download should include the metadata describing the dataset. Discovery metadata [[VOCAB-DCAT]] should also be available outside the bulk downlaod.
            </p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Depending on the nature of the data and consumer needs, possible
            approaches could include the following:</p>
          <ul>
            <li>Preprocessing a copy of the data into a compressed archive format
              and making the data accessible from one URI. This is
              particularly useful for handling data that changes infrequently.</li>
            <li>Hosting an API that includes the ability to
              retrieve a bulk download in addition to dynamic queries. This
              approach is useful for capturing a complete snapshot of dynamic data.</li>
            <li>For very large datasets, bulk file transfers can be enabled via means other than http, such as <a href="http://www.slac.stanford.edu/~abh/bbcp/">bbcp</a> or <a href="http://toolkit.globus.org/toolkit/docs/latest-stable/gridftp/">GridFTP</a>.</li>
          </ul>
          <p> The bulk download should include the metadata describing the dataset. Discovery metadata [[VOCAB-DCAT]] should also be available outside the bulk downlaod.</p>
          <aside class="example">
            <p>The MyCity transit agency may have a large dataset with arrival times for the various transit modes that was collected over the entire year of 2015. The data might be stored as a CSV file for each month. Suppose the agency wants to make that data available as a bulk download containing all the CSV files, for a hackathon. Since all the arrival data for all the transit services would be a lot of data, and they want to provide all the months together as one dataset, they might offer it as a single-file, compressed archive (tarred and gzipped).</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Check if humans can retrieve copies of preprocessed bulk data through existing tools (such as a browser).</p>
          <p>Check if clients can test bulk access (through an API or queries to web resources with discoverable metadata about the bulk data).</p>

        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessBulk">R-AccessBulk</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>-->
            <li>Access</li>
            <!--              <li>Interoperability</li>
              <li>Processability</li> -->
          </ul>
        </section>
      </div>
      <!-- end of BP Bulk Access -->

      <!-- begin of BP Subsetting-->
      <div class="practice">
        <p><span id="ProvideSubsets" class="practicelab">Provide Subsets for Large Datasets</span></p>
        <p class="practicedesc">If your dataset is large, enable users and applications to readily work with useful subsets of your data.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Large datasets can be difficult to move from place to place. It can also be inconvenient for users to store or parse a large dataset. Users should not have to download a complete dataset if they only need a subset of it. Moreover, Web applications that tap into large datasets will perform better if their developers can take advantage of “lazy loading”, working with smaller pieces of a whole and pulling in new pieces only as needed. The ability to work with subsets of the data also enables offline processing to work more efficiently. Real-time applications benefit in particular, as they can update more quickly.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Subsetting of large datasets will enable both human users and applications to be able to access subsets of a dataset, rather than the entire thing, as needed. Subsetting approaches should aim for a high ratio of needed data to unneeded data for the largest number of users. Static datasets that users in the domain would consider to be large will be downloadable in smaller pieces. APIs will make slices or filtered subsets of the data available, the granularity depending on the needs of the domain and the demands of performance in a Web application.</p><!--p> Both human users and applications should be able to access subsets of a dataset, rather than the entire thing, as needed. Subsetting approaches should aim for a high ratio of needed data to unneeded data for the largest number of users. Static datasets that users in the domain would consider to be large should be downloadable in smaller pieces. APIs should make slices or filtered subsets of the data available, the granularity depending on the needs of the domain and the demands of performance in a Web application.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approaches to Implementation</p>
          <p>Consider the expected use cases for your dataset and determine what types of subsets are likely to be most useful. An API is usually the most flexible approach to serving subets of data, as it allows customization of what data is transferred, making the available subsets much more likely to provide the needed data--and little unneeded data--for any given situation. The granularity should be suitable for Web application access speeds. (An API call that  returns within one second enables an application to deliver interactivity that feels natural. Data that takes more than ten seconds to deliver will likely cause users to suspect failure.)</p>
          <p>Another way to subset a dataset is to simply split it into smaller units and make those units individually available for download or viewing.</p>
          <p>It can also be helpful to mark up a dataset so that individual sections through the data (or even smaller pieces, if expected use cases warrant it) can be processed separately. One way to do that is by indicating “slices” with the <a href="https://www.w3.org/TR/vocab-data-cube/#cubes-slices">RDF Data Cube Vocabulary</a>.</p>
          <aside class="example">
            <p> 1. Using an API: the MyCity transit API offers information about individual buses, bus stops, and time points. It can accept a query for all the timepoints for a single stop on a single bus route, or it can accept one for all the buses along one route at one time point, or it can accept one for all the time points for a single bus on a single route. These small slices through the data enable Web applications to update data quickly and deliver it to riders on demand, interactively. </p>
            <p>2. Splitting the datset: the MyCity transit agency has a set of nicely formatted single-route schedules available in PDF format. Users can select the route they plan to ride from a menu and view or download the schedule for that route alone.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Compare your assessment of the expected use cases and check that each of the subsets that you expect to be requested can be returned from a single identifier. Check also that the granularity of subsetting is consistent throughout the dataset.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-GranularityLevels">R-GranularityLevels</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessRealTime">R-AccessRealTime</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-GranularityLevels">R-GranularityLevels</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li><li>Linkability</li>
            <!--              <li>Comprehension</li>
                           <li>Discoverability</li>              <li>Trust</li>-->
            <li>Access</li>
            <!--              <li>Interoperability</li> -->
              <li>Processability</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Subsetting -->

      <!-- begin of BP Content Negotiation -->
      <div class="practice">
        <p><span id="Conneg" class="practicelab">Use content negotiation for serving data available in multiple formats</span></p>
        <p class="practicedesc">It is recommended to use content negotiation for
          serving data available in multiple formats.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>It is possible to have data being served in a HTML page mixed with
            human-readable and machine-readable data. RDFa could be used to mix
            HTML content with semantic data. </p>
          <p>But, in some cases this page is subject of scraping by some
            applications in order to get data available. When structured data is
            mixed with HTML, but it is possible to have a different
            representation with the same structured data, written in Turtle or
            JSON-LD, it is recommended to serve this page using Content
            Negotiation.</p>
          <p>A dataset can also be served in different representations, and can be retrieved by using an API or by direct access to the resource URI. In those cases, HTTP Content Negotiation technique can be used.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Content negotiation will enable different resources or different representations of the same resource to be served according to the request made by the client. </p>

          <!--<p> It should be possible to serve the same resource with different
            representations. </p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>A possible approach to implementation is to configure the Web
            server to deal with content negotiation of the requested resource.</p>
          <p>The specific format of the resource's representation can be accessed
            by the URI or by the Content-type of the HTTP Request.</p>
          <aside class="example">
            <p>Different representations of the bus stops dataset can be served according to the specified content type of the HTTP Request: <br />

              Using <code>cURL</code> to get the content of <code>http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops</code> represented in CSV and in JSON-LD format.

              <pre class="highlight">curl -H "Accept: text/csv" http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops</pre>
              <pre class="highlight">curl -H "Accept: application/ld+json" http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops</pre>

          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Check the available representations of the resource and try to get them specifying the accepted content on the HTTP Request header.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: </p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>-->
            <li>Access</li>
            <!--              <li>Interoperability</li>
              <li>Processability</li> -->
          </ul>
        </section>
      </div>
      <!-- end of BP Content Negotiation -->
      <!-- begin of BP Access Real-time-->
      <div class="practice">
        <p><span id="AccessRealTime" class="practicelab">Provide real-time
            access </span></p>
        <p class="practicedesc">When data is produced in real-time, it should be
          available on the Web in real-time. </p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p> The presence of real-time data on the Web enables access to
            critical time sensitive data, and encourages the development of
            real-time Web applications. Real-time access is dependent on
            real-time data producers making their data readily available to the
            data publisher. The necessity of providing real-time access for a
            given application will need to be evaluated on a case by case basis
            considering refresh rates, latency introduced by data post
            processing steps, infrastructure availability, and the data needed
            by consumers. In addition to making data accessible, data publishers
            may provide additional information describing data gaps, data errors
            and anomalies, and publication delays.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Real-time access will enable data to be  available at real time or near real time, where real-time means a range from milliseconds to a few seconds after the data creation, and near real time is a predetermined delay for expected data delivery.</p>
          <!--<p>Data should be available at real time or near real time, where
            real-time means a range from milliseconds to a few seconds after the
            data creation, and near real time is a predetermined delay for
            expected data delivery. </p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Real-time data accessibility may be achieved through two means: </p>
          <ul>
            <li> Push - as data is produced the producers communicates data to
              the data publisher either by disseminating data to the publisher
              or making storage available accessible to the data producer.</li>
            <li>On-Demand (Pull) - available real-time data is made available
              upon request. In this case, data publishers will provide an API to
              facilitate these read-only requests.</li>
          </ul>
          In addition to data access, to ensure credibility providing access to
          error conditions, anomalies, and instrument "house keeping" data
          enhance real-time applications ability to interpret and convey
          real-time data quality to consumers.
          <aside class="example">
            <p><a href="dwbp-realtime-example.html">Example page</a> showing an API specification for real-time data.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          To adequately test real time data access, data will need to be tracked
          from the time it is initially collected to the time it is published
          and accessed. [[PROV-O]] can be used to describe these activities.
          Caution should be used when analyzing real-time access for systems
          that consist of multiple computer systems. For example, tests that
          rely on wall clock time stamps may reflect inconsistencies between the
          individual computer systems as opposed to data publication time
          latency.
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessRealTime">R-AccessRealTime</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>-->
            <li>Access</li>
            <!--              <li>Interoperability</li>
              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of BP Access Real-time-->
      <!-- begin of BP Access Up to date -->
      <div class="practice">
        <p><span id="AccessUptoDate" class="practicelab">Provide data up to date
          </span></p>
        <p class="practicedesc"> Data must be available in an up-to-date manner
          and the update frequency made explicit. </p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Data on the Web availability should closely coincide with data
            provided at creation time, collection time, or after it has been
            processed or changed. Carefully synchronizing data publication to
            the update frequency encourages data consumer confidence and reuse.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>When new data is provided or data is updated, it must be published
            to coincide with the data changes.</p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Implement an API to enable data access. When data is provided by
            bulk access, new files with new data should be provided as soon as
            additional data is created or updated. Or, use technologies that are intended to expose data on the Web using interlinked resources, like Activity Streams or Atom.</p>
          <p>If the site provides multiple data feeds providing multiple updates, the last update date time stamp should be co-located with each separate data feed. The international date format is recommended to avoid any ambiguity <a href="https://www.w3.org/International/questions/qa-date-format">https://www.w3.org/International/questions/qa-date-format</a>.</p>
          <aside class="example">
            <p>A real world example: <br>
            The weather services such as the U.S. based National Oceanic and Atmospheric Administration (NOAA) provides regional forecast and current weather condition information (<a href="http://www.wrh.noaa.gov/sew/">http://www.wrh.noaa.gov/sew/</a>).</p>
            <p>Information in the form of weather condition maps are periodically updated to keep residents informed of changing weather conditions. Data publishers provide a timezone specific date time stamp of the latest condition updates <em>"Last map update: Mar, 3rd 2016 at 9:03:07 pm PST"</em>.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Write test standard operating procedure for data publisher to keep
            test data on Web site up to date.</p>
          <p>Following standard operating procedure:</p>
          <ul>
            <li>Write test client to access published data. </li>
            <li>Access data and save first copy locally. </li>
            <li>Publish an updated version of data.</li>
            <li>Access data and save second copy locally.</li>
            <li>Compare first copy to second copy to verify change.</li>
          </ul>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessUpToDate">R-AccessUptodate</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>-->
            <li>Access</li>
            <!--              <li>Interoperability</li>
              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of BP Access Up to date -->
      <!-- begin Data Access APIs group -->
      <div>
        <h4>Data Access APIs</h4>
         <!-- begin of Use an API -->
        <div class="practice">
          <p><span id="useanAPI" class="practicelab">Make Data Available through an API</span></p>
          <p class="practicedesc">Offer an API to serve data if you have the resources to do so.</p>
          <!-- <p class="practicedesc">When there are resources available, you <em class="rfc2119">should</em> offer an API</p> -->
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>An API offers the greatest flexibility and processability for consumers of your data. It can enable real-time data usage, filtering on request, and the ability to work with the data at an atomic level. If your dataset is large, frequently updated, or highly complex, an API is likely to be the best option for publishing your data.</p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Developers will have programmatic access to the data for use in their own applications. Data can be updated without requiring effort on the part of consumers. Web applications will be able to obtain specific data by querying a programmatic interface.
</p>
            <!--p>Developers will have programmatic access to the data for use in their own applications. Data can be updated without requiring effort on the part of consumers.</p-->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
            <p>Creating an API is a little more involved than posting data for download. It requires some understanding of how to build a Web application. One need not necessarily build from scratch, however. If you use a data management platform, such as CKAN, you may be able to enable an existing API. Many Web development frameworks include support for APIs, and there are also frameworks written specifically for building custom APIs.</p>
            <aside class="example"><p> Rails, Django, and Express are some example Web development frameworks that offer support for building APIs. Examples of API frameworks include Swagger, Apigility, Restify, and Restlet.</p></aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check if a test client can simulate calls and responses.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessRealTime">R-AccessRealTime</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessUpToDate">R-AccessUpToDate</a></p>
          </section>
          <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li>  <li>Processability</li><li>Interoperability</li> <li>Access</li>

              <!--              <li>Comprehension</li>
                <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>-->
            </ul>
          </section>
        </div>
        <!-- end of Use an API -->
        <!-- begin of Web Standards for APIs -->
        <div class="practice">
          <p><span id="APIHttpVerbs" class="practicelab">Use Web Standards as the foundation of APIs</span></p>
          <p class="practicedesc">
When designing APIs, use an architectural style that is founded on the technologies of the Web itself.

          <!--When designing APIs, it is recommended to use an architectural style that is founded on the technologies of the Web itself. Web standards such as URIs, HTTP verbs, HTTP response codes, MIME types, typed HTTP Links, and content negotiation can all help solve difficult problems and enable you to build a flexible and useful data service. --> </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>APIs that are built on Web standards leverage the strengths of the Web. For example, using HTTP verbs as methods and URIs that map directly to individual resources helps to avoid tight coupling between requests and responses, making for an API that is easy to maintain and can readily be understood and used by many developers. The statelessness of the Web can be a strength in enabling quick scaling, and using hypermedia enables rich interactions with your API. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
              <p> Developers who have some experience with APIs based on Web standards, such as REST, will have an initial understanding of how to use the API because it uses a standardized interface. The API will also be easier to maintain.</p>
              <!--<p>Developers who have some experience with APIs based on Web standards, such as REST, will have an initial understanding of how to use your API because it uses a standardized interface. Your API will also be easier to maintain. </p>-->
          </section>
          <section class="how">
            <p class="subhead">Possible Approaches to Implementation</p>
            <p>REST (REpresentational State Transfer) is an architectural style that, when used in a Web API, takes advantage of the architecture of the Web itself. A full discussion of how to build a RESTful API is beyond the scope of this document, but there are many resources and a strong community that can help in getting started. There are also many RESTful development frameworks available. If you are already using a Web development framework that supports building REST APIs, consider using that. If not, consider an API-only framework that uses REST.</p>
            <p>Another aspect of implementation to consider is making a hypermedia API, one that responds with links rather than data alone. Links are what make the Web a web, and data APIs can be more useful and usable by including links in their responses. The links can offer additional resources, documentation, and navigation. Even for an API that does not meet all the constraints of REST, returning links in responses can make for a service that is rich and self-documenting. </p>
            <aside class="example">An example response for information about a certain bus route from a hypermedia API might look like the following:
              <pre>
  {
    "code": "200",
    "text": "OK",
    "data": {
      "update_time": "2013-01-01T03:00:02Z",
      "route_id": "52",
      "route_name" "Lexington South"
      "route_description": "Lexington corridor south of Market",
      "route_type": "3",
    },
    "links": [
      {
        "href": "https://api.transit.mycity.org/v2/routes/52",
        "rel": "self",
        "type": "application/json",
        "method": "GET"
      },
      {
        "href": "https://api.transit.mycity.org/v2/routes",
        "rel": "collection",
        "type": "application/json",
        "method": "GET"
      }
      {
        "href": "https://api.transit.mycity.org//v2/schedules/52",
        "rel": "described-by",
        "type": "application/json",
        "method": "GET"
      },
      {
        "href": "https://api.transit.mycity.org//v2/maps/52",
        "rel": "described-by",
        "type": "application/json",
        "method": "GET"
      }
    ]
  }
              </pre>
            </aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Check that the service avoids using http as a tunnel for calls to custom methods, and check that URIs do not contain method names.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-APIDocumented">R-APIDocumented</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-UniqueIdentifier">R-UniqueIdentifier</a></p>
          </section>
           <section class="benefits">
            <p class="subhead">Benefits</p>
            <ul class="benefitsList">
              <li>Reuse</li><li>Linkability</li><li>Interoperability</li>
              <!--              <li>Comprehension</li>
                                           <li>Trust</li>-->
              <li>Discoverability</li> <li>Access</li>
              <li>Processability</li>
            </ul>
          </section>
        </div>
        <!-- end of Web Standards for APIs -->
        <!-- begin of Document API code BP -->
        <div class="practice">
          <p><span id="documentYourAPI" class="practicelab">Provide complete documentation for your API</span></p>
          <p class="practicedesc">Provide complete information on the Web about your API. Be sure to update documentation as you add features or make changes.</p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <!-- <p>The primary consumers of an API are developers. In order to develop against your API, a developer will need to understand how to use it.</p> -->
            <p> Developers are the primary consumers of an API and the API documentation is the first clue about the quality and usefulness of the API. When API documentation is complete and easy to understand, developers are probably more willing to continue their journey implementing it. In order to develop against it, they will need to understand how to use it. Providing comprehensive documentation in one place allows developers to code efficiently. Highlighting changes enables your users to take advantage of new features and adapt their code if needed.</p>


            <!--p>Developers are the primary consumers of an API. In order to develop against it, they will need to understand how to use it. Providing comprehensive documentation in one place allows developers to code efficiently. Highlighting changes enables your users to take advantage of new features and adapt their code if needed. </p-->
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p> API documentation will enable developers to obtain detailed information about each call to the API, including the parameters it takes and what it is expected to return, i.e., the whole set of information related to the API—set of values, how to use it, notices of recent changes, contact information, and so on—should be described and easily browsable on the Web. It will also enables machines to access the API documentaion in order to help developers build API client software.</p>
            <!-- <p>Developers will be able to code efficiently against your API, and they will make best use of the features you have provided.Your documentation should explain the architecture chosen for the API and show how to invoke each API call and what will be returned from each call.</p> -->
            <!--p>The whole set of information related to the API&mdash;how to use it, notices of recent changes, contact information, and so on&mdash;should be easily browsable on the Web.</p>
            <p>Developers should be able to obtain detailed information about each call to the API, including the parameters it takes and what it is expected to return.</p>
            <p>The API should be self-documenting as well, so that calls return helpful information about errors and usage.</p>
            <p>Recent changes to the API itself should be readily discoverable by users.</p>
            <p>API users should be able to contact the maintainers with questions, suggestions, or bug reports.</p-->
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
<p> A typical API reference provides a comprehensive list of the calls the API can handle, describing the purpose of each one, detailing the parameters it allows and what it returns, and giving one or more examples of its use. One nice trend in API documentation is to provide a form in which developers can enter specific calls for testing, to see what the API returns for their use case. There are now tools available for quickly creating this type of documentation, such as <a href="http://swagger.io/">Swagger</a>, <a href="https://www.mashery.com/api/io-docs"> io-docs</a>, <a href="https://openapis.org/">OpenApis</a>, and others. It is important to say that The API should be self-documenting as well, so that calls return helpful information about errors and usage (e.g. .API users should be able to contact the maintainers with questions, suggestions, or bug reports).</p>
<p> The quality of documentation is also related to usage and feedback from developers. Try to get constant feedback from your users about the documentation. </p>

            <!--p>A typical API reference provides a comprehensive list of the calls the API can handle, describing the purpose of each one, detailing the parameters it allows and what it returns, and giving one or more examples of its use. One nice trend in API documentation is to provide a form in which developers can enter specific calls for testing, to see what the API returns for their use case. There are now tools available for quickly creating this type of documentation, such as <a href="http://swagger.io/">Swagger</a>, <a href="https://www.mashery.com/api/io-docs">io-docs</a>, <a href="https://openapis.org/">OpenApis</a>, and others.</p-->
            <aside class="example">
<ul>
<li> OGC 'capabilities documents' provide an example of a standardized API description. Every <a href="/TR/2016/WD-sdw-bp-20160119/#dfn-wfs">WFS</a> or <a href="/TR/2016/WD-sdw-bp-20160119/#dfn-wms">WMS service</a>, for example, understands the request 'getCapabilities', and then returns an XML document giving information about the service such as the Coordinate Reference system used, the data structure schema, available map layers, and so on. </li>
<li>Use of <code>void:TechnicalFeature</code> to describe the API for a (<a href="http://www.w3.org/TR/void/#dataset">VoID</a>) Dataset (or subset); providing a set of values, terms or entities for each API parameter (<a href="http://portal.sirf.net/about-sirf">CSIRO's Spatial Identifier Reference Framework</a>). Use URI Templates [[RFC6570]] to bind API parameters to RESTful URLs. A 'short-form' of the identifier may be required for usage in the API; this may be defined as a SKOS notation. </li>
<li> Use of <a href="http://www.w3.org/TR/vocab-data-cube/#data-cubes">Data Cube</a> with Dimensions to define the data available from a predicably structured dataset - "what, where, when", and so on (ref. <a href="http://portal.sirf.net/about-sirf">CSIRO's Spatial Identifier Reference Framework</a>); each Dimension of the <a href="http://www.w3.org/TR/vocab-data-cube/#data-cubes">Data Cube</a> is bound to a parameter in the API method. The "where" Dimension of a Data Cube, if specified as <code>qb:CodedProperty</code>, may bound to a set of SpatialThings (e.g. using the property <code>qb:codeList</code>). The URI Set (the set of all SpatialThings mentioned in the <a href="http://www.w3.org/TR/vocab-data-cube/#data-cubes">Data Cube</a>) provides a 'controlled vocabulary' of locations for which 'observations' (data points) in the <a href="http://www.w3.org/TR/vocab-data-cube/#data-cubes">Data Cube</a> are available (e.g. air quality data is available at these locations). </li>
<li> A versioned API: <a href="http://wiki.openstreetmap.org/wiki/API">OpenStreetMap API </a></li>
<li> Use of HAL: 'JSON Hypertext Application Language', see <a href="https://tools.ietf.org/html/draft-kelly-json-hal-07">IETF draft</a>. </li>
<li> Use of <a href="http://swagger.io/">Swagger</a> and <a href="https://swaggerhub.com/">swaggerhub</a>; the Dutch Cadastre has published the WFS services in its national geo-portal, PDOK, as Swagger APIs on Swaggerhub, for example an API to get data about noise pollution near highways. Swagger also offers an example reference for a pet store API. </li>
<li> Packaging a coordinate transformation API for simple re-use. </li>
<li> Relating the API to its description using HTTP link headers. </li>

</ul>


            <!--p>Swagger offers an example reference for a <a href="http://petstore.swagger.io/#/">pet store API</a>.</p--></aside>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p> Check that every call enabled by your API is described in your documentation. Make sure you provide details of what parameters are required or optional and what each call returns.  </p>
            <p> Check the Time To First Successful Call (i.e. being capable of doing a successful request to the API within a few minutes will increase the chances that the developer will stick to your API).
            </p>
            <!-- <p>Check that every call enabled by your API is described in your documentation. Make sure you provide details of what parameters are required or optional and what each call returns. The quality of documentation is also related to usage and feedback from developers. Try to get constant feedback from your users about the documentation.</p> -->
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-APIDocumented">R-APIDocumented</a></p>
          </section>
            <section class="benefits">
              <p class="subhead">Benefits</p>
              <ul class="benefitsList">
                <li>Reuse</li>
                <li>Trust</li>
                <!--              <li>Comprehension</li>
                <li>Linkability</li>              <li>Discoverability</li> -->
                <!--              <li>Access</li>
                <li>Interoperability</li>              <li>Processability</li> -->
              </ul>
            </section>
        </div>
        <!-- end of Document API code BP -->
        <!-- begin of avoid breaking changes at APIs -->
        <div class="practice">
          <p><span id="avoidBreakingChangesAPI" class="practicelab">Avoid Breaking Changes to Your API</span></p>
          <p class="practicedesc">Avoid changes to your API that break client code, and communicate any changes in your API to your developers when evolution happens. </p>
          <section class="axioms">
            <p class="subhead">Why</p>
            <p>When developers implement a client for your API, they may rely on specific characteristics that you have built into it, such as the schema or the format of a response. Avoiding breaking changes in your API minimizes breakage to client code. Communicating changes when they do occur enables developers to take advantage of new features and, in the rare case of a breaking change, take action. </p>
          </section>
          <section class="outcome">
            <p class="subhead">Intended Outcome</p>
            <p>Developer code will continue to work. Developers will know of improvements you make and be able to make use of them. Breaking changes to your API will be rare, and if they occur, developers will have sufficient time and information to adapt their code. That will enable them to avoid breakage, enhancing trust.</p>
          </section>
          <section class="how">
            <p class="subhead">Possible Approach to Implementation</p>
          <p>When improving your API, focus on adding new calls or new, unrequired options rather than changing how existing calls work. Existing clients can ignore such changes and will continue functioning.</p>
            <p>If using a fully RESTful style, you should be able to avoid changes that affect developers by keeping home resource URIs constant and changing only elements that your users do not code to directly. If you need to change your data in ways that are not compatible with the extension points that you initially designed, then a completely new design is called for, and that means changes that break client code. In that case, it’s best to implement the changes as a new REST API, with a different home resource URI. </p>
          <p>If using an architectural style that does not allow you to make moderately significant changes without breaking client code, use versioning. Indicate the version in the response header. Version numbers should be reflected in your URIs or in request "accept" headers (using content negotiation). When versioning in URIs, include the version number as far to the left as possible. Keep the previous version available for developers whose code has not yet been adapted to the new version.</p>
          <aside class="example">Some examples of breaking changes to an API include:
            <ul>
              <li>Removing a call;</li>
              <li>Changing the method used to make a call;</li>
              <li>Changing the URI of a resource used in a call;</li>
              <li>Adding a required parameter for a call;</li>
              <li>Changing the data type of a parameter;</li>
              <li>Changing the name of a key in a key-value response;</li>
              <li>Changing the structure of an XML response</li>
              <li>Changing the data type of a value in a response, such as changing a string to an array;</li>
            </ul>
<p>Suppose the MyCity transit agency's API responds to a request for a certain bus's arrival time at a single station as <code>http://api.mycitytransit.example.org/arrivals/buses/53/stop/12 </code>, but the agency decides it wants to make it possible to query for a range of stops at once. Rather than change the form of the request to require a range, like <code>http://api.mycitytransit.example.org/arrivals/buses/53/stop/12-12 </code>, the agency can keep the old API call and add a new one for multiple arrivals, like <code>http://api.mycitytransit.example.org/arrivals/buses/53/stops/1-12 </code>. </p>

          </aside>
          <p>Changes to the API should be announced on your API documentation site. To notify users directly of changes, it's a good idea to create a mailing list and encourage developers to join. You can then announce changes there, and this provides a nice mechanism for feedback as well. It also allows your users to help each other.</p>
          </section>
          <section class="test">
            <p class="subhead">How to Test</p>
            <p>Release changes initially to a test version of your API before applying them to the production version. Invite developers to test their applications on the test version and provide feedback.</p>
          </section>
          <section class="ucr">
            <p class="subhead">Evidence</p>
            <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-PersistentIdentification">R-PersistentIdentification</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-APIDocumented">R-APIDocumented</a></p>
          </section>
         <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
             <li>Trust</li><li>Interoperability</li>
            <!--              <li>Comprehension</li>
            <li>Reuse</li>
           <li>Linkability</li>              <li>Discoverability</li> -->
            <!--              <li>Access</li>
                         <li>Processability</li> -->
          </ul>
        </section>
        </div>
        <!-- end of avoid breaking changes to APIs -->

      </div>
      <!-- end of Data Access APIs group -->
    </section>
    <!-- end of Data Access -->
    <!-- begin of Data Preservation -->
    <section id="dataPreservation">
      <h3>Data Preservation</h3>
      This section describes best practices related to <a href="#data_preservation">data
        preservation</a>. Albeit being a closely related topic <a href="#data_archiving">archiving</a>
      is considered out of scope for this group and therefore not covered here.

      <div class="note"> Data Preservation Best Practices are still under discussion (see <a href="https://www.w3.org/2013/dwbp/track/issues/251"> ISSUE-251 </a>). We're keen to hear comments about the following questions:
<ul>
<li> Do we need the BP "Use a trusted serialization format for preserved data dumps" or this should be covered under the BP about using standardized formats? </li>
<li> Do we need the BP "Update the status of identifiers" or this should be covered under versioning or unavailability? </li>
<li> Do we need to rewrite the BP Assess dataset coverage to make it more clear that datasets should have minimal dependencies on external entities that may not be preserved? </li>
</ul>
       </div>
      <!-- end of list of resources BP -->
      <!-- begin of assess dataset BP -->
      <div class="practice">
        <p><span id="EvaluateCoverage" class="practicelab">Assess dataset
            coverage</span></p>
        <p class="practicedesc">The coverage of a dataset should be assessed
          prior to its preservation.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>A chunk of Web data is by definition dependent on the rest of the
            global graph. This global context influences the meaning of the
            description of the resources found in the dataset. Ideally, the
            preservation of a particular dataset would involve preserving all
            its context. That is the entire Web of Data. </p>
          <p>At ingestion time an evaluation of the linkage of Web data dataset
            dump to already preserved resources is assessed. The presence of all
            the vocabularies and target resources in uses is sought in a set of
            digital archives taking care of preserving Web data. Datasets for
            which very few of the vocabularies used and/or resources pointed out
            are already preserved somewhere should be flagged as being at risk.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>Assessing dataset coverage will enable data consumers to appreciate the coverage and external dependencies of a given dataset.</p>
          <!--<p>It should be possible to appreciate the coverage and external
            dependencies of a given dataset.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>The assessment can be performed by the digital preservation
            institute or the dataset depositor. It essentially consists in
            checking whether all the resources used are either already preserved
            somewhere or provided along with the new dataset considered for
            preservation.</p>
          <aside class="example">
            <p>A dataset targetted for preservation is made of the following
              triples:</p>
            <pre class="highlight"> 
  &lt;http://data.mycity.example.com/public-transport/road/bus/route/ABtimetable&gt; 
      a gtfs:Route ;
      gtfs:color "ff0000" ;
      gtfs:shortname "10" ;
      gtfs:longName "Airport - Bullfrog" ;
      gtfs:agency &lt;http://data.mycity.example.com/transport-agency/DTA&gt; ;
      gtfs:routeType ex:three ;
      ex:usualVehicleType dbpedia:Roumaster ;
      foaf:isPrimaryTopicOf ex:Airport_Bullfrog
      .

  &lt;http://data.mycity.example.com/public-transport/road/bus/route/BFC&gt; 
      a gtfs:Route ;
      gtfs:color "ffff00" ;
      gtfs:shortname "20" ;
      gtfs:longName "Bullfrog - Furnace Creek Resort" ;
      gtfs:agency &lt;http://data.mycity.example.com/transport-agency/DTA&gt; ;
      gtfs:routeType ex:three ;
      ex:usualVehicleType dbpedia:Articulated_bus ;
      foaf:isPrimaryTopicOf ex:Bullfrog_Furnace_Creek_Resort
      .

  …
</pre>
            <p>Those triples make use of the "gtfs" vocabulary and a custom one
              defined in the testing domain name "ex". It also uses entities
              defined in "foaf", "dbpedia" and "ex". Although not formal
              standards, FOAF and GTFS [[GTFS]] are well established ontologies
              that are archived in several places on the Web (see, for instance,
              <a href="http://lov.okfn.org">the LOV repository</a>). Entities
              defined in DBpedia are also preserved through their <a href="http://mementoweb.org/depot/native/dbpedia/">Memento
                gateway</a> and archived dumps of the dataset also exist. The
              risks associated to preserving the triple making use of those
              external resource is thus minimal. A bigger concern arises from
              the usage made of resources defined in "ex" which is a namespace
              that, by design, does not exist outside of the dataset. Unless the
              data describing "ex:usualVehicleType", "ex:Airport_Bullfrog" and
              "ex:Bullfrog_Furnace_Creek_Resort" is preserved alongside those
              triples their contextual meaning will be lost. This is
              particularly critical for "ex:usualVehicleType" as without it the
              relationship between the described route and the dbpedia resources
              will be unknown to a consuming application (however obvious it may
              be to a human).</p>
            <p>Considering this assessment, a revised dataset including the
              definition of "ex:usualVehicleType" can be considered for
              preservation:</p>
            <pre class="highlight">
  &lt;http://data.mycity.example.com/public-transport/road/bus/route/AB&gt; a gtfs:Route;
      gtfs:color "ff0000" ;
      gtfs:shortname "10" ;
      gtfs:longName "Airport - Bullfrog" ;
      gtfs:agency &lt;http://data.mycity.example.com/transport-agency/DTA&gt; ;
      gtfs:routeType ex:three ;
      ex:usualVehicleType dbpedia:Roumaster ;
      foaf:isPrimaryTopicOf ex:Airport_Bullfrog
      .

  &lt;http://data.mycity.example.com/public-transport/road/bus/route/BFC&gt; 
      a gtfs:Route;
      gtfs:color "ffff00";
      gtfs:shortname "20";
      gtfs:longName "Bullfrog - Furnace Creek Resort";
      gtfs:agency &lt;http://data.mycity.example.com/transport-agency/DTA&gt;;
      gtfs:routeType ex:three;
      ex:usualVehicleType dbpedia:Articulated_bus;
      foaf:isPrimaryTopicOf ex:Bullfrog_Furnace_Creek_Resort
      .

  …

  # Custom vocabulary element
  ex:usualVehicleType 
      a rdf:Property ;
      rdfs:subPropertyOf gtfs:routeType ;
      rdfs:range gtfs:Bus.
</pre>
            <p>This second, more complete, dataset is better suited for
              preservation as it is more self-describing and only makes use of
              external entities whose preservation is trusted.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Datasets making references to portions of the Web of Data which are
            not preserved should receive a lower score than those using common
            resources.</p>
          <div class="note">To review this test</div>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-VocabReference">R-VocabReference</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>-->
            <li>Trust</li>
            <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li> -->
          </ul>
        </section>
      </div>
      <!-- end of assess dataset BP -->
      <!-- begin of serialisation BP -->
      <div class="practice">
        <p><span id="Serialisation" class="practicelab">Use a trusted
            serialisation format for preserved data dumps</span></p>
        <p class="practicedesc">Data depositors willing to send a data dump for
          long term preservation must use a well established serialisation.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Web data follows an abtract data model that can be expressed in
            different ways (RDF/XML, JSON-LD, ...). Using a well-established
            serialisation of this data increases its chances of reuse. </p>
          <p>Institutes, such as national archives, that are engaged in digital preservation are tasked with monitoring
            file formats regularly for potential risk of obsolescence. Datasets which have been acquired in some
            format some years ago may have to be converted into another format
            in order to still be usable with more modern software (see
            [[ROSENTHAL]]). This task can be made more challenging, or even
            impossible, if non-standard serialisation formats are used by data
            depositors.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>Trusted serialisation formats will enable machines to process a datasets even if the original software that was used to create it is no longer available or supported.</p>
          <!--<p>It should be possible to read and load the dataset into a computer for manipulation
            even if the original software that was used to create it is no longer available or supported.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Give preference to non-binary Web data serialisation formats that are available as open
            standards. For instance those provided by the W3C [[FORMATS]]. </p>
          <aside class="example">
            <p>Those triples are serialised as RDf using the Turtle W3C recommendation.
              It is a text-based format which is supported by the majority of
              software able to process Web data. This format can thus be trusted
              for preservation.</p>
            <pre class="highlight"> # Definition of a person
 ex:bob a ex:Staff;
     foaf:basedNear dbpedia:Cardiff;
     foaf:knows ex:john.
                 </pre>
            <p>A custom-made serialisation of the same data such as the comma-delimited example that follows
              is an example of an inappropriate serialisation of RDF and is neither hrlpful nor good practice for preserving the dataset.</p>
            <pre class="highlight">ex:bob,a,ex:staff;###,foaf:basedNear,dbpedia:Cardiff;###,foaf:knows,ex:john.
                 </pre>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <!--<p>Try to open the data dump with different
            software.</p> -->
          <p>Check that the dataset can be read by a standard text editor. Try to dereference the HTTP URIs present in the data dump using for example [[cURL]], confirming that the Content-Type header matches the format you expect to get.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatStandardized">R-FormatStandardized</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Long-term availability of accessible data</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>              <li>Trust</li>              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of serialisation BP -->
      <!-- begin of resource status BP -->
      <div class="practice">
        <p><span id="ResourceStatus" class="practicelab">Update the status of
            identifiers</span></p>
        <p class="practicedesc">Preserved resources should be linked through URIs with their
          "live" counterparts.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>URI dereferencing is a primary interface to data on the Web.
            Linking preserved datasets with the original URI informs the data
            consumer (which might be a computer programme) that there are other, more recent, versions and facilitates determining the status of these resources.</p>
          <p>During its life cycle a dataset may undergo several modifications resulting in multiple versions.
            Although URIs assigned to things are not expected to change, the
            description of these resource will evolve over time.
            <!--There are also some new IRIs that will be put into use, some
              other that will become deprecated, and some that will get deleted. -->
            During this evolution, several snapshots could be made available for
            preservation and accessed as earlier versions of the current dataset.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>A link is maintained between the URI of a resource, the most
            up-to-date description available for it, and preserved descriptions.
            If the dataset resource does not exist any more then the description should say
            so and refer to the last preserved description that was available.</p>
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>There are a variety of HTTP status codes that could be put into use
            to relate the URI with its preserved description. In particular,
            200, 410 and 303 can be used for different scenarios:</p>
          <ul>
            <li>200 =&gt; there is a new description which contains pointers to the
              archived description</li>
            <!--              <li>404 =&gt; the resource just died, the URI consumer has to go
                find an archive to look for it</li> -->
            <li>410 =&gt; the resource is no longer available but it has been
              removed under a controlled process cf. 404 which simply states
              that something is not available.</li>
            <li>303 =&gt; the resource identified by this URI is no longer
              served here but there is a preserved description at a different
              location.</li>
            <!--              <li>209 =&gt; this resource does not exist any more but we have
                some information about it. The description could include a list                of locations having different preserved descriptions over                different times.</li> -->
          </ul>
          <p>In addition to the status codes, HTTP Link headers can also be used
            to relate resources to their preserved descriptions.</p>
            <div class="note"> The following example needs to be updated to use the URI http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05. </div>
          <aside class="example">
            <p>One approach with a link header is to use the Memento protocol to
              give a link to a timegate providing access to the preserved
              descriptions of the resource:</p>
            <pre class="highlight">curl -I http://example.org/bus-stops-001

HTTP/1.1 200 OK
Memento-Datetime: Sun, 05 April 2015 00:00:00 GMT
Link: http://example.org/bus-stops; rel=“original”, http://example.org/timegate/dataset; rel=“timegate”
            </pre>
            <p>Using HTTP status code the data consumer can be redirected to the
              most recent description of the entity. In the following example a
              request for the resource "http://example.org/bus-stops-001" is
              first redirected to the description
              "http://example.org/data/bus-stops-001" which, as it has been
              preserved and flagged as invalid, redirects the client to the
              newer description "http://example.org/newdata/bus-stops-001"</p>
            <pre class="highlight">curl -L -I http://example.org/bus-stops-001

HTTP/1.1 303 See Other
Location: http://example.org/data/bus-stops-001
Link: http://example.org/newdata/bus-stops-001, rel="new"

HTTP/1.1 303 See Other
Location: http://example.org/newdata/bus-stops-001
Link: http://example.org/data/bus-stops-001, rel="previous"

HTTP/1.1 200 Ok
           </pre>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Check that dereferencing the URI of a preserved dataset returns
            information about its current status and availability.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>:<a href="http://www.w3.org/TR/dwbp-ucr/#R-AccessLevel">R-AccessLevel</a>,
            <a href="http://www.w3.org/TR/dwbp-ucr/#R-PersistentIdentification">
              R-PersistentIdentification</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>-->
            <li>Trust</li>
            <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
          </ul>
        </section>
        <!-- end of resource status BP -->
      </div>
    </section>
    <!-- end of Data Preservation -->
    <!-- begin Feedback -->
    <section id="feedbacksection">
      <h3>Feedback</h3>
      <p>Publishing data on the Web enables data sharing on a large scale,
        providing data access to a wide range of audiences with different levels
        of expertise. Data publishers want to ensure that the data published is
        meeting the data consumer needs and user feedback is crucial. Feedback
        has benefits for both data publishers and data consumers, helping data
        publishers to improve the integrity of their published data, as well as
        to encourage the publication of new data. Feedback allows data consumers
        to have a voice describing usage experiences (e.g. applications using
        data), preferences and needs. When possible, feedback should also be
        publicly available for other data consumers to examine. Making feedback
        publicly available allows users to become aware of other data consumers,
        supports a collaborative environment, and allows user community
        experiences, concerns or questions are currently being addressed.</p>
      <p>From a user interface perspective there are different ways to gather
        feedback from data consumers, including site registration, contact
        forms, quality ratings selection, surveys and comment boxes for
        blogging. From a machine perspective the data publisher can also record
        metrics on data usage or information about specific applications
        consumers are currently relying upon. Feedback such as this establishes
        a line of communication channel between data publishers and data
        consumers. In order to quantify and analyze usage feedback, it should be
        recorded in a machine-readable format. Publicly
        available feedback should be displayed in a human-readable form through
        the user interface. </p>
      <p> This section provides some BP to be followed by data publishers in
        order to enable data consumers to provide feedback about the consumed
        data. This feedback can be for humans or machines. </p>
      <!-- begin of BP Gather Feedback -->
      <div class="practice">
        <p><span id="GatherFeedback" class="practicelab">Gather feedback from
            data consumers </span></p>
        <p class="practicedesc"> Data publishers should provide a means for
          consumers to offer feedback.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Providing feedback contributes to improving the quality of
            published data, may encourage publication of new data, helps data
            publishers understand data consumers needs better and, when feedback
            is made publicly available, enhances the consumers' collaborative
            experience.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Data consumers will be able to provide feedback and ratings about datasets and distributions.  </p>

          <!--p>It should be possible for data consumers to provide feedback and
            rate data in both human and machine-readable formats. The feedback
            should be Web accessible and it should provide a URL reference to
            the corresponding dataset.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Provide data consumers with one or more feedback mechanisms
            including, but not limited to: a registration form, contact form,
            point and click data quality rating buttons, or a comment box for
            blogging.</p>
          <p>Collect feedback in machine-readable formats to represent the
            feedback and use a vocabulary to capture the semantics of the
            feedback information.
            <!-- The definition of a Data Usage Vocabulary is
              included in the activity of the DWBP group in order to support in              the implementation of this best practice. --></p>
          <aside class="example">
            <p>to be done </p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <ul>
            <li>Demonstrate how feedback can be collected from data consumers. </li>
            <li>Verify that the feedback is persistently stored. If the feedback
              is made publicly available verify that a URL links back to the
              published data being referenced.</li>
            <li>Check that the feedback format conforms to a known
              machine-readable format specification in current use among
              anticipated data users. </li>
          </ul>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UsageFeedback">R-UsageFeedback</a>,
            <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">R-QualityOpinions</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <li>Comprehension</li>
            <!--              <li>Linkability</li>
              <li>Discoverability</li>-->
            <li>Trust</li>
            <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of BP Gather Feedback -->
      <!-- begin of BP Information about Feedback -->
      <div class="practice">
        <p><span id="FeedbackInformation" class="practicelab">Make feedback available</span></p>
        <p class="practicedesc"> Feedback  should be available for both human users and computer applications.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Making feedback about datasets and distributions publicly available allows users to become aware of other data consumers, supports a collaborative environment, and allows user community experiences, concerns or questions are currently being addressed. Providing feedback in a machine-readable format allows computer applications to automatically collect and process feedback about datasets. </p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Making feedback about a dataset or distribution publicly available will enable the sharing of feedback given by different data consumers.  
</p>

          <!--<p>It should be possible for humans to have access to feedback on a dataset or distribution given by one or more data consumers. 
          </p>
          <p>It should be possible for machines to automatically process feedback  about a dataset or distribution.</p> -->
        </section>
        <section class="how">
          <p class="subhead">Possible Approach to Implementation</p>
          <p>Feedback can be availabe  as part of an HTML Web page, but it can also be provided in a machine-readable format according to the vocabulary to describe dataset usage [[DUV]].</p>
          <aside class="example">
            <pre class="highlight">
  :bus-stops-2015-05-05
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dcat:keyword "transport","mobility","bus" ;
      dct:issued "2015-05-05"^^xsd:date ;
      dcat:contactPoint &lt;http://data.mycity.example.com/public-transport/contact>&gt; ;
      dct:temporal &lt;http://reference.data.gov.uk/id/year/2015&gt; ;
      dct:spatial &lt;http://www.geonames.org/3399415&gt; ;
      dct:publisher :transport-agency-mycity ;
      dct:accrualPeriodicity &lt;http://purl.org/linked-data/sdmx/2009/code#freq-A&gt; ;
      dcat:theme :mobility ;
      dcat:distribution :bus-stops-2015-05-05.csv ;
      .

  :bus-stops-2015-05-05.csv
      a dcat:Distribution ;
      dct:title "CSV distribution of bus-stops-2015-05-05 dataset" ; 
      dct:description "CSV distribution of the bus stops dataset of MyCity" ;
      dcat:mediaType "text/csv" ;
      .

  :comment1Content a cnt:ContentAsText ;
      cnt:chars "This dataset is missing stop 3" ; 
      .

  :comment1
      a duv:UserFeedback ;
      oa:hasBody comment1Content ;
      oa:hasTarget :bus-stops-2015-05-05 ;
      dct:creator :localresident ;
      .

  :comment2Content a cnt:ContentAsText ;
      cnt:chars "Are tab delimited formats also available?" ;
      .

  :comment2
      a duv:UserFeedback ;
      oa:hasTarget :bus-stops-2015-05-05.csv ;
      oa:hasBody comment2Content ;
      dct:creator :localresident ;
      .

  :localresident
      a foaf:Person ;
      foaf:Name "Alan Law" ;
      .</pre>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to Test</p>
          <p>Check that the metadata for the dataset itself includes feedback information about the dataset in a human-redable format.</p>
          <p>Check if a computer application can automatically process feedback information about the dataset.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements</span>: <a href="http://www.w3.org/TR/dwbp-ucr/#R-UsageFeedback">R-UsageFeedback</a>,
            <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">R-QualityOpinions</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <!--              <li>Comprehension</li>
              <li>Linkability</li>              <li>Discoverability</li>-->
            <li>Trust</li>
            <!--              <li>Access</li>
              <li>Interoperability</li>              <li>Processability</li>-->
          </ul>
        </section>
      </div>
      <!-- end of BP Gather Feedback -->
    </section>
    <!-- end Feedback -->
    <!-- begin enrichment -->
    <section id="enrichment">
      <h3>Data Enrichment</h3>
      <p>Data enrichment refers to a set of processes that can be used to
        enhance, refine or otherwise improve raw or previously processed data.
        This idea and other similar concepts contribute to making data a
        valuable asset for almost any modern business or enterprise.</p>
      <p>This section provides some advice to be followed by data publishers in
        order to enrich data.</p>
      <!-- begin of BP Enrich data -->
      <div class="practice">
        <p><span id="EnrichData" class="practicelab">Enrich data by generating
            new data</span></p>
        <p class="practicedesc">Enrich your data by generating new data from the raw data when doing so will enhance its value.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Enrichment can greatly enhance processability, particularly for unstructured data. Missing values can be filled in, and new attributes and measures can be added. Publishing more complete datasets enhances trust. Deriving additional values that are of general utility saves users time and encourages more kinds of reuse. There are many intelligent techniques that can be used to enrich data, making the dataset an even more valuable asset.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>A dataset that has missing values should be enhanced if possible to fill in those values. Additional relevant measures or attributes should be added if they enhance utility. Unstructured data can be given structure in this way as well.</p>
          <p>Because inference-based enrichment may introduce errors into the data, values generated by such techniques should be labeled as such, and it should be possible to retrieve any original values replaced by enrichment.</p>
          <p>Whenever licensing permits, the code used to enrich the data should be made available along with the dataset. Sharing such code is particularly important for scientific data. </p>
        </section>
        <section class="how">
          <p class="subhead"> Possible Approaches to Implementation</p>
          <p> Machine learning can be readily applied to the enrichment of data. Methods include those focused on data categorization, disambiguation, entity recognition, sentiment analysis, and topification, among others. After new data is extracted, it can be provided as part of any open data format.</p>
          <p>New data values may be derivable as simply as performing a mathematical calculation across existing columns. Other examples include visual inspection to identify features in spatial data and cross-reference to external databases for demographic information. </p>
          <aside class="example">
            <p>1. The MyCity transport agency has street addresses for each of its transit stops. It wants to make it easier for consumers of its data to combine the data with maps, so it adds latitude and longitude information for each stop by utilizing a geographic database.</p>
            <p>2. The transit agency has a large collection of email correspondence from transit riders. Some of the correspondence is complementary, some is complaints, and some is requesting information. The agency conducts a combination of sentiment analysis and categorization to extract metadata for each of the messages, such as transit mode, route number, and rider positivity, to create a semistructured dataset.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Look for missing values in the dataset or additional fields likely to be needed by others. Check that any data added by inferential enrichment techniques is identified as such and that any replaced data is still available. Check that code used to enrich the data is available. Check whether the metadata being extracted is in accordance with human knowledge and readable by humans.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements:</span> <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataEnrichment">R-DataEnrichment</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-FormatMachineRead">R-FormatMachineRead</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-ProvAvailable">R-ProvAvailable</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <li>Comprehension</li>
            <!--              <li>Linkability</li>
              <li>Discoverability</li>                           <li>Access</li>              <li>Interoperability</li>-->
            <li>Trust</li> <li>Processability</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Enrich Data -->
      <!-- begin of BP Complementary Presentations -->
      <div class="practice">
        <p><span id="ProvideComplementaryPresentations" class="practicelab">Provide Complementary Presentations</span></p>
        <p class="practicedesc">Enrich data by also presenting it in complementary, immediately informative ways, such as visualizations, tables, Web applications, or summaries. </p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Data published online is meant to inform others about its subject. But only posting datasets for download or API access puts the burden on consumers to interpret it. The Web offers unparalleled opportunities for presenting data in ways that let users learn and explore without having to create their own tools.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p> Complementary data presentations will enable human consumers to have immediate insight into the data by presenting it in ways that are readily understood. </p>
          <!--p>Besides making datasets available for download, processing, and reuse, publishers should give human consumers immediate insight into the data by presenting it in ways that are readily understood. Data consumers should not have to create their own tools to understand the meaning of the data.</p-->
        </section>
        <section class="how">
          <p class="subhead"> Possible Approaches to Implementation</p>
          <p> One very simple way to provide immediate insight is to publish an analytical summary in an HTML page. Including summative data in graphs or tables can help users scan the summary and quickly understand the meaning of the data.</p>
          <p>If you have the means to create interactive visualizations or Web applications that use the data, you can give consumers of your data greater ability to understand it and discover patterns in it. These approaches also demonstrate its suitability for processing and encourage reuse.</p>
          <aside class="example">
            <p>The MyCity transit agency publishes detailed data about all its transit lines through an API, but it also has many users who are not Web developers and who want to know how to use the system to move about the city. The transit agency could build a Web application that allows users to enter a departure address and a destination and receive step-by-step directions for making their journey via public transit. </p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Check that the dataset is accompanied by some additional interpretive content that can be perceived without downloading the data or invoking an API.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements:</span> <a href="http://www.w3.org/TR/dwbp-ucr/#R-DataEnrichment">R-DataEnrichment</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
            <li>Comprehension</li><li>Access</li>
              <!--                                                   <li>Interoperability</li>
            <li>Linkability</li> <li>Processability</li>-->
            <li>Trust</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Complementary Presentations -->
    </section>
    <!-- end Enrichment -->
    <!-- begin Re-use -->
    <section id="Reuse">
      <h3>Data Usage/Data Reuse</h3>
      <div class="note"> We're keen for comments about the title of this section. Which one is more suitable: Data Usage or Data Reuse? <a href="https://www.w3.org/2013/dwbp/track/issues/252"> ISSUE-252 </a></div>
      <p>Reusing data is another way of publishing data. It can take the form of combining existing data with other datasets, creating Web applications or visualizations, or repackaging the data in a new form, such as a translation. Data reusers have some responsibilities that are unique to that form of publishing on the Web. This section provides advice to be followed when reusing data. </p>
      <!-- begin of BP Provide Feedback -->
      <div class="practice">
        <p><span id="ProvideFeedbackToPublisher" class="practicelab">Provide Feedback to the Original Publisher</span></p>
        <p class="practicedesc">When using data published by others, let them know that you are reusing their data. If you find an error or have suggestions or compliments, let them know.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Publishers generally want to know whether the data they publish has been useful. Moreover, they may be required to report usage statistics in order to allocate resources to data publishing activities. Reporting your usage helps them justify putting effort toward data releases. Providing feedback repays the publishers for their efforts by directly helping them to improve their dataset for future users.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>Better communication will make it easier for original publishers to determine how the data they post is being used, which in turn helps them justify publishing the data. Publishers will also be made aware of steps they can take to improve their data. This leads to more and better data for everyone.</p>
        </section>
        <section class="how">
          <p class="subhead"> Possible Approach to Implementation</p>
          <p>When you begin using a dataset in a new product, make a note of the publisher’s contact information, the URI of the dataset you used, and the date on which you contacted them. This can be done in comments within your code where the dataset is used. Follow the publisher’s preferred route to provide feedback. If they do not provide a route, look for contact information for the Web site hosting the data.</p>
          <aside class="example">
            <pre># Calling the MyCity transit API, http://api.mycitytransit.example.org/docs/
# Published by MyCity Transit Agency,
# notified of our reuse by email to opendata@mycitytransit.example.org
# by Newton Calegari on 3/24/2016.</pre>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Check that you have a record of at least one communication informing the publisher of your use of the data.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements:</span> <a href="http://www.w3.org/TR/dwbp-ucr/#R-TrackDataUsages">R-TrackDataUsages</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-UsageFeedback">R-UsageFeedback</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-QualityOpinions">R-QualityOpinions</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
             <!--   <li>Comprehension</li><li>Access</li>   <li>Discoverability</li>
            <li>Linkability</li> <li>Processability</li>-->
            <li>Interoperability</li> <li>Trust</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Provide Feedback -->

      <!-- begin of BP Follow Licensing -->
      <div class="practice">
        <p><span id="FollowLicensingTerms" class="practicelab">Follow Licensing Terms</span></p>
        <p class="practicedesc">Find and follow the licensing requirements from the original publisher of the dataset.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Licensing provides a legal framework for using someone else’s work product. By adhering to the original publisher’s requirements, you keep the relationship between yourself and the publisher friendly. You don’t need to worry about legal action from the original publisher if you are following their wishes. Understanding the initial license will help you determine what license to select for your reuse.</p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>Data publishers will be able to trust that their work is being reused in accordance with their licensing requirements, which will make them more likely to continue to publish data. Reusers of data will themselves be able to properly license their derivative works.</p>
        </section>
        <section class="how">
          <p class="subhead"> Possible Approach to Implementation</p>
          <p>Read the original license and adhere to its requirements. If the license calls for specific licensing of derivative works, choose your license to be compatible with that requirement. If no license is given, contact the original publisher and ask what the license is.</p>
          <aside class="example">
            <p>If a dataset you are reusing is licensed under the Creative Commons Attribution 3.0 License, you will need to meet the terms specified in that <a href="https://creativecommons.org/licenses/by/3.0/us/legalcode">license agreement</a>.</p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Read through the original license and check that your use of the data does not violate any of the terms.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements:</span> <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseAvailable">R-LicenseAvailable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-LicenseLiability">R-LicenseLiability</a>, </p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
             <!--   <li>Comprehension</li><li>Access</li>   <li>Discoverability</li>
            <li>Linkability</li> <li>Processability</li><li>Interoperability</li> -->
            <li>Trust</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Follow Licensing -->

      <!-- begin of BP Cite Original-->
      <div class="practice">
        <p><span id="CiteOriginalPublication" class="practicelab">Cite the Original Publication</span></p>
        <p class="practicedesc">Indicate the source of your data in the metadata for your reuse of the data. If you provide a user interface, include the citation visibly in the interface.</p>
        <section class="axioms">
          <p class="subhead">Why</p>
          <p>Data is only useful when it is trustworthy. Identifying the source is a major indicator of trustworthiness in two ways: first, the user can judge the trustworthiness of the data from the reputation of the source, and second, citing the source suggests that you yourself are trustworthy as a republisher. In addition to informing the end user, citing helps publishers by crediting their work. Publishers who make data available on the Web deserve acknowledgment and are more likely to continue to share data if they find they are credited. Citation also maintains provenance and helps still others to work with the data. </p>
        </section>
        <section class="outcome">
          <p class="subhead">Intended Outcome</p>
          <p>End users should be able to assess the trustworthiness of the data they see, and original publishers should be recognized for their efforts. The chain of provenance for data on the Web should be traceable back to its original publisher.</p>
        </section>
        <section class="how">
          <p class="subhead"> Possible Approach to Implementation</p>
          <p>You can use the Dataset Usage Vocabulary to cite the original publication of the data in metadata.</p>
          <aside class="example">
            <!-- <pre>foaf:givenname "E"^^xsd:string;
foaf:family_name "Costello"^^xsd:string;
foaf:title "Mayor"^^xsd:string .

ex:timetable-001 a dcat:Dataset ;
        dct:title  "Bus timetable of MyCity"^^xsd:string;
        prism:doi "10.3456/4567.21"^^xsd:string ;
        dcat:landingPage <https://example.org/mycity/trans/timetable-001>; 
        pav:version "series-1.2"^^xsd:string;
        dct:issued "2015-MAY-05"^^xsd:date;
        dct:creator ex:author .
</pre> -->

<!--<pre class="highlight">

  :bus-stops-2015-05-05 
      a dcat:Dataset ;
      dct:title "Bus stops of MyCity" ;
      dct:issued "2015-05-05"^^xsd:date ;
      prism:doi "10.3456/4567.21"^^xsd:string ;
      dct:creator :john ;
      owl:versionInfo "1.0" ; 
      pav:version "1.0" ;
      . 

  ex:bus-stops-memorandum
      a biro:BibliographicReference ;
      a fabio:Policy  ;
      dct:bibliographicCitation
      "Costello, E. Mayor (2016). City Bus Stops Memorandum
      January, 2016. DOI:0.3456/4567.21"^^xsd:string ;
      biro:references :bus-stops-2015-05-05 ;
      .
      </pre> -->

            <p>You can cite the original source in a user interface by providing bibliographic text and a working link.</p>
            <!--p>Data source: Costello, E. Mayor (2016)  "City Bus Stops Memorandum". January, 2016. References dataset: http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops-2015-05-05.</p-->

            <p> Data source: Costello, E. "Bus timetable of MyCity" (series 1.2). MyCity. May 5, 2015. Available from: http://data.mycity.example.com/public-transport/road/bus/dataset/bus-stops. </p>
          </aside>
        </section>
        <section class="test">
          <p class="subhead">How to test</p>
          <p>Check that the original source of any reused data is cited in the metadata provided. Check that a human-readable citation is readily visible in any user interface.</p>
        </section>
        <section class="ucr">
          <p class="subhead">Evidence</p>
          <p><span>Relevant requirements:</span> <a href="http://www.w3.org/TR/dwbp-ucr/#R-Citable">R-Citable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-ProvAvailable">R-ProvAvailable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-MetadataAvailable">R-MetadataAvailable</a>, <a href="http://www.w3.org/TR/dwbp-ucr/#R-TrackDataUsages">R-TrackDataUsages</a></p>
        </section>
        <section class="benefits">
          <p class="subhead">Benefits</p>
          <ul class="benefitsList">
            <li>Reuse</li>
             <!--   <li>Comprehension</li><li>Access</li>
            <li>Linkability</li> <li>Processability</li> <li>Interoperability</li>-->
           <li>Discoverability</li> <li>Trust</li>
          </ul>
        </section>
      </div>
      <!-- end of BP Cite Original -->


    </section>
    <!-- end Re-use -->

  <!-- end best practices -->
  </section>
  <!--  <section id="conclusions">
      <h2>Conclusions</h2>
    </section> -->
    <section id="glossary" class="informative">
      <h2>Glossary</h2>
      <dl>
        <dt><dfn id="dataset">Dataset</dfn></dt>
        <dd>
          <p>A dataset is defined as a collection of data, published or curated
            by a single agent, and available for access or download in one or
            more formats. A dataset does not have to be available as a
            downloadable file.</p>
          <p>From: <a href="http://www.w3.org/TR/vocab-dcat/">Data Catalog
              Vocabulary (DCAT)</a></p>
        </dd>
        <dt><dfn id="citation">Citation</dfn></dt>
        <dd>
          <p>A Citation may be either direct and explicit (as in the reference
            list of a journal article), indirect (e.g. a citation to a more
            recent paper by the same research group on the same topic), or
            implicit (e.g. as in artistic quotations or parodies, or in cases of
            plagiarism).</p>
          <p>From: <a href="http://www.essepuntato.it/lode/http://purl.org/spar/cito">CiTO</a></p>
        </dd>
        <dt><dfn id="data_consumer">Data consumer</dfn></dt>
        <dd>
          <p>For the purposes of this WG, a Data Consumer is a person or group
            accessing, using, and potentially performing post-processing steps
            on data.</p>
          <p>From: Strong, Diane M., Yang W. Lee, and Richard Y. Wang. "Data
            quality in context." Communications of the ACM 40.5 (1997): 103-110.
          </p>
        </dd>
        <dt><dfn id="data_format">Data format</dfn></dt>
        <dd>
          <p>Data Format defined as a specific convention for data
            representation i.e. the way that information is encoded and stored
            for use in a computer system, possibly constrained by a formal data
            type or set of standards."</p>
          <p>From: <a href="http://guide.dhcuration.org/representation/">DH
              Curation Guide</a></p>
        </dd>
        <dt><dfn id="data_producer">Data producer</dfn></dt>
        <dd>
          <p>Data Producer is a person or group responsible for generating and
            maintaining data.</p>
          <p>From: Strong, Diane M., Yang W. Lee, and Richard Y. Wang. "Data
            quality in context." Communications of the ACM 40.5 (1997): 103-110.
          </p>
        </dd>
        <dt><dfn id="data_representation">Data representation</dfn></dt>
        <dd>
          <p>Data representation is any convention for the arrangement of
            symbols in such a way as to enable information to be encoded by a
            data producer and later decoded by data consumers."&gt;Data
            representation</p>
          <p>From: <a href="http://guide.dhcuration.org/representation/">DH
              Curation Guide</a></p>
        </dd>
        <dt><dfn id="distribution">Distribution</dfn></dt>
        <dd>
          <p> A distribution represents a specific available form of a dataset.
            Each dataset might be available in different forms, these forms
            might represent different formats of the dataset or different
            endpoints. Examples of distributions include a downloadable CSV
            file, an API or an RSS feed</p>
          <p><a href="http://www.w3.org/TR/vocab-dcat/">Data Catalog Vocabulary
              (DCAT)</a></p>
        </dd>
        <dt><dfn id="feedback">Feedback</dfn></dt>
        <dd>
          <p>A feedback forum is used to collect messages posted by consumers
            about a particular topic. Messages can include replies to other
            consumers. Datetime stamps are associated with each message and the
            messages can be associated with a person or submitted anonymously.</p>
          <p><a href="http://rdfs.org/sioc/spec/#sec-modules-types">SIOC</a>,
            (2) <a href="http://www.w3.org/TR/annotation-model/#creation-reason">Annotation#Motivation</a></p>
          <p>To better understand why an annotation [[Annotation-Model]] was created, a
          <a href="http://www.w3.org/TR/skos-reference/">SKOS</a> Concept Scheme is used to
            show inter-related annotations between communities with more
            meaningful distinctions than a simple class/subclass tree.</p>
        </dd>
        <dt><dfn id="data_preservation">Data preservation</dfn></dt>
        <dd>
          <p> Data Preservation is defined by <a href="http://www.alliancepermanentaccess.org/index.php/consultancy/dpglossary/#Preservation">APA</a>
            as "The processes and operations in ensuring the technical and
            intellectual survival of objects through time". This is part of a
            data management plan <a href="http://guide.dhcuration.org/preservation/">focusing
              on preservation planning and meta-data</a>. Whether it is
            worthwhile to put effort into preservation depends on the (future)
            value of the data, the resources available and the opinion of the
            stakeholders (= designated community). </p>
        </dd>
        <dt><dfn id="data_archiving">Data archiving</dfn></dt>
        <dd>
          <p>Data Archiving is the set of practices around the storage and
            monitoring of the state of digital material over the years. </p>
          <p>These tasks are the responsibility of a Trusted Digital Repository
            (TDR), also sometimes referred to as <a href="http://tools.ietf.org/html/rfc4810">Long-Term
              Archive Service (LTA)</a>. Often such services follow the <a href="https://en.wikipedia.org/wiki/Open_Archival_Information_System">Open
              Archival Information System</a> which defines the archival process
            in terms of ingest, monitoring and reuse of data.</p>
        </dd>
        <dt><dfn id="data_provenance">Data Provenance </dfn></dt>
        <dd>
          <p> Provenance originates from the French term "provenir" (to come
            from), which is used to describe the curation process of artwork as
            art is passed from owner to owner. Data provenance, in a similar
            way, is metadata that allows data providers to pass details about
            the data history to data users.</p>
        </dd>
        <dt><dfn id="data_quality">Data Quality </dfn></dt>
        <dd>
          <p> Data quality is commonly defined as “fitness for use” for a
            specific application or use case.</p>
        </dd>
        <dt><dfn id="file_format">File format</dfn></dt>
        <dd>
          <p> File Format is a standard way that information is encoded for
            storage in a computer file. It specifies how bits are used to encode
            information in a digital storage medium. File formats may be either
            proprietary or free and may be either unpublished or open.</p>
          <p>Examples of file formats: <a href="https://en.wikipedia.org/wiki/Text_file">txt</a>,
            <a href="https://en.wikipedia.org/wiki/Portable_Document_Format">pdf</a>,
            <a href="https://en.wikipedia.org/wiki/Postscript">ps</a>,<a href="https://en.wikipedia.org/wiki/Audio_Video_Interleave">avi</a>,
            <a href="https://en.wikipedia.org/wiki/GIF">gif</a> or <a href="https://en.wikipedia.org/wiki/JPEG">jpg</a>
          </p>
        </dd>
        <dt><dfn id="license">License </dfn></dt>
        <dd>
          <p> A license is a legal document giving official permission to do
            something with the data with which it is associated.</p>
          <p>From: <a href="http://dublincore.org/documents/2010/10/11/dcmi-terms/">
              DC-TERMS</a></p>
        </dd>
        <dt><dfn id="locale_parameter">Locale</dfn></dt>
        <dd>
          <p> A locale is a set of parameters that defines specific data
            aspects, such as language and formatting used for numeric values and
            dates.</p>
        </dd>
        <dt><dfn id="machine_readable">Machine Readable Data</dfn></dt>
        <dd>
          <p> Machine Readable Data are data formats that may be readily parsed
            by computer programs without access to proprietary libraries. For
            example <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV</a>
            and <a href="http://www.w3.org/TR/2014/NOTE-rdf11-primer-20140624/#section-graph-syntax">RDF
              turtle family for graphs</a> are machine readable, but <a href="http://www.data.gov/developers/blog/primer-machine-readability-online-documents-and-data">PDF</a>
            and <a href="https://en.wikipedia.org/wiki/JPEG">JPEG</a> are not.
          </p>
          <p> From: <a href="http://www.w3.org/TR/ld-glossary/#vocabulary">Linked
              Data Glossary</a> </p>
        </dd>
        <dt><dfn id="sensitive_data">Sensitive Data </dfn></dt>
        <dd>
          <p> Sensitive data is any designated data or metadata that is used in
            limited ways and/or intended for limited audiences. Sensitive data
            may include personal data, corporate or government data, and
            mishandling of published sensitive data may lead to damages to
            individuals or organizations.</p>
        </dd>
        <dt><dfn id="vocabulary">Vocabulary</dfn></dt>
        <dd>
          <p>Vocabulary is A collection of "terms" for a particular purpose.
            Vocabularies can range from simple such as the widely used <a href="http://www.w3.org/TR/rdf-schema/">RDF
              Schema</a>, <a href="http://xmlns.com/foaf/spec/">Foaf</a> and <a href="https://en.wikipedia.org/wiki/Dublin_Core#Dublin_Core_Metadata_Element_Set_Version_1.1">Dublin
              Core Metadata Element Set</a> to complex vocabularies with
            thousands of terms, such as those used in healthcare to describe
            symptoms, diseases and treatments. Vocabularies play a very
            important role in Linked Data, specifically to help with data
            integration. The use of this term overlaps with Ontology.</p>
          <p> From: <a href="http://www.w3.org/TR/ld-glossary/#vocabulary">Linked
              Data Glossary</a> </p>
        </dd>
        <dt><dfn id="structured_data">Structured data</dfn></dt>
        <dd>
          <p> Structured Data refers to data that conforms to a fixed schema.
            Relational databases and spreadsheets are examples of structured
            data.</p>
        </dd>
      </dl>
    </section>
    <section id="challenges" class="informative">
      <h2>Data on the Web Challenges</h2>
      <p>The following diagram summarizes some of the main
        challenges faced when publishing or consuming data on the Web. These
        challenges were identified from the <abbr title="Data on the Web Best Practices">DWBP</abbr>
        Use Cases and Requirements [[UCR]] and, as presented in the diagram, is
        addressed by one or more best practices.</p>
        <div class="note">The diagram will de redesigned to be more legible.</div>
        <embed type="image/svg+xml" src="challenges.svg" style="width:100%" id="challengesSVG">
    </section>
    <section id="BP_Benefits" class="informative">
      <h2>Best Practices Benefits</h2>
      <p>The list below describes the main benefits of applying the DWBP. Each benefit represents an improvement in the way how datasets are available on the Web.</p>
      <ul>
        <li>Comprehension: humans will have a better understanding about the
          data structure, the data meaning, the metadata and the nature of the
          dataset. </li>
        <li>Processability: machines will be able to automatically process and
          manipulate the data within a dataset.</li>
        <li>Discoverability machines will be able to automatically discover a
          dataset or data within a dataset.</li>
        <li>Reuse: the chances of dataset reuse by different groups of data
          consumers will increase.</li>
        <li>Trust: the confidence that consumers have in the dataset will
          improve.</li>
        <li>Linkability: it will be possible to create links between data
          resources (datasets and data items).</li>
        <li>Access: humans and machines will be able to access up to date data
          in a variety of forms.</li>
        <li>Interoperability: it will be easier to reach consensus among data
          publishers and consumers.</li>
      </ul>

      <p>The following table relates Best Practices and Benefits.</p>
      <table id="bpbenefitstable" class="bptable">
        <caption>Best Practices and Benefits </caption>
        <thead>
          <tr>
            <th>Best Practice</th>
            <th>Benefits</th>
          </tr>
        </thead>
        <tbody>
          <!-- this part is auto-generated by script -->
        </tbody>
      </table>

      <p>The figure below shows the benefits that data publishers will gain
        with adoption of the best practices.</p>
      <div id="benefitsTables"></div>
      
     <!-- This section is auto-generated -->

    </section>
    <section id="requirements" class="informative">
      <h2>Use Cases Requirements x Best Practices</h2>
      <table id="requirementsbpstable" class="bptable">
        <caption>Requirements x Best Practices</caption>
        <thead><tr>
          <th>Requirement</th>
          <th>Best Practices</th></tr>
        </thead>
        <tbody>
        </tbody>
      </table>
    </section>
    <section id="acknowledgements" class="appendix" typeof="bibo:Chapter" resource="#acknowledgements" rel="bibo:Chapter" property="bibo:hasPart">
      <h2>Acknowledgements</h2>
    <p>The editors gratefully acknowledge the chairs of this Working Group: Hadley Beeman, Yaso Córdova, Deirdre Lee and the staff contact Phil Archer. </p>

<p> The editors also gratefully acknowledge the contributions made to this document by all members of the working group, specially the contributions received from Adriano Machado, Adriano Veloso, Makx Dekkers, Peter Winstanley, Bart van Leeuwen, Giancarlo Guizzardi, Gisele Pappa, Lewis John McGibbney, Manuel Carrasco-Benitez, Michel Dumontier, Nandana Mihindukulasooriya, Nathalia Sautchuk Patrício, Steven Adler, Vagner Diniz and Wagner Meira. </p>

<p>This document has benefited from inputs from many members of the <a href="/2015/spatial/">Spatial Data on the Web</a> Working Group. Specific thanks are due to Andrea Perego, Dan Brickley, Linda van den Brink and Jeremy Tandy. </p>

<p> The editors would also like to thank comments received from non-members of this working group, such as Andreas Kuckartz, Augusto Herrmann, Gregg Kellogg, Erik Wilde, Herbert Van de Sompel, Ivan Herman, Leigh Dodds, Maurino Andrea and Renato Iannella. </p>
</p>
      </section>
    <section id="change-history" class="appendix" typeof="bibo:Chapter" resource="#change-history" rel="bibo:Chapter" property="bibo:hasPart">
      <h2>Change history</h2>
      <p>Changes since the <a href="http://www.w3.org/TR/2016/WD-dwbp-20160112/">previous version</a> include:</p>
      <ul>
        
        <li>Inclusion of two Best Practices in the <a href ="#enrichment">Data Enrichment </a> section: "Enrich data by generating new data" and "Provide Complementary Presentations". </li>
<li> A new section about <a href="#Reuse">Data Usage/Data Reuse </a> with three new Best Practices: "Provide Feedback to the Original Publisher"; "Follow Licensing Terms"; "Cite the Original Publication". </li>
<li> Inclusion of new examples and updating of some of the existing examples. </li>
<li> Updating the "Intended outcome" and "How to Test" in most of the Best Practices.
</li>
      </ul>
      </section>
  </body>
</html>
