<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Data on the Web Best Practices Use Cases &amp; Requirements</title>
    <!--[if lt IE 9]>
  <script src="http://www.w3.org/2008/site/js/html5shiv.js"></script>  <![endif]-->
    <script src="https://www.w3.org/Tools/respec/respec-w3c-common" class="remove"></script>
    <script class="remove">
      var respecConfig = {

          // specification status (e.g. WD, LC, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "ED", 
          //specStatus:           "CR",


          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "dwbp-ucr",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than today, set this
         // publishDate:  "2013-12-17", 
         // prEnd:        "2014-01-12",
         // lcEnd:        "2013-11-26", 
         // crEnd:        "2013-11-26",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          copyrightStart: "2014",

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
      	  previousPublishDate:  "2014-16-05", 
          //previousPublishDate:  "2013-08-01",
          //previousMaturity:  "CR",
          previousMaturity:  "FPWD",
          
          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://w3c.github.io/dwbp/usecasesv1.html",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2013-09-06",

          // if there is an earler version of this specification at the Recommendation level,
          // set this to the shortname of that version. This is optional and not usually
          // necessary.
	  //          prevRecShortname: "rdf-concepts",

          // editors, add as many as you like
          // only "name" is required

	  editors:  [
	  { name: "Deirdre Lee", url: "mailto:deirdre.lee@insight-centre.org", company: "Insight@NUIG, Ireland", companyURL: "http://www.insight-centre.org/"},
	  { name: "Bernadette Farias Lóscio", url: "mailto:bfl@cin.ufpe.br", company: "Centro de Informática - Universidade Federal de Pernambuco, Brazil", companyURL: "http://www.cin.ufpe.br/" },
	  ],

          otherLinks: [
              {
                  key: "Contributors",
                  data: [
		  {value: "xx",
		  href: "mailto:xx"}
		  ]
		  }
		  ],

          // authors, add as many as you like.
          // This is optional, uncomment if you have authors as well as editors.
          // only "name" is required. Same format as editors.

          //authors:  [
          //    { name: "Your Name", url: "http://example.org/",
          //      company: "Your Company", companyURL: "http://example.com/" },
          //],

          // name of the WG
	  wg:           "Data on the Web Best Practices Working Group",


          // URI of the public WG page
	  wgURI:        "http://www.w3.org/2013/dwbp/",

          // name (WITHOUT the @w3.org) of the public mailing to which comments are due
	  wgPublicList: "public-dwbp-comments",


          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "http://www.w3.org/2004/01/pp-impl/68239/status",

          // if this parameter is set to true, ReSpec.js will embed various RDFa attributes
          // throughout the generated specification. The triples generated use vocabulary items
          // from the dcterms, foaf, and bibo. The parameter defaults to false.
          doRDFa: "1.1",

          alternateFormats: [ { uri: "diff-20131105.html", label: "diff to previous version" } ],

	 // implementationReportURI: "http://www.w3.org/2011/gld/wiki/DCAT_Implementations",
	  maxTocLevel: 2,

      };
    </script>
    <link rel="stylesheet" href="http://www.w3.org/TR/2014/WD-dwbp-ucr-20140605/localstyles.css" />
  </head>
  <body>
    <section id="abstract">
      <p>This document lists some use cases, compiled by the Data on the Web
        Best Practices Working Group, that represent scenarios of how data is
        commonly published on the Web and how it is used. This document also
        provides a set of requirements derived from these use cases that have
        been used to guide the development of the set of Data on the Web Best
        Practices and the development of two new vocabularies: Quality and
        Granularity Description Vocabulary and Data Usage Description
        Vocabulary. </p>
    </section>
    <section id="sotd"> </section>
    <section class="informative">
      <h2 id="intro">Introduction</h2>
      <p>There is a growing interest on publishing and consuming data on the
        Web. Both government and non-government organizations already make a
        variety of data available on the Web covering several domains like
        education, economy, security, cultural heritage and scientific data. On
        the other hand, developers and journalists manipulate this data to
        create visualizations and to perform data analysis. However, despite of
        these experiences, several important issues need to be addressed in
        order to meet the requirements of both data publishers and data
        consumers. </p>
      <p>To address these issues, the Data on the Web Best Practices Working
        Group seeks to provide guidance to publishers that will improve
        consistency in the way data is managed, thus promoting the reuse of
        data. The guidance will take two forms: a set of best practices that
        apply to multiple technologies, and vocabularies currently missing, but
        that are needed to support the data ecosystem on the Web. </p>
      <p> In order to determine the scope of the best practices and the
        requirements for the new vocabularies, a set of use cases have been
        compiled. Each use case provides a narrative describing an experience of
        publishing and using Data on the Web. The use cases cover different
        domains and illustrate some of the main challenges faced by data
        publishers and data consumers. A set of requirements, used to guide the
        development of the set of best practices as well as the development of
        the vocabularies, have been derived from the compiled use cases. </p>
      <div class="issue">
        <p>This is a First Public Working Draft and shows the working group's
          current thinking and direction. Comments and new use cases are
          particularly welcome via <a href="mailto:public-dwbp-comments@w3.org">public-dwbp-comments@w3.org</a>
          (<a href="mailto:public-dwbp-comments-request@w3.org?subject=subscribe">subscribe</a>,
          <a href="http://lists.w3.org/Archives/Public/public-dwbp-comments/">archives</a>).</p>
        <p>There are many outstanding <a href="http://www.w3.org/2013/dwbp/track/issues/raised">issues</a>
          associated with the use cases presented here that are being addressed.
          Where those issue are related to a specific use case or requirement,
          they are highlighted in the body of the document below.</p>
      </div>
    </section>
    <section>
      <h2 id="use-cases">Use Cases</h2>
      <p>A use case describes a scenario that illustrates an experience of
        publishing and using Data on the Web.The information gathered from the
        uses cases should be helpful for the identification of the best
        practices that will guide the publishing and usage of Data on the Web.
        In general, a best practice will be described at least by a statement
        and a how to do it section, i.e., a discussion of techniques and
        suggestions as how to implement it. Use cases descriptions shows some of
        the main challenges faced by publishers or developers. Information about
        challenges will be helpful to identify areas where Best Practices are
        necessary. According to the challenges, a set of requirements were
        defined, in such a way that a requirement motivates the creation of one
        or more best practices.</p>
      <section id="UC-BuildingEye" typeof="bibo:Chapter" resource="#UC-BuildingEye"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-BuildingEye">Use Case #1 -
          BuildingEye: SME use of public data</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p>Buildingeye.com makes building and planning information easier to
          find and understand by mapping what's happening in your city. In
          Ireland local authorities handle planning applications and usually
          provide some customized views of the data (PDFs, maps, etc.) on their
          own website. However there isn't an easy way to get a nationwide view
          of the data. BuildingEye, an independent SME, built <a href="http://mypp.ie/">http://mypp.ie/</a>
          to achieve this. However as each local authority didn't have an Open
          Data portal, BuildingEye had to directly ask each local authority for
          its data. It was granted access to some authorities, but not all. The
          data it did receive was in different formats and of varying
          quality/detail. BuildingEye harmonized this data for its own system.
          However, if another SME wanted to use this data, they would have to go
          through the same process and again go to each local authority asking
          for the data. </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li>Domains: Planning data</li>
          <li>Obligation/motivation: demand from SME</li>
          <li>Usage: Commercial usage</li>
          <li>Quality: standardized, interoperable across local authorities</li>
          <li>Size: medium</li>
          <li>Type/format: structured according to legacy system schema</li>
          <li>Rate of change: daily</li>
          <li>Potential audience: Business, citizens</li>
          <li>“Governance”: local authorities</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Access to data is currently a manual process, on a case by case
            basis</li>
          <li>Data is provided in different formats, e.g. database dumps,
            spreadsheets</li>
          <li>Data is structured differently, depending on the legacy system
            schema, concepts and terms not interoperable</li>
          <li>No official Open license associated with the data</li>
          <li>Data is not available for further reuse by other parties</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>Creation of top-down policy on Open Data to ensure common
            understanding and approach</li>
          <li>Top-down guidance on recommended Open license usage</li>
          <li>Standardized, non-proprietary formats</li>
          <li>Availability of recommended domain-specific vocabularies.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatMachineRead">FormatMachineRead</a>
          , <a href="#R-FormatStandardized">FormatStandardized</a> , <a href="#R-FormatOpen">FormatOpen</a>
          , <a href="#R-LicenseAvailable">LicenseAvailable</a> and <a href="#R-AccessBulk">AccessBulk</a>
        </p>
      </section>
      <section id="UC-TheLandPortal" rel="bibo:Chapter" resource="#h3_UC-TheLandPortal"

        typeof="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-TheLandPortal">Use Case #2 -
          The Land Portal</h3>
        <p class="contributor">(Contributed by Carlos Iglesias)</p>
        <p>The IFAD Land Portal platform it's been completely rebuilt as an Open
          Data collaborative platform for the Land Governance community. Among
          the new features the Land Portal will provide access to comprehensive
          and in-depth 100+ indicators from 25+ different sources on land
          governance issues for 200+ countries over the world, as well as a
          repository of land related-content and documentation. Thanks to the
          new platform people could (1) curate and incorporate new data and
          metadata by means of different data importers and making use of the
          underlying common data model; (2) search, explore and compare the data
          through countries and indicators; and (3) consume and reuse the data
          by different means (i.e. raw data download at the data catalog; linked
          data and SPARQL endpoint at RDF triplestore; RESTful API; and built-in
          graphic visualization framework)</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li>Domains: Land Governance; Development</li>
          <li>Obligation/motivation: To find reliable data driven indicators on
            land governance and put all them together to facilitate access,
            study, analysis, comparison and data gaps detection.</li>
          <li>Usage: Research; Policy Making, Journalism; Development;
            Investments; Governance; Food security; Poverty; Gender issues.</li>
          <li>Quality: Every sort of data, from high quality to unverified one.</li>
          <li>Size: Varies, but low-medium in general.</li>
          <li>Type/format: Varies: APIs; JSON; spreadsheets; CSVs; HTMLs; XMLs;
            PDFs...</li>
          <li>Rate of change: Usually yearly, but also lower rates (monthly,
            quarterly...)</li>
          <li>Data lifespan: Unlimited.</li>
          <li>Potential audience: Practitioners; Policy makers; Activists;
            Researchers; Journalists.</li>
        </ul>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Data coverage.</li>
          <li>Quality of data and metadata.</li>
          <li>Lack of machine-readable metadata.</li>
          <li>Inconsistency between different data sources.</li>
          <li>Wide variety of formats and technologies.</li>
          <li>Some non machine-readable formats.</li>
          <li>Data variability (models, sources, etc.)</li>
          <li>Data provenance.</li>
          <li>Diversity and (sometimes) complexity of Licenses.</li>
          <li>Internationalization issues (e.g. different formats for numbers,
            dates, etc.) and multilingualism</li>
        </ul>
        <p><strong>Potential Requirements:</strong></p>
        <ul>
          <li>Availability of general use taxonomies (countries, topics, etc.).</li>
          <li>Data interoperability i.e. domain-specific vocabularies for a
            common data model with reference formats and protocols.</li>
          <li>Data persistence.</li>
          <li>Versioning mechanisms.</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-MetadataMachineRead">MetadataMachineRead</a>
          , <a href="#R-GranularityLevels">GranularityLevels</a> , <a href="#R-FormatMachineRead">FormatMachineRead</a>
          , <a href="#R-FormatStandardized">FormatStandardized</a> , <a href="#R-FormatLocalize">FormatLocalize</a>
          , <a href="#R-VocabReference">VocabReference</a> , <a href="#R-VocabVersion">VocabVersion</a>
          , <a href="#R-ProvAvailable">ProvAvailable</a> , <a href="#R-AccessBulk">AccessBulk</a>
          , <a href="#R-AccessRealTime">AccessRealTime</a> , <a href="#R-PersistentIdentification">Persistent</a>
          , <a href="#R-QualityCompleteness">QualityCompleteness</a> and <a href="#R-QualityMetrics">QualityMetrics</a>
        </p>
        <p> <strong>Requires:</strong> <a href="#R-MetadataStandardized">R-MetadataStandardized</a>
          , <a href="#R-MetadataInteroperable">MetadataInteroperable</a> and <a

            href="#R-GranularityLevels">GranularityLevels</a> </p>
      </section>
      <section id="UC-RecifeOpenDataPortal" typeof="bibo:Chapter" resource="#UC-RecifeOpenDataPortal"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-RecifeOpenDataPortal">Use
          Case #3 - Recife Open Data Portal</h3>
        <p class="contributor">(Contributed by Bernadette Lóscio )</p>
        <p>Recife is a city situated in the Northeast of Brazil and it is famous
          for being one of the Brazil’s biggest tech hubs. Recife is also one of
          the first Brazilian cities to release data generated by public sector
          organizations for public use as Open Data. Then <a href="http://dados.recife.pe.gov.br/">Open
            Data Portal Recife </a> was created to offer access to a repository
          of governmental machine-readable data about several domains,
          including: finances, health, education and tourism. Data is available
          in CSV and GeoJSON format and every dataset has a metadata
          description, i.e. descriptions of the data, that helps in the
          understanding and usage of the data. However, the metadata is not
          described using standard vocabularies or taxonomies. In general, data
          is created in a static way, where data from relational databases are
          exported in a CSV format and then published in the data catalog.
          Currently, they are working to have dynamically generated data from
          the contents of relational databases, then data will be available as
          soon as they are created. The main phases of the development of this
          initiative were: to educate people with appropriate knowledge
          concerning Open Data, relevant data identification in order to
          identify the sources of data that their pontential consumers could
          find useful, data extraction and transformation from the original data
          sources to the open data format, configuration and installation of the
          open data catalogue tool, data publication and portal release.</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li>Domains: Base registers, Cultural heritage information, Geographic
            information, Infrastructure information, Social data and Tourism
            Information</li>
          <li>Obligation/motivation: Data that must be provided to the public
            under a legal obligation (Brazilian Information Acess Act, edited in
            2012); Provide public data to the citizens</li>
          <li>Usage: Data that supports democracy and transparency; Data used by
            application developers</li>
          <li>Quality: Verified and clean data</li>
          <li>Size: in general small to medium CSV files</li>
          <li>Type/format: CSV, geojson</li>
          <li>Rate of change: different rates of changes depending on the data
            source</li>
          <li>Potential audience: application developers, startups, government
            organizations</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Use common vocabs to facilitate data integration</li>
          <li>Provide structural metadata to help data understanding and usage</li>
          <li>Automate the data publishing process to keep data up to date and
            accurate</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-MetadataMachineRead">MetadataMachineRead</a>
          , <a href="#R-MetadataStandardized">MetadataStandardized</a> , <a href="#R-MetadataDocum">MetadataDocum</a>
          , <a href="#R-VocabReference">VocabReference</a> , <a href="#R-VocabDocum">VocabDocum</a>
          , <a href="#R-VocabOpen">VocabOpen</a> , <a href="#R-SelectHighValue">SelectHighValue</a>
          , <a href="#R-SelectDemand">SelectDemand</a> , <a href="#R-QualityCompleteness">QualityCompleteness</a>
          , <a href="#R-SynchronisedData">SynchronisedData</a> and <a href="#R-QualityComparable">QualityComparable</a>
        </p>        
      </section>
      <section id="UC-DadosGovBr" typeof="bibo:Chapter" resource="#UC-DadosGovBr"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DadosGovBr">Use Case #4 -
          Dados.gov.br</h3>
        <p class="contributor">(Contributed by Yasodara)</p>
        <p> Dados.gov.br is the open data portal of the Brazil's Federal
          Government. The site was built in community, in a network pulled by
          three technicians from the Ministry of Planning. They managed the WG3
          from <a href="http://wiki.gtinda.ibge.gov.br/Tecnologia.ashx"> "INDA"</a>
          or "National Infrastructure for Open Data". CKAN was chosen because it
          is Free Software and present independent solutions for the placement
          of data catalog of the Federal Government provided on the internet. </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li>Domains: federal budget, addresses, Infrastructure information,
            e-gov tools usage, social data, geographic information, political
            information, Transport information</li>
          <li>Obligation/motivation: Data that must be provided to the public
            under a legal obligation, the called LAI or Brazilian Information
            Acess Act, edited in 2012</li>
          <li>Usage: Data that is the basis for services to the public; Data
            that has commercial reuse potential.</li>
          <li>Quality: Authoritative, clean data, vetted and guaranteed;</li>
          <li>Lineage/Derivation: Data came from various publishers. As a
            catalog, the site has faced several challenges, one of them was to
            integrate the various technologies and formulas used by publishers
            to provide datasets in the portal.</li>
          <li>Type/format: Tabular data, text data</li>
          <li>Rate of change: There is fixed data and data with high rate of
            change</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>data integration (lack of vocabs)</li>
          <li>collaborative construction of the portal: managing online sprints
            and balancing public expectatives.</li>
          <li>Licencing the data of the portal. Most of data that is in the
            portal has not a special licence for data. As you can see, there is
            different types of licences that applied to the datasets.</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">R-VocabReference</a>
          , <a href="#R-LicenseAvailable">R-LicenseAvailable</a> and <a href="#R-QualityOpinions">R-QualityOpinions</a>
        </p>
      </section>
      <section id="UC-ISOGEOStory" typeof="bibo:Chapter" resource="#UC-ISOGEOStory"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-ISOGEOStory">Use Case #5 -
          ISO GEO Story</h3>
        <p class="contributor">(Contributed by Ghislain Atemezing)</p>
        <p> ISO GEO is a company managing catalogs records of geographic
          information in XML, conformed to ISO-19139. (ISO- 19139 is a French
          adaptation of the ISO- 19115) An excerpts is <a href="http://cl.ly/3A1p0g2U0A2z">here</a>
          . They export thousands of catalogs like that today, but they need to
          manage them better. In their platform, they store the information in a
          more conventional manner, and use this standard for export dataset
          compliant to Inspire interoperability , or via the CSW protocol.
          Sometimes, they have to enrich their metadata with other ones,
          produced by tools like GeoSource and accessed through SDI (Spatial
          Data Infrastructure), with their own metadata records. A sample
          containing 402 metadata records in ISO 19139 are in public
          consultation <a href="http://geobretagne.fr/geonetwork/srv/fre/main.home">
            here</a> . They want to be able to integrate all the different
          implementations of the ISO 19139 in different tools in a single
          framework to better understand the thousand of metadata records they
          use in their day-to-day business. Types of information recorded in
          each file (see example <a href="http://www.eurecom.fr/%7Eatemezin/datalift/isogeo/5cb5cbeb-fiche1.xml">
            here )</a> are the following: Contact info (metadata) [Data issued];
          spatial representation ; reference system info [code space ], spatial
          Resolution ; Geographic Extension of the data, File distribution; Data
          Quality ; process step, etc. </p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Achieve interoperability between supporting applications, e.g.:,
            validation and discovery services built over metada repository</li>
          <li>Capture the semantics of the current metadata records with respect
            to ISO 19139 standard.</li>
          <li>Unify way to have access to each record within the catalog at
            different level e.g.:, local, regional, national or EU level.</li>
        </ul>
      </section>
      <section id="UC-DutchBasicRegisters" rel="bibo:Chapter" resource="#h3_UC-DutchBasicRegisters"

        typeof="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DutchBasicRegisters">Use
          Case #6 - Dutch basic registers</h3>
        <p class="contributor">(Contributed by Christophe Guéret)</p>
        <p> The Netherlands has a <a href="http://e-overheid.nl/onderwerpen/stelselinformatiepunt/stelsel-van-basisregistraties/basisregistraties">
            set of registers </a> they are looking at opening and exposing as
          Linked (Open) Data under the context of the project <a href="http://www.pilod.nl/wiki/Hoofdpagina">"PiLOD"</a>
          community of expertise. The registers contain information about
          buildings, people, businesses and other individuals public bodies may
          want to refer to for they daily activities. One of them is, for
          instance, the service of public taxes ("BelastingDienst") which
          regularly pulls out data from several registers, stores this data in a
          big Oracle instance and curates it. This costly and time consuming
          process could be optimized by providing on-demand access to up-to-date
          descriptions provided by the register owners. </p>
        <p> <strong>Challenges:</strong> </p>
        In terms of challenges, linking is for once not much of an issue as <a

          href="http://www.e-overheid.nl/onderwerpen/stelselinformatiepunt/stelselthemas/verbindingen/verbindingen-tussen-basisregistraties">
          registers already cross-reference unique identifiers </a> (see also <a

          href="http://www.wikixl.nl/wiki/gemma/index.php/Ontsluiting_basisgegevens">
          http://www.wikixl.nl/wiki/gemma/index.php/Ontsluiting_basisgegevens </a>
        ). A <a href="http://www.pilod.nl/wiki/Boek/URI-strategie"> URIs scheme
        </a> with predicable URIs is being considered for implementation. Actual
        challenges include:
        <ul>
          <li> Capacity: at this point, it can not be asked that every register
            owner cares for publishing his own data. Some of them export what
            they have on the national open data portal. This data has been used
            to do some testing with third-party publication from PiLODers but
            this is rather sensitive as a long term strategy (governmental data
            has to be tracable/trustable as such). The middle ground solution
            currently deployed is the PiLOD platform, a (semi)-official platform
            for publishing register data.</li>
          <li> Privacy: some of the register data is personal or may become so
            when linked to others (e.g. disambiguate personal data based on
            adresses). Some registers will require to provide secured access to
            some of their data to some people only (Linked Data, not Open). Some
            others can go along with open data as long as they get a precise log
            of who is using what.</li>
          <li> Revenue: institutions working under mixed gov/non-gov funding
            generate part of their revenue by selling some of the data they
            curate. Switching to an open data model will generate a direct loss
            in revenue that has to be backed-up by other means. This does not
            have to mean closing the data, e.g. a model of open dereferencing +
            paid dumps can be considered, as well as other indirect revenue
            streams. </li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">VocabReference</a>
          , <a href="#R-SensitivePrivacy">R-SensitivePrivacy</a> , <a href="#R-UniqueIdentifier">UniqueIdentifier</a>
          , <a href="#R-MultipleRepresentations">MultipleRepresentations</a>
          and <a href="#R-CoreRegister">R-CoreRegister</a> </p>
      </section>
      <section id="UC-WindCharacterizationScientificStudy" typeof="bibo:Chapter"

        resource="#UC-WindCharacterizationScientificStudy" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-WindCharacterizationScientificStudy">Use
          Case #7 - Wind Characterization Scientific Study</h3>
        <p class="contributor">(Contributed by Eric Stephan)</p>
        <p>This use case describes a data management facility being constructed
          to support scientific offshore wind energy research for the U.S.
          Department of Energy’s Office of Energy Efficiency and Renewable
          Energy (EERE) Wind and Water Power Program. The Reference Facility for
          Renewable Energy (RFORE) project is responsible collecting wind
          characterization data from remote sensing and in situ instruments
          located on an offshore platform. This raw data is collected by the
          Data Management Facility and processed into a standardized NetCDF
          format. Both the raw measurements and processed data are archived in
          the PNNL Institutional Computing (PIC) petascale computing facility.
          The DMF will record all processing history, quality assurance work,
          problem reporting, and maintenance activities for both instrumentation
          and data. All datasets, instrumentation, and activities are cataloged
          providing a seamless knowledge representation of the scientific study.
          The DMF catalog relies on linked open vocabularies and domain
          vocabularies to make the study data searchable. Scientists will be
          able to use the catalog for faceted browsing, ad-hoc searches, query
          by example. For accessing individual datasets a REST GET interface to
          the archive will be provided.</p>
        <p> <strong>Challenges:</strong> </p>
        For accessing numerous datasets scientists will be accessing the archive
        directly using other protocols such as sftp, rsync, scp, access
        techniques such as: <a href="http://www.psc.edu/index.php/hpn-ssh">
          http://www.psc.edu/index.php/hpn-ssh</a>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">FormatStandardized</a>
          , <a href="#R-VocabReference">VocabReference</a> , <a href="#R-VocabOpen">VocabOpen</a>
          and <a href="#R-AccessRealTime">AccessRealTime</a> </p>
      </section>
      <section id="UC-DigitalArchivingofLinkedData" typeof="bibo:Chapter" resource="#UC-DigitalArchivingofLinkedData"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DigitalArchivingofLinkedData">Use
          Case #8 - Digital archiving of Linked Data</h3>
        <p class="contributor">(Contributed by Christophe Guéret)</p>
        <p> Taking the concrete example of the digital archive <a href="http://dans.knaw.nl/">"DANS"</a>
          , digital archives have so far been concerned with the preservation of
          what could be defined as "frozen" dataset. A frozen dataset is a
          finished, self-contained, set of data that does not evolve after it
          has been constituted. The goal of the preserving institution is to
          ensure this dataset remains available and readable for as many years
          as possible. This can for example concern an audio record, a digitized
          image, e-books or database dumps. Consumers of the data are expected
          to look-up for a specific content based on its associated <a href="http://www.persid.org/">persistent
            identifier</a> , download it from the archive and use it. Now comes
          the <a href="http://www.prelida.eu/">question of the preservation of
            Linked Open Data.</a> In opposition to "frozen" data sets, linked
          data can be qualified as "live" data. The resources it contains are
          part of a larger entity to which third parties contribute, one of the
          design principles indicate that other data producers and consumers
          should be able to point to data. As LD publishers stop offering their
          data (e.g. at the end of a project), taking the LD off-line as a dump
          and putting it in an archive effectively turns it into a frozen
          dataset, likewise to SQL dumps and other kind of data bases. The
          question then raises as to which extent this is an issue... </p>
        <p> <strong>Challenges:</strong> The archive has to think about whether
          serving dereferencing for resources found in preserved datasets is
          required or not, also think about providing a SPARQL end point or not.
          If data consumers and publishers are fine with having RDF data dumps
          to be downloaded from the archive prior to its usage - just like any
          other digital item so far - the technical challenges could be limited
          to handling the size of the dumps and taking care of serialisation
          evolution over time (e.g. from Ntriples to Trig, or from RDF/XML to <a

            href="http://www.rdfhdt.org/">HDT</a> ) as the preference for these
          formats evolves. Turning a live dataset into a frozen dump also raises
          the question of the scope. Considering that LD items are only part of
          a much larger graph that gives them meaning through context the only
          valid dump would be a complete snapshot of the entire connected
          component of the Web of Data graph the target dataset is part of. </p>
        <p> <strong>Potential Requirements:</strong> Decide on the importance
          of the de-referencability of resources and the potential implications
          for domain names and naming of resources. Decide on the scope of the
          step that will turn a connected sub-graph into an isolated data dump.
        </p>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">VocabReference</a>
          , <a href="#R-UniqueIdentifier">UniqueIdentifier</a> , <a href="#R-PersistentIdentification">PersistentIdentification</a>
          and <a href="#R-Archiving">Archiving</a> </p>
      </section>
      <section id="UC-LATimesReporting" typeof="bibo:Chapter" resource="#UC-LATimesReporting"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-LATimesReporting">Use Case
          #9 - LA Times' reporting of Ron Galperin's Infographic</h3>
        <p class="contributor">(Contributed by Phil Archer )</p>
        <p> On 27 March 2014, the LA Times published a story <i>Women earn 83
            cents for every $1 men earn in L.A. city government</i>. It was
          based on an Infographic released by LA's City Controller, Ron
          Galperin. The Infographic was based on a dataset published on LA's
          open data portal, <a href="https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja">
            Control Panel LA</a> . That portal uses the <a href="http://www.socrata.com/">Socrata</a>
          platform which offers a number of spreadhseet-like tools for examining
          the data, the ability to download it as CSV, embed it in a Web page
          and see its metadata.</p>
        <p> <strong>Positive aspects:</strong> </p>
        <ul>
          <li> The LA Times story makes its sources clear (it also links to a
            related <a href="http://www.pewsocialtrends.org/2013/12/11/on-pay-gap-millennial-women-near-parity-for-now/">
              Pew Research Center article</a> ). </li>
          <li>It offers readers a commentary on the particular issue raised and
            is easy for anyone to digest.</li>
          <li>Data sources are cited directly and can be followed up on by
            (human) readers.</li>
        </ul>
        <p> <strong>Negative aspects:</strong> </p>
        <ul>
          <li>The Infographic itself only cites the data portal, not the
            specific dataset, i.e. https://controllerdata.lacity.org/ not
https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja/</li>
          <li> The <a href="https://controllerdata.lacity.org/Payroll/Gender-Breakdown-of-City-Workers-by-Category/fvfi-5kja/about">
              metadata</a> provided on the data portal is very sparse with many
            fields left empty. </li>
          <li>The dataset is itself the result of an analysis (there are only 8
            lines in the table), the raw data on which it is based is not cited,
            let alone made available, and the methods used are not described.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Data Citation - how could Ron Galperin have referred to the source
            data in the Infographic? (the URI is way too long). QR code? Short
            PURL?</li>
          <li>How could the publisher of the data link to the Infographic as a
            visualization of it?</li>
          <li>In this case, the creator of the underlying data is the same as
            the creator of the Infographic, but if they were different, how
            could the data creator discover the Infographic, still less the
            media report about it?</li>
          <li>The methodology used is not explained - making it hard to assess
            trustworthiness. How can provenance be described?</li>
          <li>The metadata is incomplete and does not used a recognized standard
            vocabulary making automated discovery and use by anyone other than
            the data creator difficult.</li>
        </ul>
        <p> <strong>Other Data Journalism blogs:</strong> </p>
        <ul>
          <li> <a href="http://fivethirtyeight.com/features/what-the-fox-knows/">
              FiveThirtyEight</a> </li>
          <li> <a href="http://blogs.wsj.com/numbersguy/">Wall Street Journal’s
              Number Guy column</a> </li>
          <li> <a href="http://www.theguardian.com/news/datablog"> Guardian’s
              data blog</a> </li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-MetadataStandardized">MetadataStandardized</a>
          , <a href="#R-UniqueIdentifier">UniqueIdentifier</a> and <a href="#R-Citable">Citable</a>
        </p>        
      </section>
      <section id="UC-UruguayOpenDataCatalogue" typeof="bibo:Chapter" resource="#UC-UruguayOpenDataCatalogue"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-UruguayOpenDataCatalogue">Use
          Case #10 - Uruguay: open data catalogue</h3>
        <p class="contributor">(Contributed by AGESIC )</p>
        <p>Uruguay open data site holds 85 datasets containing 114 resources
          since the first dataset was published in Dec. 2012. Open data
          initiative prioritizes the “use of data” rather than “quantity of
          data”, that’s why the catalogue holds 25 applications using datasets
          resources in some way. It’s important for the project to keep the
          relation 1/3 between applications and datasets. Most of the resources
          are CSV and shapefiles; basically we have a 3 stars catalogue and the
          reason why we can’t go to the next level is the lack of resources
          (time, human, economic, etc.) at government agencies to implement an
          open data liberation strategy. So when we are asked about opening
          data, keep it simple is the answer, and CSV is far the easiest and
          smart way to start. Uruguay has an Access to public information law
          but don’t have legislation about open data. The open data initiative
          is leaded by AGESIC with the support of the open data working group.
          OD Working group: - Intendencia de Montevideo – www.montevideo.gub.uy
          - INE – www.ine.gub.uy - AGEV – www.agev.opp.gub.uy - FING – UDELAR –
          www.fing.edu.uy - D.A.T.A. – www.datauy.org</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li>Domains:
            <ul>
              <li>Infrastructure: Most of the datasets are shapefiles.</li>
              <li>Transportation: Shapefiles and CSV, containing information
                about public transportation (stops and frequency), roads,
                accidents, etc.</li>
              <li>Tourism: data about regional events, cultural agenda, hotels,
                campings, statistics.</li>
              <li>Economics: Budget, Consumer price declarations, etc.</li>
              <li>Social development</li>
              <li>Environment</li>
              <li>Health</li>
              <li>Education</li>
              <li>Culture</li>
            </ul>
          </li>
          <li>Obligation/motivation: There is no obligation for the government
            agencies to publish open data. All initiatives were carried on by
            agencies that wants to support the initiative.</li>
          <li>Usage: Develop applications and new services for citizens,
            agencies interoperability (exchange of information in open data
            formats), transparency</li>
          <li>Quality: Most of the data is actualized properly, datasets
            metadata is complete, resources metadata about 70% complete.</li>
          <li>Size: Small; most of the datasets size is less than 1Gb.</li>
          <li>Type/format: SHAPEFILE (35), CSV (26), TXT (19), ZIP (12), HTML
            (7), XLS (6),PDF (4), XML (3), RAR (2)</li>
          <li>Rate of change: Depends on the dataset.</li>
          <li>Data lifespan: Depends on the dataset, some change in real time,
            other monthly, every 6 month, annual or never change.</li>
          <li>Potential audience: Developers, Journalists, Civil society,
            Entrepreneurs. </li>
        </ul>
        <p> <strong>Challenges:</strong> Consolidate tool to manage datasets,
          improve visualizations and transform resources to higher level (4 – 5
          stars). Automate publication process using harvesting or similar
          tools. Alerts or control panel to keep data updated. </p>
        <p> <strong>Requires:</strong> <a href="#R-VocabReference">VocabReference</a>
          and <a href="#R-SynchronisedData">SynchronisedData</a> </p>
      </section>
      <section id="UC-GS1-Digital" typeof="bibo:Chapter" resource="#UC-GS1-Digital"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-GS1-Digital">Use Case #11 -
          GS1: GS1 Digital</h3>
        <p class="contributor">(Contributed by Mark Harrison (University of
          Cambridge) &amp; Eric Kauz (GS1) )</p>
        <p>Retailers and Manufacturers / Brand Owners are beginning to
          understand that there can be benefits to openly publishing structured
          data about products and product offerings on the web as Linked Open
          Data. Some of the initial benefits may be enhanced search listing
          results (e.g. Google Rich Snippets) that improve the likelihood of
          consumers choosing such a product or product offer over an alternative
          product that lacks the enhanced search results. However, the longer
          term vision is that an ecosystem of new product-related services can
          be enabled if such data is available. Many of these will be
          consumer-facing and might be accessed via smartphones and other mobile
          devices, to help consumers to find the products and product offers
          that best match their search criteria and personal preferences or
          needs - and to alert them if a particular product is incompatible with
          their dietary preferences or other criteria such as ethical /
          environmental impact considerations - and to suggest an alternative
          product that may be a more suitable match. A more <a href="https://www.w3.org/2013/dwbp/wiki/Use_Cases#GS1:_GS1_Digital">complete
            description</a> of this use case is available.</p>
        <p><strong>Elements:</strong></p>
        <ul>
          <li>Domains:
            <ul>
              <li>Product master data (e.g. technical specifications,
                ingredients, nutritional information, dimensions, weight,
                packaging)</li>
              <li>Product offerings (e.g. sales price, availability (online,
                locally), payment options, delivery/collection options</li>
              <li>Ethical / environmental claims about a product and its
                production process</li>
            </ul>
          </li>
          <li>Obligation/motivation:
            <ul>
              <li>initially, enhanced search result listings (e.g. Google Rich
                Snippets)</li>
              <li>vision is to enable an ecosystem of new digital apps around
                product data</li>
              <li>the food sector in the EU is already obliged under new food
                labelling legislation (EU 1169 / 2011, Article 14) to provide
                the same amount of information about a food product that is sold
                online to consumers as the information that would be available
                to them from the product packaging if they picked up the product
                in-store. Although the legislation does not suggest that Linked
                Open Data technology should be used to make the same information
                available in a machine-readable format, there is currently
                significant investment and effort to upgrade websites to provide
                accurate and detailed information about food products; the GS1
                Digital team consider that for a relatively small amount of
                effort, these companies could gain some tangible benefits (e.g.
                enhanced search results) from such compliance efforts by using
                Linked Open Data technology within their web pages.</li>
            </ul>
          </li>
          <li>Usage:
            <ul>
              <li>data providing transparency about product characteristics</li>
              <li>data used to help consumers make informed choices about which
                products to buy/consume</li>
            </ul>
          </li>
          <li>Quality: Very important to have trustworthy authoritative data
            from respective organizations</li>
          <li>Size: Typically 20+ factual claims per product - probably 40+ RDF
            triples</li>
          <li>Type/format: HTML + RDFa / JSON-LD / Microdata</li>
          <li>Rate of change: mostly static data initially - but subject to some
            variation over time</li>
          <li>Data lifespan: data should remain accessible until products are no
            longer considered to be in circulation; this represents a challenge
            for deprecated product lines data that is stated authoritatively by
            one organization might be embedded / referenced in the data asserted
            by another organization; this raises concerns about whether embedded
            data becomes stale if it is inadequately synchronized, that
            referenced data is not dereferenced (and therefore not discovered /
            gathered) by consumers or the data. From a liability perspective,
            there also needs to be clarity about which organization asserted
            which factual information - and also information about which
            organization has the authority to assert specific factual claims.</li>
          <li>Potential audience: machine-readable (search engines, data
            aggregators, mobile apps etc.)</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Linked Open Data about products is likely to be highly distributed
            in nature and various parties have authority over specific claims</li>
          <li>Accreditation agencies have authority over ethical/environmental
            claims</li>
          <li>Brand owners / manufacturers have authority over product master
            data</li>
          <li>Retailers have authority over facts related to product offerings
            (price, availability etc.)</li>
          <li>An organization (e.g. retailer) might embed authoritative data
            asserted by another organization (e.g. brand owner) and there is the
            risk that such embedded information becomes stale if it is not
            continuously synchronized.</li>
          <li>An organization (e.g. retailer) might reference a graph of
            authoritative data that can be retrieved via an HTTP request to a
            remote HTTP URI. There is a risk that software or search engines
            consuming Linked Open Data containing such references may fail to
            dereference such HTTP URIs and in doing so may fail to gather all of
            the relevant data.</li>
          <li>Organizations are currently faced with a choice of whether to
            embed machine-readable structured data in their web pages using a
            block approach (e.g. using JSON-LD) or using an inline approach
            (e.g. using RDFa, RDFa Lite or Microdata). A block approach
            (JSON-LD) may be simpler and less brittle than inline annotation,
            especially as it can be easily decoupled from structural changes to
            the body of the web page that may happen over time in the redesign
            of a website. At present, tool support for the 3 major markup
            approaches for embedded Linked Open Data (RDFa, JSON-LD, MIcrodata)
            is unequal across the three formats and some tools may not export or
            import / ingest all 3 formats - some tools even fail to extract data
            from JSON-LD markup created by their corresponding export tool.
            There are some significant challenges to ensure that the structured
            data embedded within a web page is correctly linked to form coherent
            RDF triples, without any dangling nodes that should be connected to
            the Subject or other nodes.</li>
          <li>Only through the provision of best-in-class tool support that
            recognize all three major formats on a completely equal footing can
            organizations have any confidence that they can use any of the 3
            major markup formats and the ability to verify / validate that their
            own markup does result in the correct RDF triples.</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>The ability to determine who asserted various facts - and whether
            they are the organization that can assert those facts
            authoritatively.</li>
          <li>Where data from other sources is embedded, there is a risk that
            the embedded data might be stale. It is therefore helpful to
            indicate which graph of triples is a snapshot in time from data from
            another source - and to provide a link to the original source, so
            that the consumer of the data has the opportunity to obtain a fresh
            version of the live data rather than relying on a potentially stale
            snapshot graph of data. DWBP could provide guidance about how to
            indicate which graph of data is a snapshot and where it came from.</li>
          <li>Consumers of Linked Open Data about products might rely on it for
            making decisions - not only about purchase but even consumption. If
            the data about a product is inaccurate or out-of-date, we might need
            to provide some guidance about how liability terms and disclaimers
            can be expressed in Linked Open Data. We’re not suggesting that we
            define such terms from a legal perspective - but perhaps there is an
            existing framework in a similar way that there is an existing
            framework for expressing various licences of the data? If not,
            perhaps such a framework needs to be developed - but outside of the
            DWBP group? Licensing generally says what you’re allowed to do with
            the data - but I don’t think it says anything about liability for
            using the data or making decisions based on that data. This area
            probably needs some clarification, particularly if there is a risk
            of injury or death (due to inaccurate information about allergens in
            a food product).</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">FormatStandardized</a>
          , <a href="#R-FormatMultiple">FormatMultiple</a> , <a href="#R-ProvAvailable">ProvAvailable</a>
          , <a href="#R-AccessUptodate">AccessUptodate</a> , <a href="#R-LicenseLiability">LicenseLiability</a>
          , <a href="#R-PersistentIdentification">PersistentIdentification</a>
          , <a href="#R-Citable">Citable</a> , <a href="#R-SynchronisedData">SynchronisedData</a>
          and <a href="#R-CoreRegister">CoreRegister</a> </p>
      </section>
      <section id="UC-Tabulae" typeof="bibo:Chapter" resource="#UC-Tabulae" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-Tabulae">Use Case #12 -
          Tabulae - how to get value out of data</h3>
        <p class="contributor">(Contributed by Luis Polo )</p>
        <p>Tabul.ae is a framework to publish and visually explore data that can
          used to deploy powerful and easy-to-exploit open data platforms, so
          contributing organizations to unleash the potential of their data. The
          aim is to enable data owners (public organizations) and consumers
          (citizens and business reusers) to transform the information they
          manage into added-value knowledge, empowering them to easily create
          data-centric web applications. These applications are built upon
          interactive and powerful graphs, and take the shape of interactive
          charts, dashboards, infographies and reports. Tabulae provides a high
          degree of assistance to create these apps and also automate several
          data visualizations tasks (i.e., recognition of geographical entities
          to automatically generate a map). In addition, the charts and maps are
          portable outside the platform and can be smartly integrated with any
          web content, enhancing the reusability of the information.</p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li>Domains: Quantitative and geographical information: stats,
            biodiversity, socio-economic indicators, environment, security, etc</li>
          <li>Obligation/motivation: to help citizens and companies (especially,
            consultancy firms) to understand and create value from open data by
            means of reusable, user-made visualizations.</li>
          <li>Usage: Data used by citizens, public employees and companies.</li>
          <li>Quality: The information must be at least semi-structured (for
            instance, an spreadsheet).</li>
          <li>Size: Medium and large datasets (hundreds of thousands and
            millions rows)</li>
          <li>Type/format: Tabulae can manage relational databases, GeoJSON, CSV
            files and spreadsheets, and provides an API for programmatic access.</li>
          <li>Rate of change: depending on the original datasets. The platform
            enables automatic update from original sources.</li>
          <li>Data lifespan: depending on the original datasets.</li>
          <li>Potential audience: Organizations that want to publish their
            catalogue of datasets and aim to maximize their impact and
            consumption.</li>
        </ul>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Quality of data and metadata.</li>
          <li>Inconsistency between different data sources.</li>
          <li>Wide variety of formats and technologies.</li>
          <li>Different data schemas that complicates the integration of data
            sources.</li>
          <li>Diversity and (sometimes) complexity of Licenses.</li>
          <li>Data persistence.</li>
          <li>Internationalization and format issues (e.g., languages, numbers,
            dates, etc.)</li>
        </ul>
        <p> <strong>Potential Requirements:</strong> </p>
        <ul>
          <li>Dataset versioning and updating mechanisms</li>
          <li>Standardization of schemas</li>
          <li>Integration with other platforms/services</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-FormatStandardized">FormatStandardized</a>
          , <a href="#R-FormatLocalize">FormatLocalize</a> , <a href="#R-VocabReference">VocabReference</a>
          , <a href="#R-VocabVersion">VocabVersion</a> , <a href="#R-ProvAvailable">ProvAvailable</a>
          , <a href="#R-SynchronisedData">SynchronisedData</a> and <a href="#R-QualityCompleteness">QualityCompleteness</a>
        </p>
      </section>
      <section id="UC-ViolenceMap" typeof="bibo:Chapter" resource="#UC-ViolenceMap"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-ViolenceMap">Use Case #13 -
          Retrato da Violência (Violence Map)</h3>
        <p class="contributor">(Contributed by Yasodara )</p>
        <p> This is a Data Visualization made in 2012 by <a href="http://vitorbaptista.com/">Vitor
            Batista</a> , <a href="http://leotartari.com/">Léo tartari</a> and
          <a href="http://tbueno.com/">Thiago Bueno</a> for a <abbr title="World Wide Web Consortium">W3C</abbr>
          Brazil Office challenge about data from Rio Grande do Sul (a brazilian
          region). The data was released in a .zip package, the original format
          was .csv. The code and the documentation of the project are <a href="https://github.com/dataviz/retrato-da-violencia.org">
            in it's GitHub repository</a> </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li>Domains: political information, regional security
            information.</li>
          <li>Obligation/motivation: Data that must be provided to the public
            under a legal obligation, the called LAI or Brazilian Information
            Acess Act, edited in 2012</li>
          <li>Quality: not guaranteed data</li>
          <li>Type/format: Tabular data</li>
          <li>Rate of change: There is no new releases of data</li>
        </ul>
        <p> <strong>Positive Aspects:</strong> the decision on transforming CSV
          in to JSON was based on the necessity to have hierarchical data - the
          positive point, that CSV structure can be mapped to an XML or JSON was
          considered. CSV only covers tabular format and JSON can cover more
          complex structures. </p>
        <p> <strong>Negative Aspects:</strong> the data was in CSV format, but
          it's now (2014) outdated, and there's no prevision for new releases.
          There's no metadata in it. </p>
        <p> <strong>Requires:</strong> <a href="#R-QualityCompleteness">QualityCompleteness</a>
          , <a href="#R-PersistentIdentification">PersistentIdentification</a>
          and <a href="#R-SynchronisedData">SynchronisedData</a> </p>
      </section>
      <section id="UC-Bio2RDF" typeof="bibo:Chapter" resource="#UC-Bio2RDF" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-Bio2RDF">Use Case #14 -
          Bio2RDF</h3>
        <p class="contributor">(Contributed by Carlos Laufer)</p>
        <p> <a href="http://bio2rdf.org/">Bio2RDF</a> is an open source project
          that uses Semantic Web technologies to make possible the distributed
          querying of integrated life sciences data. Since its inception [2],
          Bio2RDF has made use of the Resource Description Framework (RDF) and
          the RDF Schema (RDFS) to unify the representation of data obtained
          from diverse (molecules, enzymes, pathways, diseases, etc.) and
          heterogeneously formatted biological data (e.g. flat-files,
          tab-delimited files, SQL, dataset specific formats, XML etc.). Once
          converted to RDF, this biological data can be queried using the SPARQL
          Protocol and RDF Query Language (SPARQL), which can be used to
          federate queries across multiple SPARQL endpoints. </p>
        <p> <strong>Elements:</strong> </p>
        <ul>
          <li>Domains:Biological data </li>
          <li> Obligation/motivation: Biological researchers are often
            confronted with the inevitable and unenviable task of having to
            integrate their experimental results with those of others. This task
            usually involves a tedious manual search and assimilation of often
            isolated and diverse collections of life sciences data hosted by
            multiple independent providers including organizations such as the
            National Center for Bio-technology Information ( <a href="http://www.ncbi.nlm.nih.gov/">NCBI</a>
            ) and the European Bioinformatics Institute ( <a href="http://www.ebi.ac.uk/">EBI</a>
            ) ) which provide dozens of user-submitted and curated data, as well
            as smaller institutions such as the Donaldson group which publishes
            iRefIndex [3], a database of molecular interactions aggregated from
            13 data sources. While these mostly isolated silos of biological
            information occasionally provide links between their records (e.g.
            Uni-Prot links its entries to hundreds of other <a href="http://www.uniprot.org/database/">databases</a>
            ), they are typically serialized in either HTML tags or in flat file
            data dumps that lack the semantic richness required to serialize the
            intent of the linkage between data records. With thousands of
            biological databases and hundreds of thousands if not millions of
            datasets, the ability to find relevant data is hampered by
            non-standard database interfaces and an enormous number of haphazard
            data formats [4]. Moreover, metadata about these biological data
            providers (dataset source data information, dataset versioning,
            licensing information, date of creation, etc.) is often difficult to
            obtain. Taken together, the inability to easily navigate through
            available data presents an overwhelming barrier to their reuse. </li>
          <li>Usage: Biological research</li>
          <li> Quality: Provenance Bio2RDF scripts generate provenance records
            using the <abbr title="World Wide Web Consortium">W3C</abbr>
            Vocabulary of Interlinked Datasets (VoID), the Provenance vocabulary
            (PROV) and Dublin Core vocabulary. Each data item is linked to a
            provenance object that indicates the source of the data, the time at
            which the RDF was generated, licensing (if available from data
            source provider), the SPARQL endpoint in which the resource can be
            found, and the downloadable RDF file where the data item is located.
            Each dataset provenance object has a unique IRI and label based on
            the dataset name and creation date. The date-specific dataset IRI is
            linked to a unique dataset IRI using the <abbr title="World Wide Web Consortium">W3C</abbr>
            PROV predicate "wasDerivedFrom" such that one can query the dataset
            SPARQL endpoint to retrieve all provenance records for datasets
            created on different dates. Each resource in the dataset is linked
            the date-unique dataset IRI that is part of the provenance record
            using the VoID "inDataset" predicate. Other important features of
            the provenance record include the use of the Dublin Core "creator"
            term to link a dataset to the script on Github that was used to
            generate it, the VoID predicate "sparqlEndpoint" to point to the
            dataset SPARQL endpoint, and VoID predicate "dataDump" to point to
            the data download URL.
            <p> Dataset metrics </p>
            <ol>
              <li>total number of triples </li>
              <li>number of unique subjects </li>
              <li>number of unique predicates </li>
              <li>number of unique objects </li>
              <li>number of unique types </li>
              <li>unique predicate-object links and their frequencies </li>
              <li>unique predicate-literal links and their frequencies </li>
              <li>unique subject type-predicate-object type links and their
                frequencies </li>
              <li>unique subject type-predicate-literal links and their
                frequencies </li>
              <li>total number of references to a namespace </li>
              <li>total number of inter-namespace references </li>
              <li>total number of inter-namespace-predicate references </li>
            </ol>
          </li>
          <li>Size: <br />
            Nineteen datasets were generated as part of the Bio2RDF 2 release.
            Several of the datasets are themselves collections of datasets that
            are now available as one resource. Each dataset has been loaded into
            a dataset specific SPARQL endpoint using Openlink Virtuoso version
            6.1.6. SPARQL endpoints, available at
            http://[namespace].bio2rdf.org. All updated Bio2RDF linked data and
            their corresponding Virtuoso DB files are available for <a href="http://download.bio2rdf.org/">download</a>.</li>
        </ul>
        <table>
          <tbody>
            <tr>
              <th>Dataset</th>
              <th>Namespace</th>
              <th>#of triples</th>
            </tr>
            <tr>
              <td>Affymetrix</td>
              <td>affymetrix</td>
              <td>44469611</td>
            </tr>
            <tr>
              <td>Biomodels</td>
              <td>biomodels</td>
              <td>589753</td>
            </tr>
            <tr>
              <td>Comparative Tox-icogenomics Data-base</td>
              <td>ctd </td>
              <td>141845167</td>
            </tr>
            <tr>
              <td>DrugBank</td>
              <td>drugbank</td>
              <td>1121468</td>
            </tr>
            <tr>
              <td>NCBI Gene </td>
              <td>ncbigene </td>
              <td>394026267</td>
            </tr>
            <tr>
              <td>Gene Ontology Annotations </td>
              <td>goa</td>
              <td>80028873 </td>
            </tr>
            <tr>
              <td>HUGO Gene No-menclature Committee </td>
              <td>hgnc</td>
              <td>836060</td>
            </tr>
            <tr>
              <td>Homologene </td>
              <td>homologene</td>
              <td>1281881</td>
            </tr>
            <tr>
              <td>InterPro </td>
              <td>interpro</td>
              <td>999031</td>
            </tr>
            <tr>
              <td>iProClass </td>
              <td>iproclass</td>
              <td>211365460</td>
            </tr>
            <tr>
              <td>iRefIndex </td>
              <td>irefindex</td>
              <td>31042135</td>
            </tr>
            <tr>
              <td>Medical Subject Headings </td>
              <td>mesh</td>
              <td>4172230</td>
            </tr>
            <tr>
              <td>National Center for Biomedical Ontology </td>
              <td>ncbo</td>
              <td>15384622</td>
            </tr>
            <tr>
              <td>National Drug Code Directory </td>
              <td>ndc</td>
              <td>17814216</td>
            </tr>
            <tr>
              <td>Online Mendelian Inheritance in Man </td>
              <td>omim</td>
              <td>1848729</td>
            </tr>
            <tr>
              <td>Pharmacogenomics Knowledge Base </td>
              <td>pharmgkb</td>
              <td> <br />
              </td>
            </tr>
            <tr>
              <td>SABIO-RK </td>
              <td>sabiork</td>
              <td>2618288</td>
            </tr>
            <tr>
              <td>Saccharomyces Genome Database </td>
              <td>sgd</td>
              <td>5551009</td>
            </tr>
            <tr>
              <td>NCBI Taxonomy </td>
              <td>19</td>
              <td>17814216</td>
            </tr>
            <tr>
              <td>Total </td>
              <td>taxon</td>
              <td>1010758291</td>
            </tr>
          </tbody>
        </table>
        <ul>
          <li>Type/format:RDF </li>
          <li>Rate of change: </li>
          <li>Data lifespan:</li>
          <li>Potential audience: Biological researchers</li>
        </ul>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Lack of human-readable metadata. </li>
          <li>Data variability (models, sources, etc.). </li>
          <li> RDFizations of Datasets. </li>
          <li> Wide variety of formats and technologies. </li>
        </ul>
        <p><strong>Potential Requirements:</strong></p>
        <ul>
          <li>Dataset versioning and updating mechanisms </li>
          <li>Standardization of schemas </li>
          <li>Integration with other platforms/services </li>
          <li>Data persistence </li>
        </ul>
        <p><strong>Requires: <a href="#R-Archiving"> Archiving </a> and <a href="#R-FormatStandardized">R-FormatStandardized
              </a></strong></p> </section>
      <!--   <section rel="bibo:Chapter" resource="#ref" typeof="bibo:Chapter" id="UC-NYCOpenData">
        <h3 id="h3_UC-NYCOpenData" role="heading" aria-level="2">Use Case #15 - NYC Open Data Program</h3>        <p class="contributor">(Contributed by Steven Adler)</p>        <p>Carole Post was appointed by Mayor Bloomberg as Commissioner of the          NY Departnmen of IT (DOITT) in 2010 and was the first woman in the          city's history to be CIO. She was the architect of NYC's Open Data          program, sponsored the Open Data Portal and helped pass the city's          Open Data Legislation. On March 11, she gave a presentation to the W3C          on her experiences changing the city culture, building the Open Data          Portal. A recording of her presentation is provided <a href="http://chaordix-ibm-gc-prod.s3.amazonaws.com/blog/wp-content/uploads/2014/03/Carole-Post-NYC-Open-Data.wmv">            here</a>. A copy of her presentation in PDF can be found <a href="http://chaordix-ibm-gc-prod.s3.amazonaws.com/blog/wp-content/uploads/2014/03/WC3-Webinar-on-Open-Data.pdf">            here</a>.</p>        <p> <strong>Requires:</strong> </p>        </section> -->
      <!--   
            <section rel="bibo:Chapter" resource="#ref" typeof="bibo:Chapter" id="UC-RadarParlamentar">        <h3 id="h3_UC-RadarParlamentar" role="heading" aria-level="2">Use Case #16 - Radar Parlamentar</h3>        <p class="contributor">(Contributed by Nathalia )</p>        <p> <a href="http://radarparlamentar.polignu.org/">Radar Parlamentar</a>is          a web application that illustrates the similarities between political          parties based on the vote data analysis that occurs in the Brazilian          congress. The similarities are presented in a two-dimensional          graphics, in which circles represent parties or parliamentarians, and          the distance between these circles is how similar they vote. There is          also only a section dedicated to gender issues: how many women are in          each party over the years, which are the themes most handled by each          gender and party, etc.</p>        <p> <strong>Elements:</strong> </p>        <ul>          <li>Domains: Political information, voting records</li>          <li>Obligation/motivation: The Brazilian government began to provide            their data in an open format through webservices in the portal            Dados.gov.br .</li>          <li>Usage: reuse and exploration of data available in portal            Dados.gov.br in another kinds of visualisation.</li>          <li>Type/format: Tag clouds, 2D graphic, matrix display, treemap</li>          <li>Potential audience: Brazilian citizens</li>        </ul>        <p> <strong>Potential Requirements:</strong>Documentation: there is a          page in the web application explaining the used <a href="">methodology</a></p>        <p> <strong>Requires:</strong> </p>        </section> -->
      <section id="UC-DocumentedSupportandRelease" typeof="bibo:Chapter" resource="#UC-DocumentedSupportandRelease"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DocumentedSupportandRelease">Use
          Case #15 - Documented Support and Release of Data</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p>While many cases of Data on the Web may contain meta-data about
          creation data and last update, the regularity of the release schedule
          is not always clear. Similarly, how and by whom the dataset is
          supported should also be made clear in the meta-data. These attributes
          are necessary to improve the reliability of the data so that
          third-party users can trust the timely delivery of the data, with a
          follow-up point should there be any issues.</p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>Describe release schedule in meta-data</li>
          <li>Describe support mechanisms in meta-data</li>
        </ul>
        <!--
          <p> <strong>Potential Requirements:</strong> </p>        <ul>          <li>Propose use of dcat <a href="http://www.w3.org/TR/vocab-dcat/"> dcat </a> properties <a href="http://purl.org/dc/terms/accrualPeriodicity"> dct:accrualPeriodicity </a> and            <a href="http://www.w3.org/TR/vocab-dcat/#contactpoint"> dcat:contactpoint </a> </li>          <li>Potentially extend dcat?</li>        </ul> -->
        <p> <strong>Requires:</strong> <a href="#R-AccessUptodate">AccessUptodate</a>
          and <a href="#R-SLAAvailable">SLAAvailable</a> </p>
      </section>
      <section id="UC-FeedbackLoopforCorrections" typeof="bibo:Chapter" resource="#UC-FeedbackLoopforCorrections"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-FeedbackLoopforCorrections">Use
          Case #16 - Feedback Loop for Corrections</h3>
        <p class="contributor">(Contributed by Deirdre Lee (based on Pieter
          Colpaert's paper <a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07443-6_56">'Route
            planning using Linked Open Data'</a>) )</p>
        <p>One of the advantages of publishing Open Data is often quoted as
          improving the quality of the data. Many eyes looking at a dataset
          helps spot errors and holes quicker than a public body may identify
          this themselves. For example, in his paper <a href="http://link.springer.com/chapter/10.1007%2F978-3-319-07443-6_56">'Route
            planning using Linked Open Data'</a> Colpaert looks at how feedback
          can be incorporated into transport data to improve its data quality.
          How can this 'improved' data be fed back into the public
          body,processed an incorporated into the original dataset. Should there
          be an automated mechanism for this? How can the improvement be
          described in a machine readable format? What is best practice for
          reincorporating such improvements?</p>
        <p> <strong>Technical Challenges:</strong> </p>
        <ul>
          <li>Should there be an automated mechanism for this?</li>
          <li>How can the improvement be described in a machine readable format?</li>
          <li>What is best practice for reincorporating such improvements?</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-QualityOpinions">QualityOpinions</a>
          and <a href="#R-IncorporateFeedback">IncorporateFeedback</a> </p>
      </section>
      <section id="UC-DatasetsforNaturalDisasterManagement" typeof="bibo:Chapter"

        resource="#UC-DatasetsforNaturalDisasterManagement" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-DatasetsforNaturalDisasterManagement">Use
          Case #17 - Datasets required for Natural Disaster Management</h3>
        <p class="contributor">(Contributed by Deirdre Lee (based on OKF Greece
          workshop) )</p>
        <p>Many of the datasets that are required for Natural Disaster
          Management, for example critical infrastructure, utility services,
          road networks, are not available online as they are also deemed to be
          datasets that could be used for homeland security attacks. </p>
        <strong>Requires:</strong> <a href="#R-SensitiveSecurity">SensitiveSecurity</a>
      </section>
      <section id="UC-OKFNTranportWG" typeof="bibo:Chapter" resource="#ref" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-OKFNTranportWG">Use Case #18
          - OKFN Tranport WG</h3>
        <p class="contributor">(Contributed by Deirdre Lee (based on <a href="http://www.scribd.com/doc/111890372/Helsinki-Open-Transport-Data-Manifesto">2012
            ePSI Open Transport Data Manifesto</a>) )</p>
        <p>The Context: Transportation is an important contemporary issue, which
          has a direct impact on economic strength, environmental sustainability
          and social equity. Accordingly, transport data – largely produced or
          gathered by public sector organisations or semi-private entites, quite
          often locally – represents one of the most valuable sources of public
          sector information (PSI, also called ‘Open Data’), a key policy area
          for many, including the European Commission.</p>
        <p>The Challenge: Combined with the advancement of Web 2.0 technologies
          and the increasing use of smart phones, the demand for high quality
          machine-readable and openly licensed transport data, allowing for
          reuse in commercial and non-commercial products and services, is
          rising rapidly. Unfortunately this demand is not met by current
          supply: many transport data producers and holders (from the public and
          private sectors) have not managed to respond adequately to these new
          challenges set by society and technology.</p>
        <p>So what do we need?</p>
        <ul>
          <li>Access to any transport data of any operator, of high quality, in
            real time, against free or at least fair standard conditions.</li>
          <li>An inclusive infrastructure, based on common open,
            non-discriminatory and interoperable standards and APIs, to which
            operators, service providers, developers and users can connect</li>
          <li>An ecosystem wherein universal access and re-usabiliy of transport
            data is the rule, not the exception</li>
        </ul>
        <p>Why is this not happening?</p>
        <ul>
          <li>Data that is necessary for integrated personal transportation
            solutions is rich and encompasses several domains (geospatial data,
            environmental data, private service provider data), involving a wide
            array of data holders from the public and private sectors. Because
            of its very nature, transport data is often held locally.</li>
          <li>Legacies create lock-ins that prevent adoption of open standards
            and hamper interoperability. </li>
          <li>Many operators and incumbent service providers, in particular
            those relying on income from sales of data, still regard selective
            and exclusive access to transport data as a competitive advantage,
            restricting access and re-use through the exercise of intellectual
            property rights. </li>
          <li>Perceived liability risks, often associated with data quality
            issues, prevent operators from opening up their data. </li>
          <li>Significant differences between countries, regions and transport
            modalities in terms of level of development, market maturity and
            associated business models prevent a ‘one size fits all’ solution. </li>
          <li>A lack of leadership in the value chain –either by the industry or
            from the authorities (whatever the level) –limits governance
            capabilities as to establishment of access, accessibility and other
            framework conditions, creating a need for a subtle mix of mostly
            bottom-up instruments and a dash of top-down measures. </li>
          <li>Existing market players with associated interests turn
            governmental actions into a delicate matter, in particular as to the
            question of where the role of the government should start and end
            within the value chain and where the market parties should take over
            and become the driving factor. </li>
          <li>Where market parties need to step in, the lack of a clear and
            predictable environment prevents businesses from establishing a
            long-term perspective, whereby fair competition needs to be
            safeguarded</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-AccessBulk">AccessBulk</a>, <a

            href="#R-FormatOpen">FormatOpen</a>, <a href="#R-VocabOpen">VocabOpen</a>,
          <a href="#R-QualityMetrics">QualityMetrics</a>, <a href="#R-FormatLocalize">FormatLocalize</a>,and
          <a href="#R-LicenseLiability">LicenseLiability</a></p>
      </section>
      <section id="UC-TrackingofDataUsage" typeof="bibo:Chapter" resource="#UC-TrackingofDataUsage"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-TrackingofDataUsage">Use
          Case #19 - Tracking of data usage</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p> There are many potential/perceived benefits of <a href="http://opendefinition.org/">Open
            Data</a>, however in order to publish data, some initial
          investment/resources are required by public bodies. When justifying
          these resources and evaluating the impact of the investment, many Open
          Data providers express the desire to be able to track how the datasets
          are being used. However Open Data by design often requires no
          registration, explanation or feedback to enable the access to and
          usage of the data. How can data usage be tracked in order to inform
          the Open Data ecosystem and improve data provision? </p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>No registration required by data user</li>
          <li>automatic vs. manual solution</li>
          <li>solution should not break basic Open Data principles</li>
          <li>Most developers may not mind giving feedback if it will improve
            quality of data/service</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-TrackDataUsage">TrackDataUsage</a>
        </p>
      </section>
      <section id="UC-OpenCityDataPipeline" typeof="bibo:Chapter" resource="#UC-OpenCityDataPipeline"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-OpenCityDataPipeline">Use
          Case #20 - Open City Data Pipeline</h3>
          <p class="contributor">(Contributed by Deirdre Lee, based on <a href="https://ai.wu.ac.at/~polleres/presentations/20140319CityDataPipeline_EDF2014_Polleres.pdf">a presentation by Axel Polleres at EDF 2014)</a></p>
        <p>The Open City Data Pipeline aims to to provide an extensible platform
          to support citizens and city administrators by providing city key
          performance indicators (KPIs),leveraging Open Data sources. The
          assumption of Open Data is the “Added value comes from comparable Open
          datasets being combined”. Open Data needs stronger standards to be
          useful, in particular for industrial uptake. Industrial usage has
          different requirements than app hobbyist or civil society, it's
          important to think how Open Data can be used by industry at time of
          publication. They have developed a data pipeline to: </p>
        <ol>
          <li> (semi-)automatically collect and integrate various Open Data
            Sources in different formats </li>
          <li> compose and calculate complex city KPIs from the collected data </li>
        </ol>
        <p>Current Data Summary </p>
        <ul>
          <li> Ca. 475 different indicators </li>
          <li> Categories: Demography, Geography, Social Aspects, Economy,
            Environment, etc. </li>
          <li> from 32 sources (html, CSV, RDF, ...) </li>
          <li> Wikipedia, urbanaudit.org, Statistics from City homepages,
            country Statistics, iea.org </li>
          <li> Covering 350+cities in 28 European countries </li>
          <li> District Data for selected cities (Vienna, Berlin) </li>
          <li> Mostly snapshots, Partially covering timelines </li>
          <li> On average ca. 285 facts per city. </li>
        </ul>
        <p>Base assumption (for our use case): Added value comes from comparable
          Open datasets being combined Challenges &amp; Lessons Learnt: </p>
        <ul>
          <li> <b>Incomplete</b> Data: can be partially overcome
            <ul>
              <li>By ontological reasoning (RDF &amp; OWL), by aggregation, or
                by rules &amp; equations, e.g. :populationDensity = :population
                / :area , cf. <a href="http://axel.deri.ie/publications/bisc-etal-2013ESWC.pdf">
                  [ESWC2013] </a></li>
              <li>By statistical methods or Multi-dimensional Matrix
                Decomposition (unfortunately only partially successful, because
                these algorithms assume normally-distributed data.) </li>
            </ul>
          </li>
          <li><b>Incomparable</b> Data:
            <ul>
              <li>dbpedia:populationTotal </li>
              <li>dbpedia:populationCensus </li>
            </ul>
          </li>
          <li><b>Heterogeneity</b> across Open Government Data efforts:
            <ul>
              <li>Different <b>Indicators</b>, Different Temporal and Spatial
                Granularity</li>
              <li>Different <b>Licenses</b> of Open Data: e.g. CC-BY, country
                specific licences, etc. </li>
              <li>Heterogeneous <b>Formats</b> (CSV != CSV) ... Maybe the <abbr

                  title="World Wide Web Consortium">W3C</abbr> CSV on the Web WG
                will solve this issue)</li>
            </ul>
          </li>
        </ul>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Incomplete data (can be overcome using semantic technologies
            and/or statistical methods)</li>
          <li>Heterogeneity (indicators, licenses, formats)</li>
          <li>Open Data needs stronger standards to be useful (in particular for
            industrial uptake), at a metadata level, and dataset level.</li>
          <li> Metadata is not always uniform, not only titles of columns, but
            standardisation about units, etc.</li>
        </ul>
        <p><strong>Requires:</strong> <a href="#R-FormatStandardized">FormatStandardized</a>
          , <a href="#R-IndustryReuse">IndustryReuse</a> , <a href="#R-QualityCompleteness">QualityCompleteness</a>
          and <a href="#R-QualityComparable">QualityComparable</a> </p>
      </section>
      <section id="UC-MachineReadabilityandInteroperabilityofLicenses" typeof="bibo:Chapter"

        resource="#UC-MachineReadabilityandInteroperabilityofLicenses" rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-MachineReadabilityandInteroperabilityofLicenses">Use
          Case #21 - Machine-readability and Interoperability of Licenses</h3>
        <p class="contributor">(Contributed by Deirdre Lee, based on post by
          Leigh Dodds)</p>
        <p> There are many different licenses available under which data on the
          web can be published, <a href="http://opendefinition.org/licenses/">e.g.
            Creative Commons, Open Data Commons, national licenses, etc.</a> It
          is important that the license is available in a machine-readable
          format. Leigh Dodds has done some work towards this with the Open Data
          Rights Statement Vocabulary http://schema.theodi.org/odrs/
          http://theodi.org/guides/publishers-guide-to-the-open-data-rights-statement-vocabulary
          http://theodi.org/guides/odrs-reusers-guide Another issue is when data
          under different licenses are combined, the license terms under which
          the data is available also have to be merged. This interoperability of
          licenses is a challenge [may be out of scope of <abbr title="World Wide Web Consortium">W3C</abbr>
          DWBP, as it is more concerned with legal issues] </p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>standard vocabulary for data licenses</li>
          <li>machine-readability of data licenses</li>
          <li>interoperability of data licenses</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-LicenseAvailable">LicenseAvailable</a>
        </p>
      </section>
      <section id="UC-MachineReadabilityofSLAs" typeof="bibo:Chapter" resource="#UC-MachineReadabilityofSLAs"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-MachineReadabilityofSLAs">Use
          Case #22 - Machine-readability of SLAs</h3>
        <p class="contributor">(Contributed by Deirdre Lee (based on a number of
          talks at EDF14) )</p>
        <p>A main focus of publishing data on the web is to facilitate industry
          resuse for commercial purposes. In order for a commercial body to
          reuse data on the web, the terms of reuse must be clear. The legal
          terms of reuse are included in the license, but there are other
          factors that are important for commercial reuse, e.g. reliabiliy,
          support, incidient recovery, etc. These could be included in an SLA.
          Is there a standardized, machine-readable approach to SLAs?</p>
        <p><strong>Challenges:</strong></p>
        <ul>
          <li>Defining common SLA requrirements for industry reuse</li>
          <li>Existing standards/vocabularies for SLA requirements</li>
          <li>Machine-readable access to SLAs</li>
        </ul>
        <p><strong>Requires:</strong><a href="#R-SLAAvailable">SLAAvailable</a>
        </p>
      </section>
      <section id="UC-PublicationofDataviaAPIs" typeof="bibo:Chapter" resource="#UC-PublicationofDataviaAPIs"

        rel="bibo:Chapter">
        <h3 aria-level="2" role="heading" id="h3_UC-PublicationofDataviaAPIs">Use
          Case #23 - Publication of Data via APIs</h3>
        <p class="contributor">(Contributed by Deirdre Lee)</p>
        <p> APIs are commonly used to publish data in formats designed for
          machine-consumption, as opposed to the corresponding HTML pages whose
          main aim is to deliver content suitable for human-consumption. There
          remains <a href="http://ruben.verborgh.org/blog/2013/11/29/the-lie-of-the-api/">
            questions</a> around how APIs can best be designed to publish data,
          and even if APIs are the most suitable way for publishing data at all
          . Could use of HTTP and URIs be sufficient? If the goal is to
          facilitate machine-readable data, what is best-practice? </p>
        <p> <strong>Challenges:</strong> </p>
        <ul>
          <li>APIs can be too clunky/rich in their functionality, which may
            increase the amount of calls necessary and size of data transferred,
            reducing performance</li>
          <li>Collaboration between API providers and users is necessary to
            agree on 'useful' calls</li>
          <li>API key agreements could restrict Openess of Open Data?</li>
          <li>Documentation accompanying APIs can be lacking</li>
          <li>What is best practice for publishing streams of real-time data
            (with/without APIs)?</li>
          <li>Each resource should have one URI uniquly identifying it. There
            can then be different representations of the resource
            (xml/html/json/rdf)</li>
        </ul>
        <p> <strong>Requires:</strong> <a href="#R-AccessBulk">AccessBulk</a>
          and <a href="#R-AccessRealTime">AccessRealTime</a> </p>
      </section>
      <br />
    </section>
    <section id="general-challenges" rel="bibo:Chapter" resource="#challenges" typeof="bibo:Chapter">
      <h2 role="heading" aria-level="1" id="challenges">General Challenges</h2>
      <p>The use cases presented in the previous section illustrate a number of
        challenges faced by data publishers and data consumers. These challenges
        show that some guidance is required on specifc areas and therefore best
        practices should be provided. According to the challenges, a set of
        requirements were defined in such a way that a requirement motivates the
        creation of one or more best practices. Challenges related to Data
        Qaulity and Data Usage motivated the definition of specifc requirements
        for the Quality and Granularity Description Vocabulary and the Data
        Usage Vocabulary. </p>
      <p> </p>
      <table>
        <tbody>
          <tr>
            <th>Challenge</th>
            <th>Requirements</th>
          </tr>
          <tr>
            <td>Data Formats</td>
            <td> <a href="#h4_can-req-Formats">Requirements for Data Formats </a>
            </td>
          </tr>
          <tr>
            <td>Data Vocabularies</td>
            <td> <a href="#h4_can-req-vocabularies">Requirements for Data
                Vocabularies </a> </td>
          </tr>
          <tr>
            <td>Metadata</td>
            <td> <a href="#h4_can-req-metadata">Requirements for Metadata</a> </td>
          </tr>
          <tr>
            <td>Licenses</td>
            <td> <a href="#h4_can-req-licenses">Requirements for Licenses </a>
            </td>
          </tr>
          <tr>
            <td>Provenance</td>
            <td> <a href="#h4_can-req-provenance">Requirements for Provenance </a>
            </td>
          </tr>
          <tr>
            <td>Industry-reuse</td>
            <td> <a href="#h4_can-req-industry-reuse">Requirements for Industry
                reuse </a> </td>
          </tr>
          <tr>
            <td>Data Granularity</td>
            <td> <a href="#h4_can-req-granularity">Requirements for Data
                Granularity </a> </td>
          </tr>
          <tr>
            <td>Data Selection</td>
            <td> <a href="#h4_can-req-selection">Requirements for Data
                Selection </a> </td>
          </tr>
          <tr>
            <td>Data Access</td>
            <td> <a href="#h4_can-req-access">Requirements for Data Access </a>
            </td>
          </tr>
          <tr>
            <td>Sensitive Data</td>
            <td> <a href="#h4_can-req-sensitive">Requirements for Sensitive
                Data</a> </td>
          </tr>
          <tr>
            <td>Data Identification</td>
            <td> <a href="#h4_can-req-identification">Requirements for Data
                Identification </a> </td>
          </tr>
          <tr>
            <td>Data Publication</td>
            <td> <a href="#h4_can-req-publication">Requirements for Data
                Publication </a> </td>
          </tr>
          <tr>
            <td>Persistence</td>
            <td> <a href="#h4_can-req-persistence">Requirements for Persistence
              </a> </td>
          </tr>
          <tr>
            <td>Data Quality</td>
            <td> <a href="#h4_can-req-quality">Requirements for Data Quality </a>
            </td>
          </tr>
          <tr>
            <td>Data Usage</td>
            <td> <a href="#h4_can-req-usage">Requirements for Data Usage </a>
            </td>
          </tr>
        </tbody>
      </table>
    </section>
    <section id="requirements-1" rel="bibo:Chapter" resource="#requirements" typeof="bibo:Chapter">
      <!--OddPage-->
      <h2 role="heading" aria-level="1" id="requirements">Requirements</h2>
      <p> </p>
      <section id="requirements-for-data-on-the-web-best-practices" rel="bibo:Chapter"

        resource="#req1" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req1">Requirements for Data on the
          Web Best Practices </h3>
        <section id="requirements-for-data-formats" rel="bibo:Chapter" resource="#h4_can-req-Formats"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-Formats">Requirements
            for Data Formats</h4>
          <dl>
            <dt id="R-FormatMachineRead">R-FormatMachineRead</dt>
            <dd>
              <p id="_R-FormatMachineRead"><em>Data should be available in a
                  machine-readable format that is adequate for its intended or potential use</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-BuildingEye">BuildingEye</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a> </p>
            </dd>
            <dt id="R-FormatStandardized">R-FormatStandardized</dt>
            <dd>
              <p id="_R-FormatStandardized"><em>Data should be availabe in a
                  standardized format. Through standardization, interoperability is also expected.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
                , <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a>
                , <a href="#UC-BuildingEye">BuildingEye</a> , <a href="#UC-TheLandPortal">TheLandPortal</a>
                , <a href="#UC-GS1-Digital">GS1 Digital</a> and <a href="#UC-Tabulae">Tabulae</a>
                , </p>
            </dd>
            <dt id="R-FormatOpen">R-FormatOpen</dt>
            <dd>
              <p id="_R-FormatOpen"><em>Data should be availabe in an Open
                  format</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-BuildingEye">BuildingEye</a>
                , </p>
            </dd>
            <dt id="R-FormatMultiple">R-FormatMultiple</dt>
            <dd>
              <p id="_R-FormatMultiple"><em>Data should be availabe in multiple
                  formats</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-GS1-Digital">GS1
                  Digital</a> </p>
            </dd>
            <dt id="R-FormatLocalize">R-FormatLocalize</dt>
            <dd>
              <p id="_R-FormatLocalize"><em>Information about locale parameters
                  (date and number formats, language) should be made available</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
                and <a href="#UC-Tabulae">Tabulae</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-vocabularies" rel="bibo:Chapter" resource="#h4_can-req-vocabularies"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-vocabularies">Requirements
            for Data Vocabularies</h4>
          <dl>
            <dt id="R-VocabReference">R-VocabReference</dt>
            <dd>
              <p id="_R-VocabReference"><em>Existing reference vocabularies
                  should be reused where possible</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
                , <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a> ,
                <a href="#UC-DadosGovBr">DadosGovBr</a> , <a href="#UC-ISOGEOStory">ISOGEOStory</a>
                , <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a> , <a

                  href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>
                , <a href="#UC-TheLandPortal">TheLandPortal</a> , <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>
                and <a href="#UC-Tabulae">Tabulae</a> </p>
            </dd>
            <dt id="R-VocabDocum">R-VocabDocum</dt>
            <dd>
              <p id="_R-VocabDocum"><em>Vocabularies should be clearly
                  documented</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              </p>
            </dd>
            <dt id="R-VocabOpen">R-VocabOpen</dt>
            <dd>
              <p id="_R-VocabOpen"><em>Vocabularies should be shared in an Open
                  way</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
                and <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a>
              </p>
            </dd>
            <dt id="R-VocabVersion">R-VocabVersion</dt>
            <dd>
              <p id="_R-VocabVersion"><em>Vocabularies should include versioning
                  information</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
                and <a href="#UC-Tabulae">Tabulae</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-metadata" rel="bibo:Chapter" resource="#h4_can-req-metadata"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-metadata"> <span class="secno"></span>Requirements
            for Metadata</h4>
          <dl>
            <dt id="R-MetadataMachineRead">R-MetadataMachineRead</dt>
            <dd>
              <p id="_R-MetadataMachineRead"><em>Metadata should be
                  machine-readable</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-Bio2RDF">Bio2RDF</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a></p>
            </dd>
            <dt id="R-MetadataStandardized">R-MetadataStandardized</dt>
            <dd>
              <p id="_R-MetadataStandardized"><em>Metadata should be
                  standardized. Through standardization, interoperability is also expected.</em></p>
              <p><strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>,
                <a href="#UC-ISOGEOStory">ISOGEOStory</a>
                and <a href="#UC-LATimesReporting">LATimesReporting</a></p>
            </dd>
            <dt id="R-MetadataDocum">R-MetadataDocum</dt>
            <dd>
              <p id="_R-MetadatDocum"><em>Metadata vocabulary, or values if
                  vocabulary is not standardized, should be well-documented</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-licenses" rel="bibo:Chapter" resource="#h4_can-req-licenses"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-licenses">Requirements
            for Licenses</h4>
          Note: Licenses are a form of metadata and so inherit metadata
          requirements
          <dl>
            <dt id="R-LicenseAvailable">R-LicenseAvailable</dt>
            <dd>
              <p id="LicenseAvailable"><em>Data should be associated with a
                  license. License is a type of metadata, so all metadata
                  requirements also apply here. <br />
                </em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-MachineReadabilityandInteroperabilityofLicenses">MachineReadabilityandInteroperabilityofLicenses</a>
                , <a href="#UC-DadosGovBr">DadosGovBr</a> and <a href="#UC-BuildingEye">BuildingEye</a>
              </p>
            </dd>
            <dt id="R-LicenseLiability">R-LicenseLiability</dt>
            <dd>
              <p id="LicenseLiability"><em>Liability terms associated with usage
                  of Data on the Web should be clearly outlined</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-GS1-Digital">GS1
                  Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-provenance" rel="bibo:Chapter" resource="#h4_can-req-provenance"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-provenance">Requirements
            for Provenance</h4>
          Note: Provenance data is a form of metadata and so inherits metadata
          requirements
          <dl>
            <dt id="R-ProvAvailable">R-ProvAvailable</dt>
            <dd>
              <p id="ProvAvailable"><em>Data provenance information should be
                  available. Provenance </em>data i<em>s a type of metadata, so
                  all metadata requirements also apply here. </em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
                , <a href="#UC-GS1-Digital">GS1 Digital</a> and <a href="#UC-Tabulae">Tabulae</a></p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-industry-reuse" rel="bibo:Chapter" resource="#h4_can-req-industry-reuse"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-industry-reuse">Requirements
            for Industry Reuse</h4>
          Note: SLAs are a form of metadata and so inherit metadata requirements
          <dl>
            <dt id="R-SLAAvailable">R-SLAAvailable</dt>
            <dd>
              <p id="SLAAvailable"><em>Service Level Agreements (SLAs) for
                  industry reuse of the data should be available if requested.
                  An SLA is </em><em>a type of metadata, so all metadata
                  requirements also apply here. </em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DocumentedSupportandRelease">DocumentedSupportandRelease</a>
                and <a href="#UC-MachineReadabilityofSLAs">MachineReadabilityofSLAs</a>
              </p>
            </dd>
            <dt id="R-IndustryReuse">R-IndustryReuse</dt>
            <dd>
              <p id="IndustryReuse"><em>Data should be suitable for industry
                  reuse</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
              </p>
            </dd>
            <dt id="R-PotentialRevenue">R-PotentialRevenue</dt>
            <dd>
              <p id="PotentialRevenue"><em>Potential revenue streams from data
                  should be described</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-granularity" rel="bibo:Chapter" resource="#h4_can-req-granularity"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-granularity">Requirements
            for Data Granularity</h4>
          <dl>
            <dt id="R-GranularityLevels">R-GranularityLevels</dt>
            <dd>
              <p id="_R-GranularityLevels"><em>Data available at different
                  levels of granularity should be accessible and modelled in a
                  common way</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-ISOGEOStory">ISOGEOStory</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-selection" rel="bibo:Chapter" resource="#h4_can-req-selection"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-selection">Requirements
            for Data Selection</h4>
          <dl>
            <dt id="R-SelectHighValue">R-SelectHighValue</dt>
            <dd>
              <p id="_R-SelectHighValue"><em>Datasets selected for publication
                  should be of high-value, which should be indicated in a
                  quantifiable manner/property.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              </p>
            </dd>
            <dt id="R-SelectDemand">R-SelectDemand</dt>
            <dd>
              <p id="_R-SelectDemand"><em>Datasets selected for publication
                  should be in demand by potential users, which should be
                  indicated in a quantifiable manner/property.</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-access" rel="bibo:Chapter" resource="#h4_can-req-access"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-access">Requirements
            for Data Access</h4>
          <dl>
            <dt id="R-AccessBulk">R-AccessBulk</dt>
            <dd>
              <p id="_R-AccessBulk"><em>Data should be available for bulk
                  download</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-PublicationofDataviaAPIs">PublicationofDataviaAPIs</a>
                , <a href="#UC-BuildingEye">BuildingEye</a> and <a href="#UC-TheLandPortal">TheLandPortal</a>
              </p>
            </dd>
            <dt id="R-AccessRealTime">R-AccessRealTime</dt>
            <dd>
              <p id="_R-AccessRealTime"><em>Where data is produced in real-time,
                  it should be available on the Web in real-time</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-PublicationofDataviaAPIs">PublicationofDataviaAPIs</a>
                , <a href="#UC-WindCharacterizationScientificStudy">WindCharacterizationScientificStudy</a>
                and <a href="#UC-TheLandPortal">TheLandPortal</a> </p>
            </dd>
            <dt id="R-AccessUptodate">R-AccessUptodate</dt>
            <dd>
              <p id="_R-AccessUptodate"><em>Data should be available in an
                  up-to-date manner</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DocumentedSupportandRelease">DocumentedSupportandRelease</a>
                and <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-sensitive-data" rel="bibo:Chapter" resource="#h4_can-req-sensitive"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-sensitive">Requirements
            for Sensitive Data</h4>
          <dl>
            <dt id="R-SensitivePrivacy">R-SensitivePrivacy</dt>
            <dd>
              <p id="_R-SensitivePrivacy"><em>Data should not infringe on a
                  person's right to privacy</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a>
              </p>
            </dd>
            <dt id="R-SensitiveSecurity">R-SensitiveSecurity</dt>
            <dd>
              <p id="_RSensitiveSecurity"><em>Data should not infringe on
                  national security</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DatasetsforNaturalDisasterManagement">DatasetsforNaturalDisasterManagement</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-identification" rel="bibo:Chapter" resource="#h4_can-req-identification"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-identification">Requirements
            for Data Identification</h4>
          <dl>
            <dt id="R-UniqueIdentifier">R-UniqueIdentifier</dt>
            <dd>
              <p id="UniqueIdentifier"><em>Each data resource should be
                  associated with a unique identifier</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a>
                , <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>
                , <a href="#UC-LATimesReporting">LATimesReporting</a> and <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>
              </p>
            </dd>
            <dt id="R-MultipleRepresentations">R-MultipleRepresentations</dt>
            <dd>
              <p id="MultipleRepresentations"><em>A data resource may have
                  multiple representations, e.g. xml/html/json/rdf</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a>
              </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-data-publication" rel="bibo:Chapter" resource="#h4_can-req-publication"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-publication">Requirements
            for Data Publication</h4>
          <dl>
            <dt id="R-DynamicGeneration">R-SynchronisedData</dt>
            <dd>
              <p id="DynamicGeneration"><em>Dynamic generation of Data on the
                  Web from non-Web data resources and a</em><em>utomatic update
                  when original data source is updated</em></p>
              <strong>Motivation:</strong> <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a>
              , <a href="#UC-UruguayOpenDataCatalogue">UruguayOpenDataCatalogue</a>
              , <a href="#UC-GS1-Digital">GS1 Digital</a> , <a href="#UC-Tabulae">Tabulae</a>
              , <a href="#UC-ViolenceMap">ViolenceMap</a> </dd>
            <dt id="R-CoreRegister"><br />
            </dt>
            <dt id="R-CoreRegister">R-CoreRegister</dt>
            <dd>
              <p id="CoreRegister"><em>Core registers should be accessible</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DutchBasicRegisters">DutchBasicRegisters</a>
                and <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
        <section id="requirements-for-persistence" rel="bibo:Chapter" resource="#h4_can-req-persistence"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-persistence">Requirements
            for Persistence</h4>
          <dl>
            <dt id="R-PersistentIdentification">R-PersistentIdentification</dt>
            <dd>
              <p id="Persistent"><em>Data should be persistently identifiable</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>
                , <a href="#UC-TheLandPortal">TheLandPortal</a> , <a href="#UC-GS1-Digital">GS1
                  Digital</a> and <a href="#UC-ViolenceMap">ViolenceMap</a> </p>
            </dd>
            <dt id="R-Archiving">R-Archiving</dt>
            <dd>
              <p id="PersArchiving"><em>It should be possible to archive data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-DigitalArchivingofLinkedData">DigitalArchivingofLinkedData</a>
              </p>
            </dd>
          </dl>
        </section>
      </section>
      <section id="requirements-for-quality-and-granularity-description-vocabulary"

        rel="bibo:Chapter" resource="#req2" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req2">Requirements for Quality and
          Granularity Description Vocabulary</h3>
        <section id="requirements-for-data-quality" rel="bibo:Chapter" resource="#h4_can-req-quality"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-quality"> <span class="secno">4.2.1
              </span>Requirements for Data Quality</h4>
          <dl>
            <dt id="R-QualityCompleteness">R-QualityCompleteness</dt>
            <dd>
              <p id="_R-QualityCompleteness"><em>Data should be complete</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
                , <a href="#UC-RecifeOpenDataPortal">RecifeOpenDataPortal</a> ,
                <a href="#UC-TheLandPortal">TheLandPortal</a> , <a href="#UC-Tabulae">Tabulae</a>
                and <a href="#UC-ViolenceMap">ViolenceMap</a> </p>
            </dd>
            <dt id="R-QualityComparable">R-QualityComparable</dt>
            <dd>
              <p id="_R-QualityComparable"><em>Data should be comparable with
                  other datasets</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-OpenCityDataPipeline">OpenCityDataPipeline</a>
              </p>
            </dd>
            <dt id="R-QualityMetrics">R-QualityMetrics</dt>
            <dd>
              <p id="_R-QualityMetrics"><em>Data should be associated with a set
                  of standardized, objective quality metrics</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TheLandPortal">TheLandPortal</a>
              </p>
            </dd>
            <dt id="R-QualityOpinions">R-QualityOpinions</dt>
            <dd>
              <p id="_R-QualityOpinions"><em>Subjective quality opinions on the
                  data should be supported</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-FeedbackLoopforCorrections">FeedbackLoopforCorrections</a>
                and <a href="#UC-DadosGovBr">DadosGovBr</a> </p>
            </dd>
          </dl>
        </section>
      </section>
      <section id="requirements-for-data-usage-description-vocabulary" rel="bibo:Chapter"

        resource="#req3" typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="req3">Requirements for Data Usage
          Description Vocabulary</h3>
        <section id="requirements-for-data-usage" rel="bibo:Chapter" resource="#h4_can-req-usage"

          typeof="bibo:Chapter">
          <h4 role="heading" aria-level="3" id="h4_can-req-usage">Requirements
            for Data Usage</h4>
          <dl>
            <dt id="R-TrackDataUsage">R-TrackDataUsage</dt>
            <dd>
              <p id="_R-TrackDataUsage"><em>It should be possible to track the
                  usage of data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-TrackingofDataUsage">TrackingofDataUsage</a>
              </p>
            </dd>
            <dt id="R-IncorporateFeedback">R-IncorporateFeedback</dt>
            <dd>
              <p id="_R-IncorporateFeedback"><em>It should be possible to
                  incorporate feedback on the data</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-FeedbackLoopforCorrections">FeedbackLoopforCorrections</a>
                , </p>
            </dd>
            <dt id="R-Citable">R-Citable</dt>
            <dd>
              <p id="_R-Citable"><em>It should be possible to cite data on the
                  Web</em></p>
              <p> <strong>Motivation:</strong> <a href="#UC-LATimesReporting">LATimesReporting</a>
                and <a href="#UC-GS1-Digital">GS1 Digital</a> </p>
            </dd>
          </dl>
        </section>
      </section>
    </section>
    <section id="reading-material-1" rel="bibo:Chapter" resource="#reading-material"

      typeof="bibo:Chapter">
      <h2 role="heading" aria-level="1" id="reading-material">Reading Material</h2>
      <section id="general-resources-1" rel="bibo:Chapter" resource="#general-resources"

        typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="general-resources">General
          Resources</h3>
        <ul>
          <li><a href="http://www.w3.org/TR/ld-glossary/" class="external text">Government
              Linked Data (GLD) Glossary of Terms</a></li>
          <li><a href="http://lov.okfn.org/dataset/lov/" class="external text">Open
              Knowledge Foundation (OKFN) Linked Open Vocabulary Browser</a></li>
          <li><a href="http://www.w3.org/TR/ld-bp/" class="external text">Best
              Practices for Publishing Linked Data</a></li>
          <li><a href="http://philarcher.org/diary/2013/uripersistence/" class="external text">
              10 Rules for Persistent URIs</a></li>
          <li><a href="http://www.w3.org/2012/ldp/" class="external text">Linked
              Data Platform Working Group</a></li>
          <li>The <a href="http://www.prelida.eu/" class="external text">PRELIDA</a>
            and <a href="http://www.diachron-fp7.eu/">Diachron</a> projects are
            concerned with preserving <abbr title="Linked Open Data">LOD</abbr></li>
        </ul>
      </section>
      <section id="relevant-vocabularies" rel="bibo:Chapter" resource="#relevant-vocabs"

        typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="relevant-vocabs">Relevant
          Vocabularies</h3>
        <ul>
          <li><a href="http://www.w3.org/TR/vocab-org/" class="external text">The
              Organization Ontology (ORG)</a></li>
          <li><a href="http://www.w3.org/TR/vocab-dcat/" class="external text">Data
              Catalog Vocabulary(DCAT)</a></li>
          <li><a href="http://www.w3.org/TR/vocab-data-cube/" class="external text">The
              RDF Data Cube Vocabulary (QB)</a></li>
          <li><a href="http://www.w3.org/TR/prov-o/" class="external text">The
              Provenance (PROV) Ontology</a></li>
          <li><a href="http://www.w3.org/TR/skos-reference/" class="external text">Simple
              Knowledge Organization System Reference (SKOS)</a></li>
        </ul>
      </section>
      <section id="communities-of-interest-1" rel="bibo:Chapter" resource="#communities-of-interest"

        typeof="bibo:Chapter">
        <h3 role="heading" aria-level="2" id="communities-of-interest">Communities
          of Interest</h3>
        <ul>
          <li><a href="http://www.w3.org/2013/data/" class="external text"><abbr

                title="World Wide Web Consortium">W3C</abbr> Data Activity</a></li>
          <li><a href="http://www.w3.org/2013/05/lcsv-charter.html" class="external text"><abbr

                title="World Wide Web Consortium">W3C</abbr> Comma Separated
              Values (CSV) On the Web Working Group</a>
            <ul>
              <li><a href="http://www.w3.org/TR/csvw-ucr/" class="external text">
                  CSV On the Web Use Cases</a></li>
            </ul>
          </li>
          <li><a href="http://www.w3.org/2011/gld/charter.html" class="external text"><abbr

                title="World Wide Web Consortium">W3C</abbr> Government Linked
              Data Working Group</a> (This WG is now closed but in some respects
            is the forerunner of the DWBP)</li>
          <li><a href="http://www.w3.org/2011/07/privacy-ig-charter.html" class="external text"><abbr

                title="World Wide Web Consortium">W3C</abbr> Privacy on the Web
              (PING) Working Group</a></li>
        </ul>
      </section>
    </section>
    <section rel="bibo:Chapter" resource="#acknowledgements" typeof="bibo:Chapter"

      class="appendix" id="acknowledgements">
      <h2 id="h2_acknowledgements" role="heading" aria-level="1">Acknowledgements</h2>
    </section>
    <section rel="bibo:Chapter" resource="#change-history" typeof="bibo:Chapter"

      class="appendix" id="change-history">
      <h2 id="h2_change-history" role="heading" aria-level="1">Change history</h2>
    </section>
  </body>
</html>
